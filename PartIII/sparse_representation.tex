\chapter{\chatextsparseCalculus}\label{cha:sparseRepresentation}

We in this chapter develop sparse tensor representation formats based on constrained $\cpformat$ formats.
Our motivation for these formats result from the connection to encoding mechanisms, which we have applied in \parref{par:one} and \parref{par:two}, and to sparse optimization formats.
%We further provide constructive bounds on the corresponding tensor ranks.


\sect{$\cpformat$ Decomposition}

% Motivation by Singular Value Decomposition
The $\cpformat$ decomposition is one way to generalize the ranks of matrices to tensors.
It is oriented on the Singular Value Decomposition of matrices, providing a representation of the matrix as a weighed sum of the tensor product of singular vectors.
Given a matrix $\matrixat{\catvariableof{0},\catvariableof{1}}$, we enumerate its singular values by $\decvariable$ taking values in $[\decdim]$ and store them in a vector $\scalarcoreat{\decvariable}$.
With the corresponding singular vectors by $\legcoreofat{0}{\catvariableof{0},\decvariable}$ and $\legcoreofat{1}{\catvariableof{1},\decvariable}$, the singular value decomposition of $\exmatrix$ is
\begin{align*}
    \matrixat{\catvariableof{0},\catvariableof{1}}
    &= \sum_{\decindexin} \scalarcoreat{\indexeddecvariable} \cdot \legcoreofat{0}{\catvariableof{0},\indexeddecvariable} \otimes \legcoreofat{1}{\catvariableof{1},\indexeddecvariable} \, .
\end{align*}
Here the smallest $\decdim$ such that this decomposition exists, is the matrix rank $\cprankof{\exmatrix}$.
In contraction notation we abbreviate this to
\begin{align*}
    \matrixat{\catvariableof{0},\catvariableof{1}}
    &= \contractionof{\scalarcoreat{\decvariable},\legcoreofat{0}{\catvariableof{0},\decvariable},\legcoreofat{1}{\catvariableof{1},\decvariable}}{\catvariableof{0},\catvariableof{1}} \, .
\end{align*}
Given a tensor of higher order, a generalization of this decomposition is a tensor product over multiple vectors, as we define next.
%% REPETITION
%\begin{align*}
%	\hypercorewith
%	&= \sum_{\decindexin} \scalarcoreat{\indexeddecvariable} \cdot \bigotimes_{\catenumeratorin}\legcoreofat{\catenumerator}{\catvariableof{\catenumerator},\indexeddecvariable} \, .
%	& = \contractionof{
%		\{\scalarcoreat{\decvariable}\} \cup \{ \legcoreofat{\atomenumerator}{\decvariable,\catvariableof{\atomenumerator}} \, : \, \atomenumeratorin \}
%		}{\shortcatvariables} \, .
%\end{align*}


\begin{definition}
    \label{def:cpFormats}
    A $\cpformat$ decomposition of size $\decdim$ of a tensor $ \hypercorewithin$ is a collections of a scalar core $\scalarcoreat{\decvariable}$ and leg cores $\legcoreofat{\atomenumerator}{\decvariable,\catvariableof{\atomenumerator}}$ for $\atomenumeratorin$, where $\decvariable$ is an enumeration variable taking values in $[\decdim]$, such that
    \begin{align*}
        \hypercorewith
        = \contractionof{
            \{\scalarcoreat{\decvariable}\} \cup \{ \legcorewith \, : \, \atomenumeratorin \}
        }{\shortcatvariables} \, .
    \end{align*}
%	where for each $\decindexin$ and $\atomenumeratorin$ we have $\scalarcoreat{\decindex} \in \rr$ and $\legcoreof{\atomenumerator,\decindex}\in\rr^{\catindexof{\atomenumerator}}$.
    We say that the $\cpformat$ Decomposition is
    \begin{itemize}
        \item directed, when for each $\atomenumerator$ the core $\legcoreof{\atomenumerator}$ is directed with $\decvariable$ incoming and $\catvariableof{\atomenumerator}$ outgoing.
        \item boolean, when for each $\atomenumerator$ the core $\legcoreof{\atomenumerator}$ is boolean.
        \item basis, where we demand both properties, that is for each $\atomenumeratorin$ and $\decindexin$
        \begin{align*}
            \legcoreofat{\atomenumerator}{\catvariableof{\atomenumerator},\indexeddecvariable}
            \in\{\onehotmapofat{\catindexof{\atomenumerator}}{\catvariableof{\atomenumerator}} \wcols \catindexof{\atomenumerator}\in[\catdimof{\atomenumerator}] \}\, .
        \end{align*}
        \item basis+, when for each $\atomenumeratorin$ and $\decindexin$  %$\legcoreof{\atomenumerator,\decindex}\in\onehotmapof{[\catindexof{\atomenumerator}]}$ or $\legcoreof{\atomenumerator,\decindex}=\ones$.
        \begin{align*}
            \legcoreofat{\atomenumerator}{\catvariableof{\atomenumerator},\indexeddecvariable}
            \in\{\onehotmapofat{\catindexof{\atomenumerator}}{\catvariableof{\atomenumerator}} \wcols \catindexof{\atomenumerator}\in[\catdimof{\atomenumerator}] \} \cup \{\onesat{\catvariableof{\atomenumerator}}\}\, .
        \end{align*}
    \end{itemize}
    We denote by $\cprankof{\hypercore}$, respectively $\bincprankof{\hypercore}$, $\bascprankof{\hypercore}$ and $\baspluscprankof{\hypercore}$ the minimal cardinality such that $\hypercore$ has a $\cpformat$ Decomposition, respectively with directed cores, boolean cores, basis cores and basis+ cores.
\end{definition}

%To see that all ranks are finite, we can easily
All ranks have a naive bound by the space dimension, which is obvious from the coordinate decomposition (see \charef{cha:coordinateCalculus})
\begin{align*}
    \hypercorewith
    = \sum_{\shortcatindices\in\facstates} \hypercoreat{\indexedshortcatvariables} \cdot \bigotimes_{\catenumeratorin} \onehotmapofat{\catenumerator}{\catvariableof{\catenumerator}} \, .
\end{align*}
If we construct $\decindex$ as an enumeration of the coordinates in $\facstates$, that is $\decdim=\prod_{\catenumeratorin}\catdimof{\catenumerator}$, this is a $\cpformat$ decomposition, which is basis and therefore also directed, boolean and basis+.

%
$\cpformat$ decomposition as a tensor network format come with some drawbacks.
The set of tensors with a fixed rank are not closed \cite{beylkin_algorithms_2005} and approximation problems are often ill posed \cite{de_silva_tensor_2008}.
Since as a consequence their numerical treatment comes with many problems \cite{espig_variational_2012}, alternative formats have gained popularity.
Common formats are the $\mathrm{TUCKER}$-format originally introduced in \cite{hitchcock_expression_1927}, and often refered to as higher-order singular value decomposition, and the more recently developed $\ttformat$ and $\htformat$ decomposition formats (see \charef{cha:introduction}).
Given a $\htformat$ the best approximation of a tensor always exists (Theorem 11.58 in \cite{hackbusch_tensor_2012}).

%% Sum of elementary tensors
%We have by definition
%	\[ \hypercorewith
%	= \sum_{\decindexin} \scalarcoreat{\inddecvar} \left( \bigotimes_{\atomenumeratorin} \legcoreofat{\atomenumerator}{\catvariableof{\atomenumerator},\indexeddecvariable} \right) \, . \]
%The right side can be seen as an alternative definition of $\cpformat$ decompositions by summations of elementary tensors.


\begin{figure}[h]
    \begin{center}
        \input{PartIII/tikz_pics/sparse_calculus/cp_decomposition.tex}
    \end{center}
    \caption{Tensor Network diagram of a generic $\cpformat$ decomposition (see \defref{def:cpFormats})}
\end{figure}

%We introduce different notions of sparsities based on $\cpformat$ decomposition with different properties of their leg cores.

\subsect{Directed Leg Cores}

The contraint of directionality of the leg cores does not influence decomposablitiy of a tensor, as we show next.

\begin{lemma}
    \label{lem:cprankEqualsDir}
    For any tensor $\hypercorewith$ we have
    \begin{align*}
        \cprankof{\hypercore} = \dircprankof{\hypercore} \, .
    \end{align*}
\end{lemma}
\begin{proof}
    Let there be a $\cpformat$ decomposition of $\hypercore$ by
    \begin{align*}
        \hypercorewith
        = \contractionof{
            \{\scalarcoreat{\decvariable}\} \cup \{ \legcoreofat{\atomenumerator}{\catvariableof{\atomenumerator},\decvariable} \, : \, \atomenumeratorin \}
        }{\shortcatvariables} \, .
    \end{align*}
    We then transform the scalar core to another core $\tilde{\scalarcore}[\decvariable]$ with coordinates to $\decindexin$ by
    \begin{align*}
        \tilde{\scalarcore}[\indexeddecvariable]
        = \scalarcoreat{\indexeddecvariable} \cdot \prod_{\catenumeratorin} \contraction{\legcoreofat{\atomenumerator}{\catvariableof{\atomenumerator},\indexeddecvariable}} \, .
    \end{align*}
    It follows for any $\decindexin$, that
    \begin{align*}
        \scalarcoreat{\indexeddecvariable} \cdot \bigotimes_{\catenumeratorin}\legcoreofat{\catenumerator}{\catvariableof{\catenumerator},\indexeddecvariable}
        = \tilde{\scalarcore}[\indexeddecvariable] \cdot \bigotimes_{\catenumeratorin}\normalizationof{\legcoreofat{\catenumerator}{\catvariableof{\catenumerator},\indexeddecvariable}}{\catvariableof{\catenumerator}}
    \end{align*}
    and thus
    \begin{align*}
        \hypercorewith
        = \contractionof{
            \{\tilde{\scalarcore}[\decvariable] \cup \{ \normalizationof{\legcoreofat{\atomenumerator}{\catvariableof{\atomenumerator},\decvariable}}{\catvariableof{\atomenumerator},\decvariable} \, : \, \atomenumeratorin \}
        }{\shortcatvariables} \, .
    \end{align*}
    We have thus constructed a directed $\cpformat$ decomposition of same size $\decdim$ to an arbitrary $\cpformat$ decomposition and conclude that $\cprankof{\hypercore} = \dircprankof{\hypercore}$.
\end{proof}

%This is the canonical $\cpformat$ decomposition, where the vectors $\legcoreof{\atomenumerator,\decindex}$ are interpreted as generalized singular vectors.
%Any $\cpformat$ decomposition can be transformed into a directed $\cpformat$ decomposition without enlarging the index set $\indexset$, simply by diving the vectors by their norms and multiplying it to $\scalarcoreat{\inddecvar}$.

%% Directionality
%We then have a partially directed Tensor Network representing the decomposed tensor.
%The only undirected core is $\scalarcore$, since we do not demand it to be normed.
%In many applications applications, however, also the $\scalarcore$ is directed with a single outgoing leg (see for example the empirical distributions as discussed in \secref{sec:empDistribution}).
%In that case, also the decomposed tensor is directed with outgoing legs.



\subsect{Basis $\cpformat$ decompositions and the $\ell_0$-norm}\label{sec:basisCP}

% From FOL Chapter: Bayesian Network interpretation of Basis CP
%	The basis CP can further be understood as a Bayesian network, where we understand $\datindex$ as condition and each decomposition core as a conditional probability distribution.
%	We notice that in this interpretation the direction of the dependency is inversed compared with previous representation of grounding tensors in Figure~\ref{fig:groundingCP}. 


The slices of directed and boolean tensors with respect to incoming variables are basis tensors.
We have thus called $\cpformat$ decomposition with the restiction of directed an boolean leg vectors basis $\cpformat$ decomposition.
Based on this intuition, we can interpret basis $\cpformat$ decomposition by mappings to non-vanishing coordinates of the decomposed tensor.
To start, let us define the number of nonzero coordinates of tensors by the $\ell_0$-norm.

\begin{definition}
    The $\ell_0$-norm counts the nonzero coordinates of a tensor by
    \begin{align*}
        \sparsityof{\hypercore} = \#\big\{ \catindices \, : \, \hypercore_{\catindices }\neq 0 \big\} \, .
    \end{align*}
\end{definition}

The $\ell_0$-norm is not a norm, but at each tensor the limit of $\ell_p$-norms (which are norms for $p\geq1$) for $p \rightarrow 0$.

%%%%%%%%%%%%%%%%%%

% Interpretation
The $\ell_0$ norm is the number of non-vanishing coordinates of a tensor.
We understand the leg cores as the basis encoding of functions mapping to the slices of these coordinates given an enumeration.
This is consistent with the previous analysis of \charef{cha:basisCalculus}, where we characterized boolean and directed cores by the encoding of associated functions.
Based on this idea, we can proof, that any tensor has a directed and boolean $\cpformat$ decomposition with rand $\sparsityof{\hypercore}$.


\begin{theorem}
    \label{the:sparseBasisCP}
    For any tensor $\hypercorewith$ we have
    \begin{align*}
        \bascprankof{\hypercore} = \sparsityof{\hypercore} \, .
    \end{align*}
\end{theorem}
\begin{proof}
    Let us first show, that $\bascprankof{\hypercore} \leq \sparsityof{\hypercore}$.
    We find a map
    \begin{align*}
        \datamap : [\sparsityof{\hypercore}] \rightarrow  \facstates
    \end{align*}
    which image is the set of non-vanishing coordinates of $\hypercorewith$.
    Denoting its image coordinate maps by $\datamapof{\catenumerator}$ we have
    \begin{align*}
        \hypercorewith
        = \sum_{\datindexin} \scalarcoreat{\datamapat(\datindex)} \left(\bigotimes_{\atomenumeratorin} \onehotmapofat{\datamapof{\atomenumerator}(\datindex)}{\catvariableof{\catenumerator}} \right) \, .
    \end{align*}
    This is a basis $\cpformat$ decomposition of size $\sparsityof{\hypercore}$ and we thus have $\bascprankof{\hypercore}\leq\sparsityof{\hypercore}$.

    Conversely, let us show $\bascprankof{\hypercore} \geq \sparsityof{\hypercore}$.
    Any basis $\cpformat$ decomposition of $\hypercore$ with size $r$ would has at most $r$ coordinates different from zero and thus $\sparsityof{\hypercore}\leq r$.
    Thus, there cannot be a $\cpformat$ decomposition with a dimension $r\leq\sparsityof{\hypercore}$.
\end{proof}

%
The next theorem relates the basis $\cpformat$ decomposition with encodings of $\atomorder$-ary relations (see \defref{def:daryRelation}).

\begin{theorem}
    Any boolean tensor $ \hypercorewithin$ is the encoding of a $\atomorder$-ary relation $\exrelation\subset\facstates$ with cardinality
    \begin{align*}
        \cardof{\exrelation} = \bascprankof{\hypercore} \, .
    \end{align*}
\end{theorem}
\begin{proof}
    We fine a basis $\cpformat$ decomposition of $\hypercorewith$ with $\decdim=\bascprankof{\hypercore}$.
    Since $\hypercorewith$ is boolean, and since each $\decindex$ labels a disjoint non-vanishing coordinate (see proof of \theref{the:sparseBasisCP}), the decomposition has a trivial scalar core $\scalarcoreat{\decvariable}=\onesat{\decvariable}$.
    It follows, that
    \begin{align*}
        \hypercorewith = \sum_{\decindexin} \left(\bigotimes_{\catenumeratorin}\legcoreofat{\catenumerator}{\catvariableof{\catenumerator},\indexeddecvariable}\right)
    \end{align*}
    Since the $\cpformat$ decomposition is basis, the slice $\legcoreofat{\catenumerator}{\catvariableof{\catenumerator},\indexeddecvariable}$ is for any $\catenumeratorin$ and $\decindexin$ a basis vector.
    We then define
    \begin{align*}
        \catindexof{\catenumerator}^{\decindex} = \invonehotmapof{\legcoreofat{\catenumerator}{\catvariableof{\catenumerator},\indexeddecvariable}}
    \end{align*}
    and notice, that for the relation
    \begin{align*}
        \exrelation = \{ \shortcatindices^{\decindex}  \, : \, \decindexin\} \subset \facstates \,
    \end{align*}
    we have
    \begin{align*}
        \onehotmapofat{\exrelation}{\shortcatvariables} = \sum_{\decindexin} \left(\bigotimes_{\catenumeratorin}\legcoreofat{\catenumerator}{\catvariableof{\catenumerator},\indexeddecvariable}\right) \, .
    \end{align*}
    This coincides with the above $\cpformat$ decomposition of $\hypercorewith$ and the claim is established.
\end{proof}



\begin{remark}[Matrix Storage of basis $\cpformat$ decompositions]
    \label{rem:matStorageBas}
    % Storage
    The storage demand of any $\cpformat$ decomposition is at most linear in the size and the sum of its leg dimension.
    When we have a basis $\cpformat$ decomposition, this demand can be further improved.
    The basis vectors can be stored by its preimage of the one hot encoding $\onehotmapof{\cdot}$, that is the number of the basis vector in $[\catdim]$.
    This reduces the storage demand of each basis vector to the logarithms of the space dimension without the need of storing the full vector.
% Matrix Representation
    More precisely, we can define a leg selecting variable $\selvariable$ taking values in $[\catorder+1]$ and store a basis $\cpformat$ decomposition of size $\decdim$ by the matrix
    \begin{align*}
        \matrixat{\decvariable,\selvariable} \in \rr^{\datanum \times (\atomorder+1)}
    \end{align*}
    defined for $\decindexin$ and $\atomenumeratorin$ by
    \begin{align*}
        \matrixat{\inddecvar,\selvariable=\atomenumerator} =
        \begin{cases}
            \scalarcoreat{\inddecvar} & \text{if} \quad \atomenumerator = \catorder \\
            \invonehotmapof{\legcoreofat{\atomenumerator}{\catvariableof{\atomenumerator},\indexeddecvariable}} & \text{else} \\% \quad \atomenumerator < \catorder \\
        \end{cases} \, .
    \end{align*}
    This is a common trick to store relational databases.
\end{remark}


\subsect{Basis+ $\cpformat$ decompositions and polynomials}

The basis+ $\cpformat$ decompositions are closely related to monomial decompositions of a tensor, which we will define next.

\begin{definition}
    \label{def:polynomialSparsity}
    A monomial decomposition of a tensor $ \hypercorewithin$ is a set $\sliceset$ of tuples $\slicetupleof{}$ where $\slicescalar\in\rr, \variableset\subset[\atomorder]$ and $\catindexof{\variableset}\in\bigtimes_{\atomenumerator\in\variableset} [\catdimof{\atomenumerator}]$ such that
    \begin{align}
        \label{eq:decIntoMonomials}
        \hypercorewith
        = \sum_{\slicetupleof{}\in\sliceset} \slicescalar \cdot \contractionof{\onehotmapofat{\catindexof{\variableset}}{\catvariableof{\variableset}}}{\shortcatvariables} \, .
    \end{align}
    For any tensor $ \hypercorewithin$ we define its polynomial sparsity of order $\sliceorder$ as
    \begin{align*}
        \slicerankwrtof{\sliceorder}{\hypercore} =
        \min \left\{ \cardof{\sliceset} \, : \,
        \hypercorewith = \sum_{\slicetupleof{}\in\sliceset} \slicescalar \cdot \contractionof{\onehotmapofat{\catindexof{\variableset}}{\catvariableof{\variableset}}}{\shortcatvariables} \, , \, \forall_{\slicetupleof{}\in\sliceset} \cardof{\variableset} \leq \sliceorder \, .
        \right\}
    \end{align*}
\end{definition}


% Explanation of monomials
We refer to the terms in a decomposition \eqref{eq:decIntoMonomials} in \defref{def:polynomialSparsity} as monomials of boolean features, which are enumerated by pairs $(\atomenumerator,\catindexof{\atomenumerator})$ and indicate whether the variable $\catvariableof{\atomenumerator}$ is in state $\catindexof{\atomenumerator}\in[\catdimof{\atomenumerator}]$.
Each such boolean features is represented by the indicator
\begin{align*}
    \indicatorofat{\indexedcatvariableof{\atomenumerator}}{\catvariableof{\atomenumerator}} =
    \onehotmapofat{\catindexof{\atomenumerator}}{\catvariableof{\atomenumerator}} \, .
\end{align*}
The monomial of multiple such boolean features indicates, whether all variables labelled by a set $\variableset$ are in the state $\catvariableof{\variableset}$.
We have
\begin{align*}
    \indicatorofat{\forall{\atomenumerator\in\variableset}: \, \indexedcatvariableof{\atomenumerator}}{\catvariableof{\variableset}}
    = \onehotmapofat{\catindexof{\variableset}}{\catvariableof{\variableset}} = \bigotimes_{\atomenumerator\in\variableset} \onehotmapofat{\catindexof{\atomenumerator}}{\catvariableof{\atomenumerator}}  \, .
\end{align*}
The states of the variables labeled by $\atomenumerator\in[\atomorder]/\variableset$ are not specified in the monomial and the indicators are trivially extended to
\begin{align*}
    \contractionof{\onehotmapofat{\catindexof{\variableset}}{\catvariableof{\variableset}}}{\shortcatvariables}
    = \onehotmapofat{\catindexof{\variableset}}{\catvariableof{\variableset}} \otimes \onesat{\catvariableof{[\atomorder]/\variableset}} \, .
\end{align*}
Since we are working with boolean features, there is no need to consider higher-order powers of individual features, since for any $n\in\nn, \, n\geq1$ and any boolean value $z\in\ozset$ we have $z^n=z$.

% Infinity
For some monomial orders $\sliceorder<\catorder$ there are tensors $\hypercorewith$, which do not have a monomial decomposition of order $\sliceorder$.
In that case the minimum is over an empty set and we define $\slicerankwrtof{\sliceorder}{\hypercore}=\infty$.
We characterize in the next theorem the set of tensors with monomial decompositions of order $\sliceorder$.

\begin{theorem}
    \label{the:polynomialSubspaces}
    For any $\atomorder, \sliceorder$, the set of tensors of $\catorder$ variables with leg dimension $\catdim$, which have a monomial decomposition of order $\sliceorder$, is a linear subspace $\subspaceof{\atomorder,\sliceorder}$ with dimension
    \begin{align*}
        \subspacedimof{\subspaceof{\atomorder,\sliceorder}} \leq  \sum_{s \in [\sliceorder]} \catdim^s \binom{\catorder}{s} \, .
    \end{align*}
\end{theorem}
\begin{proof}
    The set of tensors admitting a monomial decomposition of order $\sliceorder$ is closed under addition and scalar multiplication.
    Specifically, the sum of two such tensors retains a monomial decomposition, formed by concatenating their respective decompositions.
    Scalar multiplication can be performed by a rescaling of each scalar $\slicescalar$ and therefore preserves the decomposition structure.
    Hence, these tensors form a linear subspace.

%    Any sum of tensors with a monomial decomposition of order $\sliceorder$ admits again a monomial decomposition, which is the concatenation of both.
%    The same holds for a scalar multiplication, and thus, the sets of such tensors form a linear subspace.

    To bound the dimension of this subspace, we consider tensors of the form $\contractionof{\onehotmapof{\catindexof{\variableset}}}{\shortcatvariables}$.
    The number of such tensors is given by
    \begin{align*}
        \sum_{s \in [\sliceorder]} \catdim^s \binom{\catorder}{s}  \, .
    \end{align*}
    Since any tensor with a monomial decomposition is a weighted sum of those, this provides an upper bound on the dimension.

    We notice, that the set of slices is in general not linear independent, and therefore forms a frame instead of a linear basis \cite{casazza_introduction_2013}.
    The number of elements in the frame is therefore in general a loose upper bound on the dimension.
\end{proof}


% Infinite rank
\theref{the:polynomialSubspaces} states, that the tensors admitting a monomial decomposition of a small order build a low-dimensional subspace in the $\catdim^\catorder$ dimensional space of tensors, since for $\sliceorder << \catorder $ we have
\begin{align*}
    \subspacedimof{\subspaceof{\atomorder,\sliceorder}} << \catdim^{\catorder} \, .
\end{align*}
If $\sliceorder\geq\catorder$, we always find a monomial decomposition by an enumeration of nonzero coordinates.
In the next theorem, we show that in that case the $\slicerankwrtof{\sliceorder}{\hypercore}$ furthermore coincides with the basis+ $\cpformat$ rank $\baspluscprankof{\hypercore}$.

\begin{theorem}
    For any tensor $\hypercorewithin$ we have
    \begin{align*}
        \polsparsityof{\hypercore} = \baspluscprankof{\hypercore} \, .
    \end{align*}
    In case of two-dimensional legs, that is $\catdimof{\atomenumerator}=2$ for all $\atomenumeratorin$, we also have
    \begin{align*}
        \bincprankof{\hypercore} = \polsparsityof{\hypercore}  \, .
    \end{align*}
\end{theorem}
\begin{proof}
    To proof the first claim, we construct a basis+ $\cpformat$ decomposition given a monomial decomposition and vice versa.
    To show $\polsparsityof{\hypercore} \geq \baspluscprankof{\hypercore}$, let there be an arbitrary tensor $\hypercorewith$ with a monomial decomposition by $\sliceset$ with $\cardof{\sliceset}=m$ and let us enumerate the elements in $\sliceset$ by $\slicetupleof{\decindex}$ for $\decindexin$.
    We define for each $\atomenumeratorin$ the tensors
    \begin{align*}
        \legcoreofat{\atomenumerator}{\decvariable,\catvariableof{\atomenumerator}}
        = \left( \sum_{\decindexin \, : \, \atomenumerator\in\variableset} \onehotmapofat{\decindex}{\decvariable} \otimes \onehotmapofat{\catindexof{\atomenumerator}^{\decindex}}{\catvariableof{\atomenumerator}} \right)
        + \left(\sum_{\decindexin \, : \, \atomenumerator\notin\variableset} \onehotmapofat{\decindex}{\decvariable} \otimes \onesat{\catvariableof{\atomenumerator}} \right)
    \end{align*}
    and
    \begin{align*}
        \scalarcoreat{\decvariable} = \sum_{\decindexin} \slicescalar^{\decindex} \cdot \onehotmapofat{\decindex}{\decvariable}
    \end{align*}
    and notice that
    \begin{align*}
        \hypercorewith
        & = \sum_{\decindexin} \slicescalar^{\decindex} \cdot \contractionof{\onehotmapof{\catindexof{\variableset}^{\decindex}}}{\shortcatvariables} \\
        & = \sum_{\decindexin} \left(  \scalarcoreat{\inddecvar} \cdot \bigotimes_{\atomenumeratorin} \legcoreofat{\atomenumerator}{\inddecvar, \catvariableof{\atomenumerator}} \right) \\
        & = \contractionof{
            \{\scalarcoreat{\decvariable}\} \cup \{\legcoreofat{\atomenumerator}{\decvariable,\catvariableof{\atomenumerator}} \, : \, \atomenumeratorin \}
        }{\shortcatvariables} \, .
    \end{align*}
    By construction this is a basis+ $\cpformat$ decomposition with rank $\decdim$.
    Since any monomial decomposition can be transformed into a basis+ $\cpformat$ decomposition with same rank we have
    \begin{align*}
        \polsparsityof{\hypercore} \geq \baspluscprankof{\hypercore} \, .
    \end{align*}

    To show $\polsparsityof{\hypercore} \leq \baspluscprankof{\hypercore}$, let there now be a basis+ $\cpformat$ decomposition of an arbitrary $\hypercorewith$.
    We define for each $\decindexin$
    \begin{align*}
        \variableset^{\decindex} = \{\atomenumeratorin : \legcoreofat{\atomenumerator}{\inddecvar, \catvariableof{\atomenumerator}} \neq \onesat{\catvariableof{\atomenumerator}} \}
        \quad \text{and} \quad
        \catindexof{\variableset}^{\decindex} = \{\invonehotmapof{\legcoreofat{\atomenumerator}{\inddecvar, \catvariableof{\atomenumerator}} } \, : \atomenumerator\in\variableset\}
    \end{align*}
    where by $\invonehotmapof{\cdot}$ we denote the inverse of the one-hot encoding.

    We notice that this is a monomial decomposition of $\hypercorewith$ to the tuple set
    \begin{align*}
        \sliceset = \{(\scalarcoreat{\inddecvar}, \variableset^{\decindex}, \catindexof{\variableset^{\decindex}}^{\decindex} ) \, : \, \decindexin \} \, .
    \end{align*}
    It follows from this that
    \begin{align*}
        \polsparsityof{\hypercore} \leq \baspluscprankof{\hypercore} \,
    \end{align*}
    and the first claim is shown.

    The second claim follows from the observation, that the set of non-vanishing boolean vectors coincides with the set of one-hot encodings extended by the trivial vector.
    Thus, a $\cpformat$ decomposition with non-vanishing slices is boolean if and only if it is basis+.
    This establishes, that both ranks are equal, since a $\cpformat$ decomposition of minimal rank cannot contain non-vanishing slices.
\end{proof}

\begin{remark}[Sparse representation of propositional formulas]
    When all leg dimensions of a boolean tensor $\hypercore$ are $2$, we can further interpret $\hypercore$ as a logical formula.
    We can use the boolean $\cpformat$ decomposition of any tensor $\sechypercore$ with $\nonzeroof{\sechypercore}=\hypercore$ as a CNF of $\hypercore$.
    Finding the sparsest CNF thus amounts to finding the $\sechypercore$ with minimal $\polsparsityof{\sechypercore}$ such that $\nonzeroof{\sechypercore}=\hypercore$.
\end{remark}

\begin{remark}[Matrix Storage of basis+ $\cpformat$ decompositions]
    \label{rem:matStorageBasPlus}
    We can adapt the storage format of \remref{rem:matStorageBas} from basis to basis+ $\cpformat$ decompositions.
    To this end, let there be a basis+ $\cpformat$ decomposition of a tensor with scalar core $\scalarcoreat{\decvariable}$ and leg cores $\{\legcoreofat{\atomenumerator}{\catvariableof{\atomenumerator},\decvariable} \, : \, \atomenumeratorin\}$.
    We use a value $z\in\rr/\imageof{\scalarcore}$ distinguished from the coordinates of the scalar core and define a matrix
    \begin{align*}
        \matrixofat{z}{\decvariable,\selvariable} \,
    \end{align*}
    where $\selvariable$ takes values in $[\catorder]$, coordinatewise as
    \begin{align*}
        \matrixofat{z}{\inddecvar,\selvariable=\atomenumerator} =
        \begin{cases}
            \scalarcoreat{\inddecvar} & \text{if} \quad \atomenumerator = \catorder \\
            z & \text{if} \quad \legcoreofat{\atomenumerator}{\catvariableof{\atomenumerator},\indexeddecvariable} = \onesat{\catvariableof{\atomenumerator}} \\
            \invonehotmapof{\legcoreofat{\atomenumerator}{\catvariableof{\atomenumerator},\indexeddecvariable}} & \text{else}
        \end{cases} \, .
    \end{align*}
\end{remark}



\sect{Constructive Bounds on CP Ranks}

After having defined different $\cpformat$ decompositions, let us investigate bounds on their ranks, which proofs rely on explicit core constructions.


\subsect{Cascade of ranks}

%% ? Case of boolean legs
%Especially useful, when the leg dimensions are two, where the slice decomposition shows decomposition of the tensor into monomials.

We start by showing a cascade of bounds of $\cpformat$ ranks, when demanding different leg restrictions as in \defref{def:cpFormats}.

\begin{theorem}
    \label{the:rankCascade}
    For any tensor $\hypercorewithin$ we have
    \begin{align*}
        \cprankof{\hypercore} = \dircprankof{\hypercore} \leq \bincprankof{\hypercore} \leq \baspluscprankof{\hypercore} \leq \bascprankof{\hypercore} \, .
    \end{align*}
\end{theorem}
\begin{proof}
    The equality $\cprankof{\hypercore} = \dircprankof{\hypercore}$ has been established in \lemref{lem:cprankEqualsDir}.
    The further inequalities follow by consecutive subset relations of the set of allowed leg slices in the respective $\cpformat$ decompositions.
    These imply, that any basis $\cpformat$ decomposition of a tensor $\hypercorewith$ is also a basis+ $\cpformat$ decomposition, further that any basis+ $\cpformat$ decomposition is also a boolean $\cpformat$ decomposition and that any boolean $\cpformat$ decomposition is trivially an unrestricted $\cpformat$ decomposition.
    Thus, the ranks are minima of enlarging sets and the claimed rank cascade is established.
\end{proof}

%% Tightness of the Bounds
Let us notice, that the stated bounds are not tight in general.
To give an example, let us consider the tensor $\hypercorewith=\oneswith$, for which we have
\begin{align*}
    \bascprankof{\hypercore} = \sparsityof{\hypercore} = \prod_{\catenumeratorin}\catdimof{\catenumerator} \, .
\end{align*}
Since in the other restricted $\cpformat$ formats we can choose trivial slices to the leg cores, we have
\begin{align*}
    \baspluscprankof{\hypercore} = 1 = \bincprankof{\hypercore} = \dircprankof{\hypercore} = \cprankof{\hypercore} \, .
\end{align*}
The trivial tensor serves thus as an example, where the demand of the the storage format in \remref{rem:matStorageBas} has an exponential overhead compared to the storage format in \remref{rem:matStorageBasPlus}.


\subsect{Operations on $\cpformat$ decompositions}

When using $\cpformat$ decompositons of tensors in practicle applications, such as those investigated in \parref{par:one} and \parref{par:two}, we have to perform numerical manipulations in the form of summations, contractions and normalizations of the represented tensors.
Let us here investigate, how these operations influence the decomposition.

\subsubsect{Summation}

We start with the sum of tensors in a $\cpformat$ decomposition, which can be captured by a concatenation of the slices.

\begin{theorem}
    \label{the:CPrankSumBound}
    For any collections of tensors $\{\hypercoreofat{\selindex}{\catvariableof{\nodes}} : \selindexin\}$ with identical variables and scalars $\lambda^{\selindex} \in \rr$ for $\selindexin$ we have
    \begin{align*}
        \cprankof{\sum_{\selindexin} \lambda^{\selindex} \cdot \hypercoreof{\selindex}} \leq \sum_{\selindexin} \cprankof{\hypercoreof{\selindex}}  \, .
    \end{align*}
    The bound still holds, when we replace on both sides $\cprankof{\cdot}$ by $\bincprankof{\cdot}$, by $\bascprankof{\cdot}$ or by $\baspluscprankof{\cdot}$.
\end{theorem}
\begin{proof}
    Products with scalars do not change the rank, since they just rescale the core $\scalarcore$.
    The sum of $\cpformat$ decomposition is just the combination of all slices, thus the rank is at most additive.
\end{proof}

% Loose upper bounds
Let us notice, that the upper bound is loose in many applications.
For example, if two slice tuples of two decomposed tensors agree on $\catindexof{\variableset},\variableset$, then their sum can be performed by a sum of the corresponding scalar.

%%%%%%%%%%
% 20.3. noon
%%%%%%%%%%

\subsubsect{Contraction}

We continue to show rank bounds for arbitrary contractions by the product of the ranks of contracted tensors.

\begin{theorem}
    \label{the:CPrankContractionBound}
    For any tensor network $\extnetat{\catvariableof{\nodes}}$ on a graph $\graph=(\nodes,\edges)$, we have for any subset $\secnodes\subset\nodes$
    \begin{align*}
        \cprankof{\contractionof{\extnet}{\catvariableof{\secnodes}}} \leq
        \prod_{\edge\in\edges \, : \, \secnodes\cap\edge \neq \varnothing} \cprankof{\hypercoreof{\edge}} \, .
    \end{align*}
    The bound still holds, when we replace on both sides $\cprankof{\cdot}$ by $\bincprankof{\cdot}$, by $\bascprankof{\cdot}$ or by $\baspluscprankof{\cdot}$.
\end{theorem}

Remarkably, in \theref{the:CPrankContractionBound} the upper bound on the CP rank is build only by the ranks of the tensor cores, which have remaining open edges.
We prepare for its proof by first showing the following lemmata.

\begin{lemma}
    \label{lem:sparsityGeneralContraction}
    For any tensors $\hypercoreofat{1}{\catvariableof{\nodesone}}$ and $\hypercoreofat{2}{\catvariableof{\nodestwo}}$ and any set of variables $\secnodes\subset\nodesone\cup\nodestwo$ we have
    \begin{align*}
        \cprankof{\contractionof{\hypercoreof{1},\hypercoreof{2}}{\catvariableof{\secnodes}}} \leq \cprankof{\hypercoreof{1}} \cdot \cprankof{\hypercoreof{2}} \, .
    \end{align*}
    The bound still holds, when we replace on both sides $\cprankof{\cdot}$ by $\bincprankof{\cdot}$, by $\bascprankof{\cdot}$ or by $\baspluscprankof{\cdot}$.
\end{lemma}
\begin{proof}
    Let there be $\cpformat$ decompositions of $\hypercoreofat{1}{\catvariableof{\nodesone}}$ and $\hypercoreofat{2}{\catvariableof{\nodestwo}}$ by
    \begin{align*}
        \hypercoreofat{1}{\catvariableof{\nodesone}}
        = \contractionof{\{\scalarcoreofat{1}{\decvariableof{1}}\}\cup\{\legcoreofat{1,\atomenumerator}{\catvariableof{\atomenumerator},\decvariableof{1}} \, : \, \atomenumerator\in\nodesone\}}{\catvariableof{\nodesone}}
    \end{align*}
    and
    \begin{align*}
        \hypercoreofat{2}{\catvariableof{\nodesone}}
        = \contractionof{\{\scalarcoreofat{2}{\decvariableof{2}}\}\cup\{\legcoreofat{2,\secatomenumerator}{\catvariableof{\secatomenumerator},\decvariableof{2}} \, : \, \secatomenumerator\in\nodestwo\}}{\catvariableof{\nodestwo}} \, .
    \end{align*}
    By linearity of contractions we have
    \begin{align*}
        \contractionof{\hypercoreof{1},\hypercoreof{2}}{\catvariableof{\secnodes}}
        &= \sum_{\decindexof{1}\in\decdimof{1}} \sum_{\decindexof{2}\in\decdimof{2}}
        \scalarcoreofat{1}{\indexeddecvariableof{1}} \cdot \scalarcoreofat{2}{\indexeddecvariableof{2}} \\
        & \quad\quad \cdot \contractionof{\{\legcoreofat{1,\atomenumerator}{\catvariableof{\atomenumerator},\indexeddecvariableof{1}} \, : \, \atomenumerator\in\nodesone\} \cup \{\legcoreofat{2,\secatomenumerator}{\catvariableof{\secatomenumerator},\indexeddecvariableof{2}} \, : \, \secatomenumerator\in\nodestwo\}}{\catvariableof{\secnodes}} \\
        &= \sum_{\decindexof{1}\in\decdimof{1}} \sum_{\decindexof{2}\in\decdimof{2}}
        \scalarcoreofat{1}{\indexeddecvariableof{1}} \cdot \scalarcoreofat{2}{\indexeddecvariableof{2}} \cdot \\
        & \quad\quad \contraction{\{\legcoreofat{1,\atomenumerator}{\catvariableof{\atomenumerator},\indexeddecvariableof{1}} \, : \, \atomenumerator\in\nodesone/\secnodes\} \cup \{\legcoreofat{2,\secatomenumerator}{\catvariableof{\secatomenumerator},\indexeddecvariableof{2}} \, : \, \secatomenumerator\in\nodestwo/\secnodes\}} \cdot \\
        & \quad\quad \bigotimes_{\atomenumerator\in\secnodes} \legcoreofat{\atomenumerator}{\catvariableof{\atomenumerator},\indexeddecvariableof{1},\indexeddecvariableof{2}} \, ,
    \end{align*}
    where we denote
    \begin{align*}
        \legcoreofat{\atomenumerator}{\catvariableof{\atomenumerator},\indexeddecvariableof{1},\indexeddecvariableof{2}}
        = \begin{cases}
              \legcoreofat{1,\atomenumerator}{\catvariableof{\atomenumerator},\indexeddecvariableof{1}}  & \text{if} \quad \atomenumerator \notin \nodestwo \\
              \legcoreofat{2,\atomenumerator}{\catvariableof{\atomenumerator},\indexeddecvariableof{2}}  & \text{if} \quad \atomenumerator \notin \nodesone \\
              \contractionof{\legcoreofat{1,\atomenumerator}{\catvariableof{\atomenumerator},\indexeddecvariableof{1}}, \legcoreofat{2,\atomenumerator}{\catvariableof{\atomenumerator},\indexeddecvariableof{2}}}{\catvariableof{\atomenumerator}}  & \text{else}
        \end{cases} \, .
    \end{align*}
    Note, that since $\atomenumerator\in\secnodes\subset\nodesone\cup\nodestwo$, these slices are well-defined.
    We build a new decomposition variable $\decvariable$ enumerating the summands to indices $[\decdimof{1}]\times[\decdimof{2}]$ and have thus found a $\cpformat$ decomposition of $\contractionof{\hypercoreof{1},\hypercoreof{2}}{\catvariableof{\secnodes}}$ of size $\decdim=\decdimof{1}\cdot\decdimof{2}$.
    This shows the claim in the case of $\cprankof{\cdot}$.

    When the $\cpformat$ decompositions of $\hypercoreof{1}$ and $\hypercoreof{2}$ are boolean, basis or basis+, then the property is preserved in the constructed $\cpformat$ decomposition, since the constructed slices $\legcoreofat{\atomenumerator}{\catvariableof{\atomenumerator},\indexeddecvariableof{1},\indexeddecvariableof{2}}$ are either copies of the leg cores or their contractions and the respective property is preserved in both cases.
    Thus, the constructive rank bounds hold also for $\bincprankof{\cdot}$, $\bascprankof{\cdot}$ and $\baspluscprankof{\cdot}$.
\end{proof}

When one core of the contracted tensor network does not contain variables which are left open, we can drastically sharpen the bound provided by \lemref{lem:sparsityGeneralContraction} as we show next.

\begin{lemma}
    \label{lem:sparsityDisjointContraction}
    For any two tensors $\hypercoreofat{1}{\catvariableof{\nodesone}}$, $\hypercoreofat{2}{\catvariableof{\nodestwo}}$ and any set $\secnodes$ with $\secnodes\cap\nodestwo=\varnothing$ we have
    \begin{align*}
        \cprankof{\contractionof{\hypercoreof{1},\hypercoreof{2}}{\catvariableof{\secnodes}}} \leq \cprankof{\hypercoreof{1}} \, .
    \end{align*}
    The bound still holds, when we replace on both sides $\cprankof{\cdot}$ by $\bincprankof{\cdot}$, by $\bascprankof{\cdot}$ or by $\baspluscprankof{\cdot}$.
\end{lemma}
\begin{proof}
    As in the proof of \lemref{lem:sparsityGeneralContraction} we assume a $\cpformat$ decomposition of $\hypercoreofat{1}{\catvariableof{\nodesone}}$ and $\hypercoreofat{2}{\catvariableof{\nodestwo}}$ and use the linearity of contractions to get
    \begin{align*}
        \contractionof{\hypercoreof{1},\hypercoreof{2}}{\catvariableof{\secnodes}}
        %&= \sum_{\decindexof{1}\in\decdimof{1}} \sum_{\decindexof{2}\in\decdimof{2}}
        %\scalarcoreofat{1}{\indexeddecvariableof{1}} \cdot \scalarcoreofat{2}{\indexeddecvariableof{2}} \\
        %& \quad\quad \cdot \contractionof{\{\legcoreofat{1,\atomenumerator}{\catvariableof{\atomenumerator},\indexeddecvariableof{1}} \, : \, \atomenumerator\in\nodesone\} \cup \{\legcoreofat{2,\secatomenumerator}{\catvariableof{\secatomenumerator},\indexeddecvariableof{2}} \, : \, \secatomenumerator\in\nodestwo\}}{\catvariableof{\secnodes}} \\
        &= \sum_{\decindexof{1}\in\decdimof{1}} \sum_{\decindexof{2}\in\decdimof{2}}
        \scalarcoreofat{1}{\indexeddecvariableof{1}} \cdot \scalarcoreofat{2}{\indexeddecvariableof{2}} \cdot \\
        & \quad\quad \contraction{\{\legcoreofat{1,\atomenumerator}{\catvariableof{\atomenumerator},\indexeddecvariableof{1}} \, : \, \atomenumerator\in\nodesone/\secnodes\} \cup \{\legcoreofat{2,\secatomenumerator}{\catvariableof{\secatomenumerator},\indexeddecvariableof{2}} \, : \, \secatomenumerator\in\nodestwo/\secnodes\}} \cdot \\
        & \quad\quad \bigotimes_{\atomenumerator\in\secnodes} \legcoreofat{1,\atomenumerator}{\catvariableof{\atomenumerator},\indexeddecvariableof{1}} \, ,
    \end{align*}
    where we used that $\secnodes\cup\nodestwo=\varnothing$.
    By rearranging the sum of $\decindexof{2}$, we have a $\cpformat$ decomposition with decomposition variable $\decvariableof{1}$ and slices
    \begin{align*}
        \scalarcoreat{\indexeddecvariableof{1}}
        & = \sum_{\decindexof{2}\in\decdimof{2}}  \scalarcoreofat{1}{\indexeddecvariableof{1}} \cdot \scalarcoreofat{2}{\indexeddecvariableof{2}} \cdot \\
        & \quad \quad \contraction{\{\legcoreofat{1,\atomenumerator}{\catvariableof{\atomenumerator},\indexeddecvariableof{1}} \, : \, \atomenumerator\in\nodesone/\secnodes\} \cup \{\legcoreofat{2,\secatomenumerator}{\catvariableof{\secatomenumerator},\indexeddecvariableof{2}} \, : \, \secatomenumerator\in\nodestwo/\secnodes\}} \, .
    \end{align*}
    This shows the rank bound for $\cprankof{\cdot}$.
    The properties of the $\cpformat$ decomposition are trivially inherited by the constructed decomposition, since the leg cores of the decomposition of $\hypercoreofat{1}{\catvariableof{\nodesone}}$ are chosen.
    Thus, the rank bounds hold also for any other rank in the claim.
%    We show the lemma by constructing a $\cpformat$ decomposition of $\cprankof{\contractionof{\{\hypercoreof{1},\hypercoreof{2}\}}{\catvariableof{\secnodes}}} $ for any $\cpformat$ decomposition of $\hypercoreof{1}$.
%    Let therefore take any $\cpformat$ decomposition of $\hypercoreof{1}$ consistent of the leg cores $\{\legcoreof{\node} \, : \, \node \in \nodesone \}$ and a scalar core $\scalarcore$.
%    Then we define a new $\scalarcore$ by
%    \[ \tilde{\scalarcore} = \contractionof{\{\scalarcore\}\cup \{\legcoreof{\node} \, : \, \node \in \nodesone , \node \notin \secnodes \} \cup \{\hypercoreof{2}\} }{\decvariable} \, . \]
%    Then, the leg cores $\{\legcoreof{\node} \, : \, \node \in \secnodes \}$ build with the scalar core $\tilde{\scalarcore}$ a $\cpformat$ decomposition of $\contractionof{\{\hypercoreof{1},\hypercoreof{2}\}}{\catvariableof{\secnodes}}$.
%% boolean of basis
%    When the $\cpformat$ decomposition of $\hypercoreof{1}$ was boolean, basis or basis+, this property is also satisfied by the constructed $\cpformat$ decomposition.
%    Thus the bound also holds for the ranks $\bincprankof{\cdot}$ or $\bascprankof{\cdot}$.
\end{proof}

\begin{proof}[Proof of \theref{the:CPrankContractionBound}]
    We partition the edges into the set $\edgesof{1}= \{\edge\in\edges \, : \, \edge\cup\secnodes\neq\varnothing\}$ and $\edgesof{2}= \{\edge\in\edges \, : \, \edge\cup\secnodes=\varnothing\}$.
    We then have
    \begin{align}
        \label{eq:cprankContractionPartition}
        \contractionof{\extnet}{\catvariableof{\secnodes}}
        = \contractionof{
            \contractionof{\{\hypercoreofat{\edge}{\catvariableof{\edge}} \, : \, \edge\in\edgesof{1}\}}{\catvariableof{\bigcup_{\edge\in\edgesof{1}}\edge}},
            \contractionof{\{\hypercoreofat{\edge}{\catvariableof{\edge}} \, : \, \edge\in\edgesof{2}\}}{\catvariableof{\bigcup_{\edge\in\edgesof{2}}\edge}}
        }{\catvariableof{\secnodes}}
    \end{align}
    By an iterative application of \lemref{lem:sparsityGeneralContraction} when including the cores to $\edge\in\edgesof{1}$ after each other to the contraction, we get the bound
    \begin{align*}
        \cprankof{\contractionof{\{\hypercoreofat{\edge}{\catvariableof{\edge}} \, : \, \edge\in\edgesof{1}\}}{\catvariableof{\bigcup_{\edge\in\edgesof{1}}\edge}}}
        \leq \prod_{\edge\in\edgesof{1}} \cprankof{\hypercoreof{\edge}} \, .
    \end{align*}
    With the decomposition \eqref{eq:cprankContractionPartition} and \lemref{lem:sparsityDisjointContraction} we then arrive at the claim
    \begin{align*}
        \contractionof{\extnet}{\catvariableof{\secnodes}} \leq \prod_{\edge\in\edgesof{1}} \cprankof{\hypercoreof{\edge}} \, .
    \end{align*}
    Since the applied lemmata hold also for the restricted $\cpformat$ ranks in the claim, the derived bound is also for those valid.
    %Use delta tensor representation to represent contractions by graphs.
    %We then iterate through the cores and contract them to the previously contracted tensor, where we apply \lemref{lem:sparsityGeneralContraction} when the tensor core has variables left open and \lemref{lem:sparsityDisjointContraction} if not.
\end{proof}


\begin{example}[Composition of formulas with connectives]
    For any formula $\exformula$ we have $1-\exformula$ = $\lnot\exformula$.
    The CP rank bound brings an increase by at most factor $2$ when taking the contraction with $\bencodingof{\lnot}$ which has polynomial sparsity of $2$.
    This is not optimal, since $\lnot\exformula$ has at most an absolute polynomial sparsity increase of $1$.

    For any formulas $\exformula$ and $\secexformula$ we have $\exformula\cdot\secexformula = \exformula\land\secexformula$.
    Here the $\cpformat$ rank bounds on contractions can also be further tightened.
\end{example}


\begin{example}[Distributions of independent variables]
    Independence means factorization, conditional independence means sum over factorizations.
    Again, the $\ell_0$ norm is bounded by the product of the $\ell_0$ norm of the factors.
\end{example}


%\subsect{normalizations}
%\red{As a theorem: If any of the above $\cpformat$ decomposition is normable, the normalization has the same CP ranks.
%Especially interesting when learning Bayesian Networks, where each core has a CP bound by the number of datapoints.}


\sect{Sparse Encoding of Functions}

%Using the proof idea of \theref{the:sparseBasisCP}, we can state a more general CP bound on the encoding of functions.

We now state that the basis CP rank of basis encodings is equal to the cardinality of the domain.
The basis CP format can therefore not provide a sparse representation when the factored system contains many categorical variables.

%\subsect{}

\begin{theorem}
    \label{the:bencodingBasCP}
    For any function
    \[ \exfunction : \facstates \rightarrow  \secfacstates \]
    between factored systems we have
    \[ \bascprankof{\bencodingof{\exfunction}} =  \facdim \, . \]
\end{theorem}
\begin{proof}
    The bound follows from \theref{the:sparseBasisCP}, using that $\sparsityof{\bencodingof{\exfunction}}=\facdim$.
\end{proof}

Let us further provide a construction scheme to find a basis $\cpformat$ decomposition of $\bencodingof{\exfunction}$ of size $\facdim$.
We notice that
\begin{align*}
    \bencodingofat{\exfunction}{\secshortcatvariables,\shortcatvariables}
    = \sum_{\shortcatindices\in\facstates} \onehotmapofat{\shortcatindices}{\shortcatvariables} \otimes \onehotmapofat{\exfunctionat{\indexedshortcatvariables}}{\secshortcatvariables} \, .
\end{align*}
We build for $\catenumeratorin$ decomposition variables $\decvariableof{[\atomorder]}$ with $\decdimof{\atomenumerator}=\catdimof{\atomenumerator}$ and define leg cores %a function $\indexinterpretation$ and define leg cores by
\begin{align*}
    \legcoreofat{\catenumerator}{\catvariableof{\catenumerator},\decvariableof{[\atomorder]}} = \identityat{\catvariableof{\catenumerator},\decvariableof{\atomenumerator}}
\end{align*}
and for $\seccatenumerator\in[\secatomorder]$ and $\decindexof{[\atomorder]}$
\begin{align*}
    \legcoreofat{\seccatenumerator}{\seccatvariableof{\seccatenumerator},\indexeddecvariableof{[\atomorder]}}
    = \onehotmapof{\exfunction_{\seccatenumerator}[\shortcatvariables=\decindexof{[\atomorder]}]}{\seccatvariableof{\seccatenumerator}} \, .
\end{align*}
We then have with a trivial scalar core
\begin{align*}
    \bencodingofat{\exfunction}{\secshortcatvariables,\shortcatvariables}
    = \contractionof{
        \{\onesat{\decvariableof{[\atomorder]}}\}\cup
        \{\legcoreofat{\catenumerator}{\catvariableof{\atomenumerator},\decvariableof{[\atomorder]}} \, : \, \catenumeratorin\} \cup
        \{\legcoreofat{\seccatenumerator}{\seccatvariableof{\seccatenumerator},\decvariableof{[\atomorder]}} \, : \, \seccatenumerator\in[\secatomorder]\}
    }{\secshortcatvariables,\shortcatvariables} \, .
\end{align*}
This is a basis $\cpformat$ decomposition of size $\facdim$.

% Extension by rank cascade
In combination with \theref{the:rankCascade}, \theref{the:bencodingBasCP} also provides bounds on all other $\cpformat$ ranks defined in \defref{def:cpFormats}.
This is obvious, since basis leg slices are the most restrictive properties compared with boolean, directed or basis+.


We restate \theref{the:functionImageDecompositionContraction} as a basis $\cpformat$ decomposition bound.

\begin{theorem}
    \label{the:functionDecompositionBasisCP}
    Let $\exfunction$ and be a function between factored systems
    \begin{align*}
        \exfunction : [\catdim] \rightarrow  \facstates
    \end{align*}
    and $\exfunctionof{\atomenumerator}$ as in \theref{the:functionImageDecompositionContraction}.
    Then $\bencodingofat{\exfunction}{\shortcatvariables,\catvariable}$ has a basis $\cpformat$ decomposition with decomposition index $\catvariable$, trivial slices $\onesat{\catvariable}$ leg vectors $\bencodingofat{\exfunctionof{\catenumerator}}{\catvariableof{\catenumerator},\catvariable}$, that is
    \begin{align*}
        \bencodingofat{\exfunction}{\catvariable,\shortcatvariables}
        = \contractionof{\{\onesat{\catvariable}\} \cup \{\bencodingofat{\exfunctionof{\catenumerator}}{\catvariableof{\catenumerator},\catvariable}\,:\,\catenumeratorin}{\shortcatvariables}
    \end{align*}
\end{theorem}
\begin{proof}
    The claimed decomposition directly follows from \theref{the:functionImageDecompositionContraction}, since the trivial scalar core $\scalarcoreat{\catvariable}=\onesat{\catvariable}$ does not influence the contraction and can be omitted.
%    We interpret the decompositon as a basis $\cpformat$ decomposition, after adding a trivial scalar core $\scalarcoreat{\catvariable}=\onesat{\catvariable}$ to the contraction.
\end{proof}

Basis $\cpformat$ decompositions can be constructed by understanding the variable $\indvariableof{\insymbol}$ of the basis encoding of a function $\exfunction:\inset \rightarrow \outset$ as the slice selection variable.

\begin{example}[Empirical distributions, see \theref{the:empCPRep}]
    \label{exa:empDistCP}
    Let there be a data map
    \begin{align*}
        \datamap : [\datanum] \rightarrow \facstates \, .
    \end{align*}
    We can use \theref{the:functionDecompositionBasisCP} to find a tensor network representation fo $\bencodingof{\datamap}$ as
    \begin{align*}
        \bencodingofat{\datamap}{\shortcatvariables,\datvariable}
        = \contractionof{
            \{\bencodingofat{\datamapof{\atomenumerator}}{\catvariableof{\atomenumerator},\datvariable} : \atomenumeratorin \}
        }{\shortcatvariables,\datvariable} \, .
    \end{align*}
    This representation is a basis $\cpformat$ decomposition, when adding trivial scalar core.
    This provides also a basis $\cpformat$ decomposition for the empirical distribution, since normalization can be done by setting a slice core to $\frac{1}{\datanum}\onesat{\datvariable}$.
\end{example}

\begin{example}{Exponential families}
    \label{exa:expFamCP}
    The statistic has a $\cpformat$ decomposition with rank by the cardinality of states, that is
    \begin{align*}
        \bencodingofat{\sstat}{\headvariables,\shortcatvariables}
        = \contractionof{
            \{ \bencodingofat{\sstatcoordinateof{\selindex}}{\headvariableof{\selindex},\shortcatvariables} \, : \, \selindexin \}
        }{\headvariables,\shortcatvariables} \, .
    \end{align*}
\end{example}

% Now a image central bound
While \theref{the:bencodingBasCP} and \theref{the:functionDecompositionBasisCP} provide $\cpformat$ rank bounds based on the domain factored system, we can also show in the next theorem a bound using the structure of the image.

\begin{theorem}
    Let $\exfunction : \inset \rightarrow \outset$ be an arbitrary function and let us consider for each $\exfunctionimageelement\in\imageof{\exfunction}$ the indicator
    \begin{align*}
        \onesofat{\exfunction=\exfunctionimageelement}{\indvariableof{\insymbol}} =
        \begin{cases}
            1 & \text{if} \quad \exfunctionat{\indexedindvariableof{\insymbol}}=y \\
            0 & \text{else} \, .
        \end{cases}
    \end{align*}
    The basis+ rank of the basis encoding of $\exfunction$ then obeys the bound
    \begin{align*}
        \cprankof{\bencodingof{\exfunction}} \leq \sum_{\exfunctionimageelement\in\imageof{\exfunction}} \cprankof{\onesof{\exfunction=\exfunctionimageelement} } \, .
    \end{align*}
    The bound still holds, when we replace on both sides $\cprankof{\cdot}$ by $\bincprankof{\cdot}$, by $\bascprankof{\cdot}$ or by $\baspluscprankof{\cdot}$.
\end{theorem}
\begin{proof}
    We have
    \begin{align*}
        \bencodingofat{\exfunction}{\indvariableof{\outsymbol},\indvariableof{\insymbol}}
        = \sum_{\exfunctionimageelement\in\imageof{\exfunction}} \onehotmapofat{\indexinterpretationat{\exfunctionimageelement}}{\indvariableof{\outsymbol}}
        \otimes \onesofat{\exfunction=\exfunctionimageelement}{\indvariableof{\insymbol}} \, .
    \end{align*}
    For any $\exfunctionimageelement\in\imageof{\exfunction}$ it is obvious that
    \begin{align*}
        \cprankof{\onehotmapofat{\indexinterpretationat{\exfunctionimageelement}}{\indvariableof{\outsymbol}}
        \otimes \onesofat{\exfunction=\exfunctionimageelement}{\indvariableof{\insymbol}}}
        = \cprankof{\onesofat{\exfunction=\exfunctionimageelement}{\indvariableof{\insymbol}}} \, ,
    \end{align*}
    which also holds true for the other bounds in the claim.
    We then use the summation bound of \theref{the:CPrankSumBound} to get
    \begin{align*}
        \cprankof{\bencodingofat{\exfunction}{\indvariableof{\outsymbol},\indvariableof{\insymbol}}}
        &\leq \sum_{\exfunctionimageelement\in\imageof{\exfunction}} \cprankof{\onehotmapofat{\indexinterpretationat{\exfunctionimageelement}}{\indvariableof{\outsymbol}}
        \otimes \onesofat{\exfunction=\exfunctionimageelement}{\indvariableof{\insymbol}}} \\
        &\leq  \sum_{\exfunctionimageelement\in\imageof{\exfunction}} \cprankof{\onesofat{\exfunction=\exfunctionimageelement}{\indvariableof{\insymbol}}} \, .
    \end{align*}
    Again, the bound still hold for the other ranks in the claim.
    % For each $\exfunctionimageelement\in\imageof{\exfunction}$ we represent $\onehotmapofat{\indexinterpretationat{\exfunctionimageelement}}{\headvariableof{\exfunction}}$ in an basis+ CP format with $\baspluscprankof{\onesof{\exfunction=\exfunctionimageelement} } $ summands and arrive at a basis+ $\cpformat$ decomposition of $\bencodingof{\exfunction}$ with $\sum_{\exfunctionimageelement\in\imageof{\exfunction}} \baspluscprankof{\onesof{\exfunction=\exfunctionimageelement} } $ summands.
\end{proof}

The above claim still holds when replacing $\baspluscprankof{\cdot}$ with the ranks $\bascprankof{\cdot}$ or $\bincprankof{\cdot}$.
For the rank $\bascprankof{\cdot}$ it leads to the bound of \theref{the:bencodingBasCP}, since summing the number of non zero coordinators of the indicators is the cardinality of the domain.

\begin{example}[Propositional formulas]
    Let us now illustrate how the above representation scheme can be leveraged for the sparse representation of propositional formulas.
    For an arbitrary propositional formula $\exformula$ we have $\imageof{\exformula}\subset\ozset$ and the indicators
    \begin{align*}
        \onesofat{\exformula=1}{\shortcatvariables} = \formulaat{\shortcatvariables} \quad \text{and} \quad
        \onesofat{\exformula=0}{\shortcatvariables} = \lnot\formulaat{\shortcatvariables} = \onesat{\shortcatvariables} - \formulaat{\shortcatvariables} \, .
    \end{align*}

    For the conjunction $\land[\catvariableof{0},\catvariableof{1}] = \catvariableof{0} \land \catvariableof{1}$ we have
    \begin{align*}
        \bencodingofat{\land}{\catvariableof{0},\catvariableof{1}}
        = \tbasisat{\headvariableof{\land}} \otimes \onehotmapofat{1,1}{\catvariableof{0},\catvariableof{1}}
        + \fbasisat{\headvariableof{\land}} \otimes (\onesat{\catvariableof{0},\catvariableof{1}} - \onehotmapofat{1,1}{\catvariableof{0},\catvariableof{1}})
    \end{align*}
    and thus
    \begin{align*}
        \baspluscprankof{\bencodingof{\land}} \leq 3
    \end{align*}
    while $\bascprankof{\bencodingof{\land}} = 4$.

    We can even generalize this observation to $\catorder$-ary conjunctions $\land\left[\shortcatvariables\right]=\catvariableof{0}\land\ldots\land\catvariableof{\catorder-1}$ (see \remref{rem:naryConnectives})
    \begin{align*}
    {\land}[\shortcatvariables]
        = \bigotimes_{\catenumeratorin} \tbasisat{\catvariableof{\catenumerator}}
        \quad \text{and} \quad
        {\lnot\land}[\shortcatvariables] = \onesat{\shortcatvariables} - \bigotimes_{\catenumeratorin} \tbasisat{\catvariableof{\catenumerator}}
    \end{align*}
    and thus
    \begin{align*}
        \bencodingofat{\land}{\shortcatvariables} =
        \tbasisat{\headvariableof{\land}} \otimes \left(\bigotimes_{\catenumeratorin} \tbasisat{\catvariableof{\catenumerator}}\right)
        + \fbasisat{\headvariableof{\land}} \otimes \left(\bigotimes_{\catenumeratorin} \tbasisat{\catvariableof{\catenumerator}}\right)
    \end{align*}
    Thus, while the basis $\cpformat$ rank is $\bascprankof{\bencodingof{\land}}=2^{\catorder}$, the basis+ rank is bounded by $3$, independently of $\catorder$.
\end{example}






\sect{Optimization of sparse tensors}

Let us now study the problem of searching for the maximal coordinate in a tensor represented by a monomial decomposition.
Given a tensor $\hypercorewith$ we state this as the problem:
\begin{align}
    \label{prob:maxCoordinate}\tag{$\probtagtypeinst{\mathrm{max}}{\hypercore}$}
    \argmax_{\shortcatindices\in\facstates} \hypercoreat{\indexedshortcatvariables}
\end{align}

\probref{prob:maxCoordinate} can be reformulated as optimization over the standard simplex
\begin{align*}
    \meansetof{\mlnmintermsymbol} = \convhullof{\onehotmapofat{\shortcatindices}{\shortcatvariables} \, : \, \shortcatindices\in\facstates}
\end{align*}
as
\begin{align*}
    \argmax_{\meanparamat{\selvariableof{[\catorder]}}\in\meansetof{\mlnmintermsymbol}} \contraction{\meanparam,\hypercore} \, .
\end{align*}

\begin{example}[Mode search in exponential families]
    % \red{This transforms the mean parameter polytope by contracting with some core, here the selection encoding of the statistic!}
    Given a statistic $\sstat$, a canonical parameter $\canparam$ and a boolean base measure $\basemeasure$, the mode search problem for the member $\expdistof{\sstat,\canparam,\basemeasure}$ of the exponential family $\expfamilyof{\sstat,\basemeasure}$ is
    \begin{align*}
        \max_{\shortcatindices\in\atomstates \, : \, \basemeasureat{\indexedshortcatvariables}=1} \contraction{\sencsstatat{\indexedshortcatvariables,\selvariable},\canparamat{\selvariable}}
        = \max_{\meanparam\in\meansetof{\sstat,\basemeasure}} \contraction{\meanparamat{\selvariable},\canparamat{\selvariable}} \, .
    \end{align*}
    Such mode search problems have appeared as generic MAP queries (see \charef{cha:probReasoning}).
    In \charef{cha:networkReasoning} we have discussed them for the specific cases of \HybridLogicNetworks{} and grafting proposal distributions.
% Appearance of mode search
%    The search for maximal coordinates appears in various reasoning tasks:
%    \begin{itemize}
%        \item MAP query as mode search of MLN: $\hypercore$ is the contraction of evidence with the distribution, leaving the query variables open.
%        \item Grafting as mode search of proposal distribution: $\hypercore$ is the contraction of the gradient of the likelihood with the basis encoding of the hypothesis.
%    \end{itemize}
%Both tasks have been formulated as mode search problems in exponential families.
\end{example}



\subsect{Unconstrained Binary Optimization}

For leg dimensions $\catdimof{\atomenumerator}=2$, \probref{prob:maxCoordinate} is known as the unconstrained binary optimization.
\probref{prob:maxCoordinate} is a Higher-Order Unconstrained Binary Optimization (HUBO), when $\hypercorewith$ has a when $\hypercore$ has a monomial decomposition (see \defref{def:polynomialSparsity}) with $\cardof{\variablesetof{\decindex}}\leq\sliceorder$ for all $\decindexin$, that is when $\slicerankwrtof{\sliceorder}{\hypercore}<\infty$.

\begin{definition}
    Let $\hypercorewith$ be a tensor with a monomial decomposition $\enumeratedslices$, where $\max_{\decindexin}\cardof{\variablesetof{\decindex}}=\sliceorder$.
    Se then call \probref{prob:maxCoordinate} a $\sliceorder$-Order Unconstrained Binary Optimization (HUBO), which we denote as
    \begin{align}
        \label{prob:HUBO}\tag{$\probtagtypeinst{\mathrm{HUBO}}{\hypercore}$}
        \argmax_{\shortcatindices\in\atomstates} \quad
        \sum_{\decindexin} \slicescalar^{\decindex} \contractionof{\onehotmapofat{\catindexof{\variablesetof{\decindex}}^{\decindex}}{\catvariableof{\variablesetof{\decindex}}}}{\indexedshortcatvariables} \, .
    \end{align}
%    The binary optimization of a tensor $\hypercorewith\in\atomstates$ is the problem
%    \begin{align}\tag{$\probtagtypeinst{\mathrm{HUBO}}{\hypercore}$}\label{prob:HUBO}
%        \argmax_{\shortcatindices\in\atomstates} \quad \hypercoreat{\indexedshortcatvariables}
%    \end{align}
%    We call Problem~\ref{prob:HUBO} a Higher-Order Unconstrained Binary Optimization (HUBO) problem of order $\sliceorder$ and sparsity $\slicerankwrtof{\sliceorder}{\hypercore}$, when $\hypercore$ has a monomial decomposition (see \defref{def:polynomialSparsity}) with $\cardof{\variablesetof{\decindex}}\leq\sliceorder$ for all $\decindexin$, that is when $\slicerankwrtof{\sliceorder}{\hypercore}<\infty$.
\end{definition}

\begin{remark}[Leg dimensions larger than 2]
    We demanded leg dimensions $\catdimof{\atomenumerator}=2$ to have boolean valued variables $\catvariableof{\catenumerator}$, which is required to connect with the formalism of binary optimization.
    Categorical variables with larger dimensions can be represented by atomization variables, which are created by contractions with categorical constraint tensors (see \secref{sec:categoricalTN}).
\end{remark}

% Interpretation of sparsity
The sparsity $\slicerankwrtof{\sliceorder}{\hypercore}$ is the minimal number of monomials, for which a weighted sum is equal to $\hypercore$.
Thus we interpret \probref{prob:HUBO} as searching for the maximum in a polynomial consistent of $\slicerankwrtof{\sliceorder}{\hypercore}$ monomial terms.
%\red{Each monomial is also refered to as potential.}

\probref{prob:HUBO} is called Quadratic Unconstrained Binary Optimization problems, if $\sliceorder=2$.
We can transform certain Higher-Order Unconstrained Binary Optimization (HUBO) problems into Quadratic Unconstrained Binary Optimization (QUBO) problems by introducing auxiliary variables.
An example of such an transform is provided by the next lemma.

%% Slack variables
\begin{lemma}
    \label{lem:monomialToQUBO}
    For any $\atomindices\in[2]$ and $\variableset\subset[\atomorder]$ we have
    \begin{align*}
        \left( \prod_{\atomenumerator\in\variableset} \atomlegindexof{\atomenumerator } \right)  \left(  \prod_{\atomenumerator\notin\variableset} (1- \atomlegindexof{\atomenumerator }) \right) =
        \max_{\slackvariable\in[2]} \slackvariable \cdot 2 \cdot \left( \sum_{\atomenumerator\in\variableset}\atomlegindexof{\atomenumerator}  - \cardof{\variableset} - \sum_{\atomenumerator\notin\variableset}\atomlegindexof{\atomenumerator} + \frac{1}{2} \right) \, . % Alternative: no factor 2, but + 1 instead of +1/2 (->pyqubo)
    \end{align*}
\end{lemma}
\begin{proof} %Proof by case distinction
    Only if $\atomlegindexof{\atomenumerator}=1$ for $\atomenumerator\in\variableset$ and $\atomlegindexof{\atomenumerator}=0$ else we have
    \[ \left( \sum_{\atomenumerator\in\variableset}\atomlegindexof{\atomenumerator}  - \cardof{\variableset} - \sum_{\atomenumerator\notin\variableset}\atomlegindexof{\atomenumerator} + \frac{1}{2} \right) \geq 0 \, . \]
    In this case the maximum is taken for $\slackvariable=1$ and we have
    \[ \max_{\slackvariable\in[2]} \slackvariable \cdot 2 \cdot \left( \sum_{\atomenumerator\in\variableset}\atomlegindexof{\atomenumerator}  - \cardof{\variableset} - \sum_{\atomenumerator\notin\variableset}\atomlegindexof{\atomenumerator} + \frac{1}{2} \right)
    = 1 = \left( \prod_{\atomenumerator\in\variableset} \atomlegindexof{\atomenumerator } \right)  \left(  \prod_{\atomenumerator\notin\variableset} (1- \atomlegindexof{\atomenumerator }) \right) \, . \]
    In all other cases, the maximum is taken for $\slackvariable=0$ and thus vanishes, that is
    \[ \max_{\slackvariable\in[2]} \slackvariable \cdot 2 \cdot \left( \sum_{\atomenumerator\in\variableset}\atomlegindexof{\atomenumerator}  - \cardof{\variableset} - \sum_{\atomenumerator\notin\variableset}\atomlegindexof{\atomenumerator} + \frac{1}{2} \right)
    = 0 = \left( \prod_{\atomenumerator\in\variableset} \atomlegindexof{\atomenumerator } \right)  \left(  \prod_{\atomenumerator\notin\variableset} (1- \atomlegindexof{\atomenumerator }) \right) \, . \]
    Thus, the claim holds in all cases.
\end{proof}

\subsect{Integer Linear Programming}

Let us now show how optimization problems can be represented as linear programming problems.
% State vector
To this end, we understand each index tuple $\shortcatindices\in\facstates$ as a vector $\statevectorofat{\shortcatindices}{\selvariable}\in\rr^{\catorder}$ with coordinates
\begin{align*}
    \statevectorofat{\shortcatindices}{\selvariable=\catenumerator} = \catindexof{\catenumerator} \, .
\end{align*}

\begin{definition}
    The integer linear program (ILP) of $\matrixat{\datvariable,\selvariable}\in\rr^{n \times d}$, $\rhssymbol[\datvariable]\in\rr^{n}$ and $c\in\rr^{\catorder}$ is the problem
    \begin{align}
        \tag{$\probtagtypeinst{\mathrm{ILP}}{\objectivesymbol,\exmatrix,\rhssymbol}$}
        \argmax_{\shortcatindices\in\facstates} \contraction{\objectivesymbol[\selvariable], \statevectorofat{\shortcatindices}{\selvariable}}
        \quad \text{subject to } \quad \contraction{\matrixat{\datvariable,\selvariable},\statevectorofat{\shortcatindices}{\selvariable}} \prec \rhssymbol[\datvariable] \, ,
    \end{align}
    where by $\prec$ we denote partial ordering of tensors (see \defref{def:partialOrder}).
\end{definition}


We now show that any binary optimization problem of a tensor can be transformed into a integer linear program, given a monomial decomposition of the tensor $\hypercorewith$ by $\sliceset=\enumeratedslices$.
For this we choose state indices by vectors
\begin{align*}
    \seccatindex_{[\catorder+\decdim]} = \catindexof{0},\ldots,\catindexof{\catorder-1},\slackindexof{0},\ldots\slackindexof{\decdim-1} \in \left(\bigtimes_{\catenumeratorin}[2]\right) \times  \left(\bigtimes_{\decindexin}[2]\right) \, ,
\end{align*}
that is we added for each monomial an index $\slackindexof{\decindex}$, which will represent the evaluations of the respective monomial.


We furthermore define a vector $\objofat{\sliceset}{\selvariable}$, where $\selvariable$ takes values in $[\catorder+\decdim]$, as
\begin{align}
    \label{eq:ilpPotential}
    \objofat{\sliceset}{\indexedselvariable} =
    \begin{cases}
        \slicescalarof{\selindex-\catorder} & \text{if} \quad \selindex>\catorder \\% \decindexin \text{ we have } \selindex = \catorder + \decindex \\
        0 & \text{else}
    \end{cases} \, .
\end{align}

To construct a matrix $\matrixat{\datvariable,\selvariable}$ and a vector $b[\datvariable]$ to the monomial decomposition $\sliceset$, we now introduce a variable $\datvariable$ enumerating linear inequalities, which takes values in $[\datanum]$, where
\[ \datanum =  \sum_{\decindexin} \left(\cardof{\variablesetof{\decindex}} +1\right) \, . \]
We define for each $\decindexin$ an auxiliary number
\[ \datanum_{\decindex} = \sum_{\tilde{\decindex}=0}^{\decindex} \left(\cardof{\variablesetof{\tilde{\decindex}}} +1\right) \]
and further enumerate the set $\variablesetof{\decindex}$ by a function $\indexinterpretation: [\cardof{\variablesetof{\decindex}}] \rightarrow \variablesetof{\decindex}$.

We then construct a matrix $\matrixofat{\sliceset}{\datvariable,\selvariable}$, were for $\selindex\in[\catorder+\decdim]$, $\decindexin$ and $\datindex\in[\cardof{\variablesetof{\decindex}}]$ we have
\begin{align}
    \label{eq:ilpMatrix}
    \matrixofat{\sliceset}{\datvariable=\datanum_{\decindex}+\datindex,\indexedselvariable} =
    \begin{cases}
        1 - 2 \cdot \catindexof{\indexinterpretationat{\datindex}}^{\decindex} & \text{if} \quad \datindex < \cardof{\variablesetof{\decindex}}, \,\, \datindex=\selindex \text{  and  } \selindex = \indexinterpretationat{\datindex} \\ % Upper bounds on z, x position
        1  & \text{if} \quad \datindex < \cardof{\variablesetof{\decindex}} \text{  and  } \selindex = \catorder + \decindex \\ % Upper bound on z, z position
        -\catindexof{\indexinterpretationat{\datindex}}^{\decindex} & \text{if }  \datindex = \cardof{\variablesetof{\decindex}}    \text{ and }  \selindex=\indexinterpretationat{\datindex}  \\ % Last condition on $x$
        -1 & \text{if }  \datindex = \cardof{\variablesetof{\decindex}}  \text{ and }  \selindex = \catorder + \decindex \\ % Last condition on $x$
        0 & \text{else} \\
    \end{cases} \, .
\end{align}
%All further coordinates of $\matrixofat{\sliceset}{\datvariable,\selvariable}$ not reached by this construction are set to $0$.
Similarly, we define $\rhsofat{\sliceset}{\datvariable}$ as the vector which nonvanishing coordinates are for $\decindexin$ at
\begin{align}
    \label{eq:ilpRhs}
    \rhsofat{\sliceset}{\datvariable=\datanum_{\decindex}+\datindex} =
    \begin{cases}
        1 - \catindexof{\indexinterpretationat{\datindex}}^{\decindex} & \text{if }  \datindex < \cardof{\variablesetof{\decindex}} \\ % Upper bounds on z
        %\datindex = \catenumerator \text{ and } \catindexof{\catenumerator}^{\decindex} = 0 \\ % First $\catorder$ conditions, on x
        -1 + \cardof{\{\catenumerator\in\variablesetof{\decindex} \, : \,  \catindexof{\catenumerator}^{\decindex} = 1\}}  & \text{if }  \datindex = \cardof{\variablesetof{\decindex}} \\ % \text{ and }  \selindex = \catorder + \decindex \\ % Last condition on $x$
    \end{cases} \, .
\end{align}


% Intuition
Informally, we pose for each tuple $\slicetupleof{}$ $\cardof{\variableset}+1$ linear equations.
The first $\cardof{\variableset}$ enforce, that the slice representing variable $\slackvariable$ is zero once a leg is $0$.
The last enforces that the slice representing variable is $1$.
We prove this claim more formally in the next theorem.

\begin{theorem}
    Given a monomial decomposition $\sliceset=\enumeratedslices$ of a tensor $\hypercore$, let  $\seccatindex^{ILP,\sliceset}$ be a solution of the integer linear program defined by the matrix and vectors in equations \eqref{eq:ilpPotential}, \eqref{eq:ilpMatrix} and \eqref{eq:ilpRhs}.
    Then we have
    \begin{align*}
        \restrictionofto{\seccatindex^{ILP,\sliceset}}{[\catorder]} \in \argmax_{\shortcatindices\in\atomstates} \quad \hypercoreat{\indexedshortcatvariables} \, .
    \end{align*}
    where by  $\restrictionofto{\seccatindex^{ILP,\sliceset}}{[\catorder]}$ we denote the restriction of the index tuple $\seccatindex^{ILP,\sliceset}$ to the first $\catorder$.
\end{theorem}
\begin{proof}
    We show that the linear constraints by
    \begin{align*}
        \contraction{\matrixofat{\sliceset}{\datvariable,\selvariable},\statevectorofat{\seccatindexof{[\atomorder+\decdim]}}{\selvariable}} \prec \rhsofat{\sliceset}{\datvariable}
    \end{align*}
    are satisfied for a vector $\seccatindexof{[\atomorder+\decdim]}=(\catindexof{[\atomorder]},\slackindexof{[\decdim]})$, if and only if for all $\decindexin$ the product constraints
    \begin{align}
        \label{eq:slackindexInequalityILPProof}
        \slackindexof{\decindex}
        = \left( \prod_{\catenumerator\in\variablesetof{\decindex} \, , \,  \catindexof{\catenumerator}^{\decindex} = 0} (1 - \catindexof{\catenumerator} \right)
        \cdot \left( \prod_{\catenumerator\in\variablesetof{\decindex} \, , \,  \catindexof{\catenumerator}^{\decindex} = 1}  \catindexof{\catenumerator} \right) \,
    \end{align}
    hold.
    We will see, that the linear constraints where $\datvariable$ takes indices in $\datanum_{\decindex}+[\cardof{\variablesetof{\decindex}}]$ are equivalent to the upper bound on $\slackindexof{\decindex}$ and the constraint to $\datvariable=\datanum_{\decindex}+\cardof{\variablesetof{\decindex}}$ is equivalent to an lower bound on $\slackindexof{\decindex}$.
    To show the upper bound, we notice that for any $\datindex\in[\cardof{\variablesetof{\decindex}}]$ the constraint $\datvariable = \datanum_{\decindex}+\datindex$ is
    \begin{align*}
        \slackindexof{\decindex} \leq
        \begin{cases}
            \catindexof{\indexinterpretationat{\datindex}}  & \text{if} \quad \catindexof{\indexinterpretationat{\datindex}}^\decindex = 1 \\
            (1- \catindexof{\indexinterpretationat{\datindex}}) & \text{if} \quad \catindexof{\indexinterpretationat{\datindex}}^\decindex = 0 \\
        \end{cases} \, .
    \end{align*}
    Thus, whenever a factor on the right side of \eqref{eq:slackindexInequalityILPProof} is $0$, we have $\slackindexof{\decindex}=0$ if the respective constraint is satisfied.
    We conclude, that
    \begin{align*}
        \slackindexof{\decindex}
        \leq \left( \prod_{\catenumerator\in\variablesetof{\decindex} \, , \,  \catindexof{\catenumerator}^\decindex = 0} (1 - \catindexof{\catenumerator}) \right)
        \cdot \left( \prod_{\catenumerator\in\variablesetof{\decindex} \, , \,  \catindexof{\catenumerator}^\decindex = 1}  \catindexof{\catenumerator} \right) \, .
    \end{align*}
    To show the lower bound, we have the constraint to $\datvariable=\datanum_{\decindex}+\cardof{\variablesetof{\decindex}}$ by
    \begin{align*}
        \slackindexof{\decindex} \geq 1 -
        \left( \sum_{\catenumerator\in\variablesetof{\decindex} \, , \,  \catindexof{\catenumerator}^\decindex = 0} \catindexof{\catenumerator} \right)
        + \left( \sum_{\catenumerator\in\variablesetof{\decindex} \, , \,  \catindexof{\catenumerator}^\decindex = 1}  (\catindexof{\catenumerator} - 1 )\right) \, .
    \end{align*}
    The right side of this inequality is $1$, if and only if all factors on the right side of \eqref{eq:slackindexInequalityILPProof} are $1$, and less or equal to $0$ else.
    Thus, whenever this constraint is satisfied, we have
    \begin{align*}
        \slackindexof{\decindex}
        \geq \left( \prod_{\catenumerator\in\variablesetof{\decindex} \, , \,  \catindexof{\catenumerator}^\decindex = 0} (1 - \catindexof{\catenumerator}) \right)
        \cdot \left( \prod_{\catenumerator\in\variablesetof{\decindex} \, , \,  \catindexof{\catenumerator}^\decindex = 1}  \catindexof{\catenumerator} \right)  \, .
    \end{align*}

    In summary, the equation \eqref{eq:slackindexInequalityILPProof} holds, if and only if the constraints where $\datvariable$ takes indices in $\datanum_{\decindex}+[\cardof{\variablesetof{\decindex}}+1]$ are satisfied.
%    In summary we arrive at
%    \[ \slackindexof{\decindex}
%    = \left( \prod_{\catenumerator\in\variablesetof{\decindex} \, , \,  \catindexof{\catenumerator}^\decindex = 0} (1 - \catindexof{\catenumerator}^\decindex) \right)
%    \cdot \left( \prod_{\catenumerator\in\variablesetof{\decindex} \, , \,  \catindexof{\catenumerator}^\decindex = 1}  \catindexof{\catenumerator}^\decindex \right)
%    \]
%    if and only if the indices $\seccatindex_{[\catorder+\decdim]}$ are feasible.

    This characterization of the constraints implies, that for any $\shortcatindices\in\facstates$ there is exactly one feasible index $\seccatindex_{[\catorder+\decdim]}$ with $\restrictionofto{(\seccatindex_{[\catorder+\decdim]})}{[\catorder]}=\shortcatindices$, and the objective takes for this index the value
    \begin{align*}
        \contraction{\objectivesymbol[\selvariable], \statevectorofat{\seccatindex_{[\catorder+\decdim]}}{\selvariable}}
        &= \sum_{\decindexin} \slicescalarof{\decindex} \cdot \slackindexof{\decindex} \\
        &= \sum_{\decindexin} \slicescalarof{\decindex} \cdot \left( \prod_{\catenumerator\in\variablesetof{\decindex} \, , \,  \catindexof{\catenumerator}^\decindex = 0} (1 - \catindexof{\catenumerator}^\decindex) \right)
        \cdot \left( \prod_{\catenumerator\in\variablesetof{\decindex} \, , \,  \catindexof{\catenumerator}^\decindex = 1}  \catindexof{\catenumerator}^\decindex \right)  \\
        & = \hypercoreat{\indexedshortcatvariables} \, .
    \end{align*}
    Therefore, any solution of the ILP reduced to the first $\catorder$ indices corresponding with the axis of $\hypercore$, is a solution of the binary optimization problem to $\hypercore$.
\end{proof}


% Sparsity
In order to achieve a sparse linear program it is benefitial to use a monomial decomposition with small order and rank.
Beside this sparsity, the matrix $\matrixofat{\sliceset}{\datvariable,\selvariable}$ is often $\ell_0$-sparse, and has thus an efficient representation in a basis CP format.
More precisely we have by the above construction
\begin{align*}
    \sparsityof{\matrixofat{\sliceset}{\datvariable,\selvariable}} \leq \sum_{\decindexin} 3 \cdot \cardof{\variablesetof{\decindex}} +1 \, .
\end{align*}
