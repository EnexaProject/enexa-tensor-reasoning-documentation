\section{Contraction Equations}

We have observed, that many concepts and theorems in probability theory and logics can be understood as contraction equations.
We first provide a summary of the used contraction equations.

\subsection{Contraction equations in logical and probabilistic reasoning}

Let us summarize the application of contractions and normation in the definition of
\begin{itemize}
	\item Marginal probabilities (\defref{def:marginalProbability}, \theref{the:marginalContraction})
		\[ \probat{\exrandom} = \sbcontractionof{\probtensor}{\exrandom} \]
	\item Conditional probabilities (\defref{def:conditionalProbability}, \theref{the:conditionalContraction})
		\[ \condprobof{\exrandom}{\secexrandom} = \sbnormationofwrt{\probtensor}{\exrandom}{\secexrandom} \]
	\item The partition function of a Markov Networks 
		\begin{align*}
			\partitionfunctionof{\extnet} = \contractionof{\extnet}{\varnothing}
		\end{align*}
	\item The probability distribution of a Markov Network is (\defref{def:markovNetwork})
		\begin{align*}
			\probtensor^{\extnet} = \normationofwrt{\extnet}{\nodes}{\varnothing}
		\end{align*}
\end{itemize}


Further the following properties have been defined by contraction equations:
\begin{itemize}
	\item $\exrandom$ and $\secexrandom$ are independent when (\defref{def:independence}, \theref{the:independenceProductCriterion})
		\[  \sbcontractionof{\probtensor}{\exrandom,\secexrandom} 
		=  \sbcontractionof{\probtensor}{\exrandom} 
			\otimes  \sbcontractionof{\probtensor}{\secexrandom} \]
	\item $\exrandom$ and $\secexrandom$ are called independent conditioned on $\thirdexrandom$ when (\defref{def:condIndependence}, \theref{the:condIndependenceProductCriterion})
		\[ \sbnormationofwrt{\probtensor}{\exrandom,\secexrandom}{\thirdexrandom} 
		= \sbnormationofwrt{\probtensor}{\exrandom}{\thirdexrandom} 
		\otimes \sbnormationofwrt{\probtensor}{\secexrandom}{\thirdexrandom} \]
\end{itemize}





\subsection{Normation Equations}

\begin{theorem}[Normation as a Contraction Equation]\label{the:normationContractionEQ}
	For any on $\innodes$ normable tensor $\hypercoreat{\catvariableof{\nodes}}$, where $\innodes\dot{\cup}\outnodes=\nodes$, we have
	\begin{align*}
		\sbcontractionof{\hypercore}{\catvariableof{\nodes}} 
		= \sbcontractionof{\sbnormationofwrt{\hypercore}{\catvariableof{\outnodes}}{\catvariableof{\innodes}},\sbcontractionof{\hypercore}{\catvariableof{\innodes}}}{\catvariableof{\nodes}} \, . 
	\end{align*}
\end{theorem}
\begin{proof}
	Let us choose indices $\catindexof{\innodes}$ and $\catindexof{\outnodes}$.
	We have that
	\begin{align*}
		%\sbcontractionof{
		\sbnormationofwrt{\hypercore}{\indexedcatvariableof{\innodes}}{\indexedcatvariableof{\outnodes}}
		%}{\indexedcatvariableof{\innodes},\indexedcatvariableof{\outnodes}} 
		= \frac{
			\sbcontractionof{\hypercore}{\indexedcatvariableof{\innodes},\indexedcatvariableof{\outnodes}} 	
		}{
			\sbcontractionof{\hypercore}{\indexedcatvariableof{\innodes}} 	
		} 
	\end{align*}
	and therefor
	\begin{align*}
		\sbcontractionof{\hypercore}{\indexedcatvariableof{\innodes},\indexedcatvariableof{\outnodes}} = 
		\sbnormationofwrt{\hypercore}{\indexedcatvariableof{\innodes}}{\indexedcatvariableof{\outnodes}}
		\cdot 
		\sbcontractionof{\hypercore}{\indexedcatvariableof{\innodes}} 	
	\end{align*}
	Since the equation holds for arbitrary indices, the claim is established.
\end{proof}


\begin{theorem}[Generic Chain Rule]\label{the:genericChainRule}
	For any Tensor $\hypercoreat{\catvariableof{\nodes}}$ and any total order $\prec$ on the nodes $\nodes$ we have % ! CAN DIRECTLY USE [d] when having the order !
	\begin{align*}
		\hypercoreat{\catvariableof{\nodes}} = 
		\contractionof{
			\{ \sbnormationofwrt{\hypercore}{\catvariableof{\node}}{\catvariableof{\prenodes}}  \, : \nodein \}
		}{\catvariableof{\nodes}}
	\end{align*}
\end{theorem}
\begin{proof}
	We apply \theref{the:normationContractionEQ} on the tensor
	\begin{align*}
		\sbnormationofwrt{\hypercore}{
			\catvariableof{\node},\catvariableof{\afternodes}
		}{
			\indexedcatvariableof{\prenodes}
		} \, ,
	\end{align*}
	where $\nodein$ and $\catindexof{\nodes}$ are chosen arbitrarly.
	For any $\nodein$ we get
	\begin{align*}
		\sbnormationofwrt{\hypercore}{
			\catvariableof{\node},\catvariableof{\afternodes}
			}{
			\catvariableof{\prenodes}
		} 
		= \sbcontractionof{
			\normationofwrt{\hypercore}{
				\catvariableof{\afternodes}
				}{
				\catvariableof{\node},\catvariableof{\prenodes}
				},
			\normationofwrt{\hypercore}{
				\catvariableof{\node}
				}{
				\catvariableof{\prenodes}
				}
		}{
			\catvariableof{\nodes} 
		} \, .
	\end{align*}
	Applying this equation iteratively and making use of the commutation of contractions we get for any $\nodein$
	\begin{align*}
		\sbnormationofwrt{\hypercore}{
			\catvariableof{\node},\catvariableof{\afternodes}
		}{
			\catvariableof{\prenodes}
		}
		= \sbcontractionof{
			\normationofwrt{\hypercore}{
				\catvariableof{\secnode}
			}{
				\catvariableof{\{\thirdnode : \thirdnode \prec \secnode, \thirdnode\neq\secnode\}}
			} 
			\, : \node \prec \secnode
		}{
			\catvariableof{\nodes} 
		} \, .
	\end{align*}
	With the maximal node $\node$, that is the $\node$, such that no $\secnode\in\nodes$ with $\node\prec\secnode$ and $\node\neq\secnode$ exists, this is the claim.
\end{proof}




\subsection{Proof of Hammersley-Clifford Theorem}\label{sec:proofHCTheorem}

\red{Different to the standard case, we show a version of Hammersley-Clifford for hypergraphs.}


\begin{lemma}\label{the:contractionFactorization}
	Let $\hypercoreat{\catvariableof{\nodes}}$ be a positive tensor and $\seccatindexof{\nodes}$ an arbitrary index.
	Then we have 
	\begin{align*}
		\hypercoreat{\catvariableof{\nodes}}
		= \sbcontractionof{
			\big(\sbcontractionof{\hypercore}{\catvariableof{\nodes/\thirdnodes}, \catvariableof{\thirdnodes} = \seccatindexof{\thirdnodes}}\big)^{(-1)^{\cardof{\secnodes}-\cardof{\thirdnodes}}} \, : \, \thirdnodes \subset \secnodes \subset \nodes
		}{\catvariableof{\nodes}} \, ,
	\end{align*}
	where the exponentiation is performed coordinatewise and positivity of $\hypercore$ ensures the well-definedness.
\end{lemma}
\begin{proof}
	It suffices to show, that for an arbitrary index $\catindexof{\nodes}$ be an arbitrary index we have
	\begin{align*}
		\hypercoreat{\indexedcatvariableof{\nodes}}
		= \prod_{\secnodes\subset\nodes} \prod_{\thirdnodes\subset\secnodes}
			\big(\sbcontractionof{\hypercore}{\indexedcatvariableof{\nodes/\thirdnodes}, \catvariableof{\thirdnodes} = \seccatindexof{\thirdnodes}}\big)^{(-1)^{\cardof{\secnodes}-\cardof{\thirdnodes}}} \, .
	\end{align*}
	We do this by applying a logarithm on the right hand side and grouping the terms by $\thirdnodes$ as
	\begin{align*}
		%\lnof{\hypercoreat{\indexedcatvariableof{\nodes}}} 
		& \lnof{\prod_{\secnodes\subset\nodes} \prod_{\thirdnodes\subset\secnodes}
			\sbcontractionof{\hypercore}{\indexedcatvariableof{\nodes/\thirdnodes}, \catvariableof{\thirdnodes} = \seccatindexof{\thirdnodes}}\big)^{(-1)^{\cardof{\secnodes}-\cardof{\thirdnodes}}}} \\
		& = \sum_{\thirdnodes\subset\nodes} \lnof{\sbcontractionof{\hypercore}{\indexedcatvariableof{\nodes/\thirdnodes}, \catvariableof{\thirdnodes} = \seccatindexof{\thirdnodes}}} 
		\left( \sum_{\secnodes\subset\nodes \, : \, \thirdnodes\subset \secnodes} (-1)^{\cardof{\secnodes}-\cardof{\thirdnodes}} \right) \\
		& =  \sum_{\thirdnodes\subset\nodes} \lnof{\sbcontractionof{\hypercore}{\indexedcatvariableof{\nodes/\thirdnodes}, \catvariableof{\thirdnodes} = \seccatindexof{\thirdnodes}}} 
		\left( \sum_{i \in [\cardof{\nodes}-\cardof{\thirdnodes}]}  (-1)^{i}  \binom{\cardof{\nodes}-\cardof{\thirdnodes}}{i}  \right) 
	\end{align*}
	Now, by the generic binomial theorem we have that for $n\in\nn, n \neq 0$
		\[ 0 = (1-1)^n = \sum_{i \in [n]}  (-1)^{i}  \binom{n}{i}   \, . \]
	Therefore, the summands for $\thirdnodes\neq\nodes$ vanish and we have 
	\begin{align*}
			& \lnof{ \prod_{\secnodes\subset\nodes} \prod_{\thirdnodes\subset\secnodes}
			\big(\sbcontractionof{\hypercore}{\indexedcatvariableof{\nodes/\thirdnodes}, \catvariableof{\thirdnodes} = \seccatindexof{\thirdnodes}}\big)^{(-1)^{\cardof{\secnodes}-\cardof{\thirdnodes}}} } \\
			& = \lnof{\hypercoreat{\indexedcatvariableof{\nodes}}}
			\left( \sum_{i \in [0]}  (-1)^{i}  \binom{0}{i}  \right) \\
			& = \lnof{\hypercoreat{\indexedcatvariableof{\nodes}}} \, . 
	\end{align*}
	Applying the exponential function on both sides establishes the claim.
\end{proof}


%\begin{lemma}\label{the:condIndMN}
%	Let $\extnet$ be a tensor network of positive cores and $\catindexof{\nodes}$ an arbitrary index.
%	Then we have
%	\begin{align*}
%		\contractionof{\extnet}{\catvariableof{\nodes}} =
%		\prod_{\secnodes\subset\nodes} \prod_{\thirdnodes\subset\secnodes} 
%		\left(\contractionof{\extnet\cup\{\onehotmapof{\catindexof{\nodes/\thirdnodes}}\}}{\catvariableof{\thirdnodes}}\right)^{(-1)^{\cardof{\secnodes}-\cardof{\thirdnodes}}}
%	\end{align*}
%\end{lemma}
%\begin{proof}
%	Show, that any factor $\contractionof{\extnet\cup\{\onehotmapof{\catindexof{\nodes/\thirdnodes}}\}}{\catvariableof{\thirdnodes}}$ with $\thirdnodes\neq\nodes$ is cancelled (by the $(1-1)^n$ binominal theorem).
%\end{proof}


\begin{lemma}\label{lem:independentContractionFactorization}
	Let $\hypercore$ be a positive tensor, $\secnodes\subset\nodes$ and arbitrary subset and $\catindexof{\secnodes}$ an arbitrary index.
	When there are $\nodesa,\nodesb \in\secnodes$, such that
	\begin{align*}
		\sbnormationofwrt{\hypercore}{\catvariableof{\nodesa,\nodesb}}{\catvariableof{\nodes/\{\nodesa,\nodesb\}}}
		= \sbcontractionof{ 
		\sbnormationofwrt{\hypercore}{\catvariableof{\nodesa}}{\catvariableof{\nodes/\{\nodesa,\nodesb\}}},
		\sbnormationofwrt{\hypercore}{\catvariableof{\nodesb}}{\catvariableof{\nodes/\{\nodesa,\nodesb\}}}
		}{\catvariableof{\secnodes}}
	\end{align*}
	then
	\begin{align*}
 \prod_{\thirdnodes\subset\secnodes} 
		\left(\sbcontractionof{\hypercore}{\indexedcatvariableof{\nodes/\thirdnodes}, \catvariableof{\thirdnodes} = \seccatindexof{\thirdnodes}}\right)^{(-1)^{\cardof{\secnodes}-\cardof{\thirdnodes}}} = 1 \, .
	\end{align*}
\end{lemma}
\begin{proof}
	We abbreviate
		\[ Z_{\thirdnodes} = \sbcontractionof{\hypercore}{\indexedcatvariableof{\nodes/\thirdnodes}, \catvariableof{\thirdnodes} = \seccatindexof{\thirdnodes}} \, . 
 \]
	By reorganizing the sum over $\thirdnodes\subset\secnodes$ into  $\thirdnodes\subset\secnodes/\nodesa\cup\nodesb$ we have
	\begin{align}\label{eq:indContFacProof}
	 	\prod_{\thirdnodes\subset\secnodes} 
		\left(
			Z_{\thirdnodes}
		\right)^{(-1)^{\cardof{\secnodes}-\cardof{\thirdnodes}}} = 
		 \prod_{\thirdnodes\subset\secnodes/\{\nodesa,\nodesb\}} 
		 \left( 
		 	\frac{
				Z_{\thirdnodes} \cdot Z_{\thirdnodes\cup\{\nodesa,\nodesb\}}
			}{
				Z_{\thirdnodes\cup\{\nodesa\}} \cdot Z_{\thirdnodes\cup\{\nodesb\}}
			}
		 \right)^{(-1)^{\cardof{\secnodes}-\cardof{\thirdnodes}}} \, . 
	\end{align}
	From the independence assumption it follows that for any index $\catindex$
	\begin{align*}
		& \sbnormationofwrt{\hypercore}{
			 	\indexedcatvariableof{\nodesa} 
			 }{\indexedcatvariableof{\nodes/\thirdnodes\cup\{\nodesa,\nodesb\}},\catvariableof{\thirdnodes}=\seccatindexof{\thirdnodes},  \indexedcatvariableof{\nodesb} } 
			 \\
		& \quad =  
		\sbnormationofwrt{\hypercore}{
			 	\indexedcatvariableof{\nodesa} 
			 }{\indexedcatvariableof{\nodes/\thirdnodes\cup\{\nodesa,\nodesb\}}, \catvariableof{\thirdnodes}=\seccatindexof{\thirdnodes}} \\
		 & \quad  = 
		\sbnormationofwrt{\hypercore}{
			 	\indexedcatvariableof{\nodesa} 
			 }{\indexedcatvariableof{\nodes/\thirdnodes\cup\{\nodesa,\nodesb\}},\catvariableof{\thirdnodes}=\seccatindexof{\thirdnodes},  \catvariableof{\nodesb} = \seccatindexof{\nodesb}} 
	\end{align*}
	Applying this in each squares bracket term of \eqref{eq:indContFacProof} we get
	\begin{align*}
		\frac{
			Z_{\thirdnodes}
		}{
			Z_{\thirdnodes\cup\{\nodesa\}}
		} 
		& = 
		\frac{
			 \sbnormationofwrt{\hypercore}{
			 	\indexedcatvariableof{\nodesa} 
			 }{\indexedcatvariableof{\nodes/\thirdnodes\cup\{\nodesa,\nodesb\}}, \catvariableof{\thirdnodes}=\seccatindexof{\thirdnodes}, \indexedcatvariableof{\nodesb} } 
		}{
			 \sbnormationofwrt{\hypercore}{
			 	\catvariableof{\nodesa} = \seccatindexof{\nodesa}
			 }{\indexedcatvariableof{\nodes/\thirdnodes\cup\{\nodesa,\nodesb\}} , \catvariableof{\thirdnodes}=\seccatindexof{\thirdnodes}, \indexedcatvariableof{\nodesb}} 
		} \\
		& = 
		\frac{
			 \sbnormationofwrt{\hypercore}{
			 	\indexedcatvariableof{\nodesa} 
			 }{\indexedcatvariableof{\nodes/\thirdnodes\cup\{\nodesa,\nodesb\}}, \catvariableof{\thirdnodes}=\seccatindexof{\thirdnodes}, \catvariableof{\nodesb} = \seccatindexof{\nodesb}} 
		}{
			 \sbnormationofwrt{\hypercore}{
			 	\catvariableof{\nodesa} = \seccatindexof{\nodesa}
			 }{\indexedcatvariableof{\nodes/\thirdnodes\cup\{\nodesa,\nodesb\}}, \catvariableof{\thirdnodes}=\seccatindexof{\thirdnodes},\catvariableof{\nodesb} = \seccatindexof{\nodesb}} 
		} \\
		& = 
		\frac{
			Z_{\thirdnodes\cup\{\nodesb\}}
		}{
			Z_{\thirdnodes\cup\{\nodesa,\nodesb\}}
		} \, . 
	\end{align*}
	Thus, each factor in \eqref{eq:indContFacProof} is trivial, which establishes the claim.
\end{proof}

We are finally ready to proof \theref{the:condIndMN} based on the Lemmata above.

\begin{theorem}[\theref{the:condIndMN}]
	Let $\probat{\catvariableof{\nodes}}$ be a probability distribution and $\graph$ a clique-capturing hypergraph, such that for $\nodesa$, $\nodesb$, $\nodesc$ we have that $\catvariableof{\nodesa}$ is independent of $\catvariableof{\nodesb}$ conditioned on $\catvariableof{\nodesc}$, when $\nodesc$ separates $\nodesa$ and $\nodesb$ in the hypergraph.
	Then there is a Markov Network on $\graph$, which distribution is equal to $\probat{\catvariableof{\nodes}}$.
\end{theorem}
\begin{proof}[Proof of \theref{the:condIndMN}]
	By \lemref{the:contractionFactorization} we have for any index $\catindexof{\nodes}$
	\begin{align*}
		\probat{\indexedcatvariableof{\nodes}} =
		\prod_{\secnodes\subset\nodes} \prod_{\thirdnodes\subset\secnodes} 
		\left(
			\probat{\indexedcatvariableof{\thirdnodes},\catvariableof{\nodes/\thirdnodes}=\seccatindexof{\nodes/\thirdnodes}}
		%	\contractionof{\extnet\cup\{\onehotmapof{\catindexof{\nodes/\thirdnodes}}\}}{\catvariableof{\thirdnodes}}
		\right)^{(-1)^{\cardof{\secnodes}-\cardof{\thirdnodes}}}
	\end{align*}
	For any subset $\secnodes\subset\nodes$, which is not contained in a hyperedge, we find $\nodesa,\nodesb \in\secnodes$ such that $\catvariableof{\nodesa}$ is independendent on $\catvariableof{\nodesb}$ conditioned on $\catvariableof{\secnodes/\{\nodesa,\nodesb\}}$.
	If no such nodes $\nodesa,\nodesb \in\secnodes$ exists, $\secnodes$ would be contained in a hyperedge, since the hypergraph is assumed to be clique-capturing.
	By \lemref{lem:independentContractionFactorization} we then have
	\begin{align*}
	 \prod_{\thirdnodes\subset\secnodes} 
		\left(
			\probat{\indexedcatvariableof{\thirdnodes},\catvariableof{\nodes/\thirdnodes}=\seccatindexof{\nodes/\thirdnodes}}
		\right)^{(-1)^{\cardof{\secnodes}-\cardof{\thirdnodes}}} = 1 \, .
	\end{align*}
	We label by a function 
	\begin{align*}
		\alpha: \{\secnodes : \exists\edge\in\edges: \secnodes \subset \edge \} \rightarrow \edges
	\end{align*}	
	the remaining node subsets by a hyperedge containing the subset.
	We build the tensor
	\begin{align*}
		\hypercoreofat{\edge}{\catvariableof{\edge}} = \prod_{\secnodes \, : \, \alpha(\secnodes) = \edge} \prod_{\thirdnodes\subset\secnodes} 
		\left(
			\probat{\indexedcatvariableof{\thirdnodes},\catvariableof{\nodes/\thirdnodes}=\seccatindexof{\nodes/\thirdnodes}}
		\right)^{(-1)^{\cardof{\secnodes}-\cardof{\thirdnodes}}} \, . 
	\end{align*}
	and get, that 
	\begin{align*}
		\probat{\catvariableof{\nodes}} & = \contractionof{\extnetasset}{\catvariableof{\nodes}} \\
		& = \normationofwrt{\extnetasset}{\catvariableof{\node}}{\varnothing} \, .
	\end{align*}
	We have thus constructed a Markov Network with trivial partition function, which contraction coincides with the probability distribution.
\end{proof}





\subsection{Commutation of Contractions}

We show in the next theorem, that a contractions can be performed by contracting a subnetwork first and then further contracting the result with the rest. 

%% OLD Statement
%\begin{theorem}\label{the:splittingContractions}
%	Let $\tnetof{\graph}$ be a tensor network on a hypergraph $\graph=(\nodes,\edges)$.
%	Let us now split the $\graph$ into two graphs $\graph_1=(\nodes_1,\edges_1)$ and $\graph_2=(\nodes_2,\edges_2)$, such that $\edges_1\dot{\cup}\edges_2=\edges$, and let $\secnodes,\secnodes_2\subset\nodes$ be such that $\nodes_2\cap(\nodes_1\cup\secnodes_2) \subset \secnodes$.
%	%$\nodes_1\cup\nodes_2=\nodes$.
%	If $\nodes_2\cup\secnodes \subset \secnodes_2$ then
%		\[ \contractionof{\tnetof{\graph}}{\secnodes} = \contractionof{\tnetof{\graph_1} \cup \{
%			\contractionof{\tnetof{\graph_2}}{\secnodes_2}
%		\}}{\nodes}   \, . \]
%\end{theorem}
%\begin{proof}
%	By an exchange of summations.
%\end{proof}



\begin{theorem}\label{the:splittingContractions}
	Let $\tnetof{\graph}$ be a tensor network on a hypergraph $\graph=(\nodes,\edges)$.
	Let us now split the $\graph$ into two graphs $\graph_1=(\nodes_1,\edges_1)$ and $\graph_2=(\nodes_2,\edges_2)$, such that $\edges_1\dot{\cup}\edges_2=\edges$, $\nodes_1\cup\nodes_2=\nodes$ and all nodes in $\nodes_2$ are contained in an hyperedge of $\edges_2$.
	We then have
		\[ \contractionof{\tnetof{\graph}}{\catvariableof{\secnodes}} 
		= 
		\contractionof{\tnetof{\graph_1} \cup \{
			\contractionof{\tnetof{\graph_2}}{\catvariableof{\nodes_2\cap(\nodes_1\cup\secnodes)}}
		\}}{\catvariableof{\secnodes}}   \, . \]
\end{theorem}
\begin{proof}
	For any index $\catindexof{\secnodes}$ we show that 
			\[ \contractionof{\tnetof{\graph}}{\indexedcatvariableof{\secnodes}} 
		= 
		\contractionof{\tnetof{\graph_1} \cup \{
			\contractionof{\tnetof{\graph_2}}{\catvariableof{\nodes_2\cap(\nodes_1\cup\secnodes)}}
		\}}{\indexedcatvariableof{\secnodes}}   \, . \]
	By definition we have
	\begin{align*}
		\contractionof{\tnetof{\graph}}{\indexedcatvariableof{\secnodes}} 
		& = \sum_{\catindexof{\nodes/\secnodes}} \prod_{\edge\in\edges} \hypercoreofat{\edge}{\indexedcatvariableof{\edge}} \\
		& = \sum_{\catindexof{\nodes/\secnodes}} 
		 	\left( \prod_{\edge\in\edges_1} \hypercoreofat{\edge}{\indexedcatvariableof{\edge}} \right) 
		 	\cdot \left( \prod_{\edge\in\edges_2} \hypercoreofat{\edge}{\indexedcatvariableof{\edge}}  \right) \\
		& =  \sum_{\catindexof{\nodes_1/\secnodes}} \sum_{\catindexof{\nodes_2/(\secnodes\cup\nodes_1)}} 
			\left( \prod_{\edge\in\edges_1} \hypercoreofat{\edge}{\indexedcatvariableof{\edge}} \right) 
		 	\cdot \left( \prod_{\edge\in\edges_2} \hypercoreofat{\edge}{\indexedcatvariableof{\edge}}  \right) \\
		& =  \sum_{\catindexof{\nodes_1/\secnodes}}  
			\left( \prod_{\edge\in\edges_1} \hypercoreofat{\edge}{\indexedcatvariableof{\edge}} \right) 
		 	\cdot \left( \sum_{\catindexof{\nodes_2/(\secnodes\cup\nodes_1)}}  \prod_{\edge\in\edges_2} \hypercoreofat{\edge}{\indexedcatvariableof{\edge}}  \right) \, .
	\end{align*}
	When contracting the variables $\catvariableof{\nodes_2/(\secnodes\cup\nodes_1)}$ on $\tnetof{\graph_2}$, the variables $\catvariableof{\nodes_2\cap(\secnodes\cup\nodes_1)}$ are left open. 
	We therefore have for any $\catindexof{\nodes_2\cap(\secnodes\cup\nodes_1)}$ 
	\begin{align*}
		\sbcontractionof{\tnetof{\graph_2}}{\indexedcatvariableof{\nodes_2\cap(\secnodes\cup\nodes_1)}} =
		 \left( \sum_{\catindexof{\nodes_2/(\secnodes\cup\nodes_1)}}  \prod_{\edge\in\edges_2} \hypercoreofat{\edge}{\indexedcatvariableof{\edge}}  \right) \, . 
	\end{align*}
	It follows with the above, that 
	\begin{align*}
		\contractionof{\tnetof{\graph}}{\indexedcatvariableof{\secnodes}} 
		& =  \sum_{\catindexof{\nodes_1/\secnodes}}  \left( \prod_{\edge\in\edges_1} \hypercoreofat{\edge}{\indexedcatvariableof{\edge}} \right) \cdot \sbcontractionof{\tnetof{\graph_2}}{\indexedcatvariableof{\nodes_2\cap(\secnodes\cup\nodes_1)}} \\
		& = \contractionof{\tnetof{\graph_1} \cup \{
			\contractionof{\tnetof{\graph_2}}{\catvariableof{\nodes_2\cap(\nodes_1\cup\secnodes)}}
		\}}{\indexedcatvariableof{\secnodes}}   \, . 
	\end{align*}
\end{proof}







\subsection{Support of Contractions}\label{sec:supportContractionEquations}



To state the next theorem we introduce the nonzero function $\nonzerofunction: \rr \rightarrow [2]$ by
\begin{align}
	\nonzeroof{x} = \begin{cases}
	0 & \text{if }x=0 \\
	1 & \text{else}
	\end{cases}
\end{align}
Applied coordinatewise on tensors it marks the nonzero coordinates by $1$.

We show that adding binary tensor cores to an contraction orders the results by the partial ordering introduced in \defref{def:partialFTOrder}

\begin{theorem}[Monotonicity of Tensor Contractions]\label{the:monotonicityBinaryContractions}
	Let $\extnet, \secextnet$ be tensor network of non-negative tensors and $\catvariableof{\secnodes}$ an arbitrary set of random variables. %, and $\tilde{\theta}$ another binary tensor. 
	Then we have
		\[ \nonzeroof{\contractionof{\extnet\cup\secextnet}{\catvariableof{\secnodes}}} \prec
		\nonzeroof{\contractionof{\extnet}{\catvariableof{\secnodes}}} \, .  \]
\end{theorem}
\begin{proof}
	It suffices to show that for any $\catindexof{\secnodes}$ with 
		\[ \nonzeroof{\contractionof{\extnet\cup\secextnet}{\indexedcatvariableof{\secnodes}}}=1 \]
	we also have 
		\[ \nonzeroof{\contractionof{\extnet}{\indexedcatvariableof{\secnodes}}}=1 \, . \]
	For any $\catindexof{\secnodes}$ satisfying the first equation we find an extension $\catindexof{\nodes}$ to all variables of the tensor networks such that
		\[ \contractionof{\extnet\cup\secextnet}{\indexedcatvariableof{\nodes}} > 0 \]
	and it follows that
		\[ \contractionof{\extnet}{\indexedcatvariableof{\nodes}} > 0 \quad\text{and}\quad  \contractionof{\secextnet}{\indexedcatvariableof{\nodes}} > 0  \, . \]
	But this already implies, that 
		\[ \nonzeroof{\contractionof{\extnet}{\indexedcatvariableof{\secnodes}}}=1 \, . \]
\end{proof}

Let us now state an equivalence of the contraction, when we add the result of the same contraction 
\begin{theorem}[Invariance under adding subcontractions]\label{the:invarianceAddingSubcontractions}
	Let $\extnet$ be a tensor network of non-negative tensors with variables $\catvariableof{\nodes}$ and let $\secextnet$ be a subset.
	Then we have for any subset $\catvariableof{\secnodes}$ of $\catvariableof{\nodes}$
		\[ \contractionof{\extnet \cup\{
			\nonzeroof{
			\contractionof{\secextnet}{\catvariableof{\secnodes}}
			}
		\}}{\catvariableof{\nodes}} 
		= \contractionof{\extnet}{\catvariableof{\nodes}}
		\, . \]
	
	%For any sets of leg variables $\randomxof{V},\randomxof{\tilde{V}}$ appearing in $\theta$  we have
	%Then we have
	%	\[ \contractionof{\theta\cup
	%	\nonzeroof{\contractionof{\tilde{\theta}}{\randomxof{\tilde{V}}}}
	%			}{\randomxof{V}} = \contractionof{\theta}{\randomxof{V}} \, . \]
\end{theorem}
\begin{proof}
	For any $\catindexof{\nodes}$ with 
		\[ \contractionof{\extnet}{\indexedcatvariableof{\nodes}} = 0 \]
	we also have 
		\[ \contractionof{\extnet \cup\{
			\nonzeroof{
			\contractionof{\secextnet}{\catvariableof{\secnodes}}
			}
		\}}{\indexedcatvariableof{\nodes}} = 0 \, . \]
	For any $\catindexof{\nodes}$ with 
		\[ \contractionof{\extnet}{\indexedcatvariableof{\nodes}} \neq 0 \]
	we have for the reduction $\catindexof{\secnodes}$ of the index $\catindexof{\nodes}$ that
		\[  \contractionof{\secextnet}{\indexedcatvariableof{\secnodes}} \neq 0 \]
	and thus
	\begin{align*}
		\contractionof{\extnet \cup\{
			\nonzeroof{
			\contractionof{\secextnet}{\catvariableof{\secnodes}}
			}
		\}}{\indexedcatvariableof{\nodes}} 
		= \contractionof{\extnet}{\indexedcatvariableof{\nodes}} \cdot \nonzeroof{
			\contractionof{\secextnet}{\catvariableof{\secnodes}}
			}[\indexedcatvariableof{\secnodes}]
		= \contractionof{\extnet}{\indexedcatvariableof{\nodes}} \, . 
	\end{align*}
%	When the subcore transformed by $\nonzeroof{\cdot}$ contains a zero slice, then this
%	 zero slice is also appearing in the rest contraction.
%	Multiplying a zero slice with zero does not affect the contraction, neither does multiplication with one on any slice.
\end{proof}





\begin{remark}
	Similar statements hold, when dropping the non-negativity assumption on the, but demanding that all variables are left open.
\end{remark}




















