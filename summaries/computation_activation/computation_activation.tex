\documentclass[aps,onecolumn,nofootinbib,pra]{article}

\usepackage{../../article_compilation/spec_files/arxiv}
\usepackage{amsmath,amsfonts,amssymb,amsthm,bbm,graphicx,enumerate,times}
\usepackage{mathtools}
\usepackage[usenames,dvipsnames]{color}
\usepackage{hyperref}
\hypersetup{
    breaklinks,
    colorlinks,
    linkcolor=gray,
    citecolor=gray,
    urlcolor=gray,
    pdftitle={},
    pdfauthor={Alex Goessmann}
}

\usepackage{tikz}
\usepackage{graphicx}
\usepackage{float}
\usepackage{comment}
\usepackage{csquotes}

\usepackage{braket}

\usepackage{listings}
\usepackage{verbatim}
\usepackage{etoolbox}
\usepackage{braket}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{titlesec}
\usepackage{fancyhdr}
\usepackage{bbm}
\usepackage{bm}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{lipsum}

\newtheorem{remark}{Remark}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}

\input{../../macros/organization_macros.tex}
\input{../../macros/general_macros.tex}
\input{../../macros/tc_macros.tex}
\input{../../macros/tikz_macros.tex}

\pretolerance=500
\tolerance=100
\emergencystretch=10pt

% Bibliography
\DeclareUnicodeCharacter{FB01}{fi}
\usepackage[round]{natbib}
\usepackage{wasysym}


\newcommand{\red}[1]{\textcolor{red}{#1}}
\renewcommand{\charef}[1]{\textit{Chapter #1}}

\begin{document}
    \title{\ComputationActivationNetworks{} - Unifying probabilistic and logical reasoning}

    \maketitle
    \date{\today}

    \begin{abstract}
        We introduce a novel architecture for tensor networks, which is adapted to represent propositional formulas and exponential distributions.
        Based on the
    \end{abstract}


    \section{Motivation}

    Models which combine
    \begin{itemize}
        \item hard features: Always satisfied and necessary for non-vanishing probability.
        \item soft features: Typically satisfied
    \end{itemize}

    Comment on maximum entropy motivation?


    \section{Notation and Basic Concepts}

    \begin{itemize}
        \item Tensor Notation
        \item \BasisEncodings{}
        \item \ComputationActivationNetworks{} as contractions of \BasisEncodings{} (computing a statistic) and activation tensors (shaping the distribution based on the computed statistic).
    \end{itemize}


    \section{Hard Activation: Propositional Formulas}

    \charef{cha:logicalRepresentation}
    \begin{itemize}
        \item Propositional Syntax
        \item Contractions to decide entailment
    \end{itemize}


    \section{Soft Activation: Markov Logic Networks}

    \charef{cha:probRepresentation}
    \begin{itemize}
        \item Exponential families
        \item Contractions to compute marginal probabilities
    \end{itemize}


    \section{Hybrid Logic Networks}

    Unification of both frameworks by allowing for arbitrary activation tensors.

\end{document}