\section{Generic Base Measures}

The definition of the Shannon entropy is dependent on the chosen base measure.
We now allow for generic non-Boolean base measures $\basemeasurewith$, which are non-negative and non-vanishing tensors.
We define
\begin{itemize}
    \item The set of by $\basemeasure$ representable distributions
    \begin{align*}
        \Gamma^{\basemeasure} = \{\probwith \wcols \uniquantwrtof{\shortcatindicesin}{\probat{\indexedshortcatvariables}>0} \ncond \contraction{\probwith,\basemeasurewith}=1 \ncond
        \contraction{\probwith,\oneswith-\basemeasurewith}=0
        \}
    \end{align*}
    \item The entropy of $\probwith\in\Gamma^{\basemeasure}$ by
    \begin{align*}
        \mathbb{H}^{\basemeasure}[\probtensor] = \contraction{\probwith,\lnof{\probwith},\basemeasurewith}
    \end{align*}
    \item The mean parameter of $\probwith\in\Gamma^{\basemeasure}$ with respect to the statistic $\sstat$ by
    \begin{align*}
        \meanparamwith = \contractionof{\probwith,\sencsstatwith,\basemeasurewith}{\selvariable}
    \end{align*}
    \item Polytope of mean parameters by
    \begin{align*}
        \meansetof{\sstat,\basemeasure} = \convhullof{\sencsstat{\indexedshortcatvariables,\selvariable} \wcols \basemeasureat{\indexedshortcatvariables}\neq 0}
    \end{align*}
    \item The maximum entropy problem by
    \begin{align*}
        \argmax_{\probtensor\in\Gamma^{\basemeasure}} \mathbb{H}^{\basemeasure}[\probtensor] \quad \text{subject to} \quad \meanparamwith = \contractionof{\probwith,\sencsstatwith,\basemeasurewith}{\selvariable}
    \end{align*}
\end{itemize}

The main theorem of this work generalizes to this situation, with minor changes in the proofs.


