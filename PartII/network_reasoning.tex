\chapter{\chatextnetworkReasoning}\label{cha:networkReasoning}

In this chapter we investigate the inference properties of Hybrid Logic Networks, exploiting the characterizations of the corresponding mean parameter polytopes in \charef{cha:networkRepresentation}.
We investigate unconstrained parameter estimated for Markov Logic Networks and Hybrid Logic Networks, which are special cases of the backward maps introduced in \charef{cha:probRepresentation}.
We then motivate structure learning based on sparsity constraints on the parameters on the minterm exponential family and present heuristic strategies leading to efficient structure learning algorithms.



\sect{Entropy Optimization on Hybrid Logic Networks} \label{sec:parameterEstimation} % Check for redundancy with the mln introduction chapter!

We will investigate two entropic approaches towards unconstrained parameter estimation.
First of all, we characterize Maximum Entropy distributions with a moment constraint.
Maximum Likelihood Estimation restricts the distributions optimized over to a specific set, here the Hybrid Logic Networks.

\subsect{Entropy Maximization}


The Maximum Entropy Problem $\probtagtypeinst{\entropysymbol}{\mlnstat,\basemeasure,\genmean}$ for a statistic $\mlnstat$ and a base measure $\basemeasure$ is %Markov Logic Networks is
\begin{align}\label{prob:maxEntropyHLN}
    %\custtag{\probtagtypeinst{\entropysymbol}{\mlnstat,\basemeasure,\genmean}}
    \argmax_{\probtensor\in\bmrealprobof{\basemeasure}} \quad \sentropyof{\probtensor}
    \quad \text{subject to} \quad
    \contractionof{\probtensor,\sencmlnstat}{\selvariable}
    =  \genmeanwith
    % & \hfill \probtagtypeinst{\entropysymbol}{\mlnstat,\basemeasure,\genmean}
    \tag{$\probtagtypeinst{\entropysymbol}{\mlnstat,\basemeasure,\genmean}$}
\end{align}

\begin{theorem}
    \label{the:maxEntropyCharacterizationHLN}
    Let $\genmeanwith\in\genmeanset$ and the minimal face of $\genmeanset$, which includes $\genmeanwith$, be $\genfaceset$, and let
    \begin{align*}
        \gencanparam = \backwardmapwrtof{\mlnstat,\hlnfacemeasure}{\genmeanwith} \, ,
    \end{align*}
    where $\backwardmapwrt{\mlnstat,\hlnfacemeasure}$ is a backward map in the exponential family $\expfamilyof{\mlnstat,\hlnfacemeasure}$.
    The solution of the Maximum Entropy Problem \probref{prob:maxEntropyHLN} is then
    \begin{align*}
        \probwith = \expdistof{(\mlnstat,\gencanparam,\hlnfacemeasure)} \, .
    \end{align*}
\end{theorem}
\begin{proof}
    Any feasible distribution has to be representable by $\hlnfacemeasure$, since $\genmeanwith\in\hlnfaceset$.
    The solution therefore coincides with the solution of the maximum entropy problem with respect to $\mlnstat$ and $\hlnfacemeasure$ as a base measure.
    Since $\genfaceset$ is minimal, $\meanparamwith$ is on the effective interior of the face and the claim follows with \theref{the:maxEntropyFace}.
\end{proof}

\theref{the:maxEntropyCharacterizationHLN} characterizes the solution of the Maximum Entropy Problem for arbitrary positions of the mean parameter.
Note, that if $\genmeanwith\notin\genmeanset$ then no distribution is feasible for \probref{prob:maxEntropyHLN} and there is no solution.
We are especially interested in situations, where the solution is a Hybrid Logic Network.
As we show next, this is exactly the case if the mean parameter is reproducable by a Hybrid Logic Network (see \secref{sec:HLNrepMean}).

\begin{theorem}
    Let $\genmeanwith$ be a mean parameter reproducable by a Hybrid Logic Network (see \defref{def:HLNrepMean}).
    Then the unique Hybrid Logic Network reproducing $\genmeanwith$ is the solution of the Maximum Entropy Problem \probref{prob:maxEntropyHLN}.
\end{theorem}
\begin{proof}
    We notice, that if $\genmeanwith$ is reproducable by a Hybrid Logic Network, then the normalization of the corresponding face measure $\hlnfacemeasure$ of the minimal face containing $\genmeanwith$ is a Hybrid Logic Network in $\elrealizabledistsof{\mlnstat}$.
    The solution of \probref{prob:maxEntropyHLN} characterized in \theref{the:maxEntropyCharacterizationHLN} is then also in $\elrealizabledistsof{\mlnstat}$.
\end{proof}


\subsect{Cross Entropy Minimization}

Different to Maximum Entropy Problems, we formulate the Maximum Likelihood Problem $\probtagtypeinst{\mathrm{M}}{\Gamma,\gendistribution}$ as cross entropy minimization with respect to Hybrid Logic Networks, that is
\begin{align}
    \tag{$\probtagtypeinst{\mathrm{M}}{\Gamma,\gendistribution}$}\label{prob:minCrossEntropyHLN}
    \argmin_{\probtensor\in\elrealizabledistsof{\mlnstat}} \centropyof{\gendistribution}{\probtensor}
\end{align}
When choosing $\gendistribution$ by an empirical distribution, this minimization problem is the Maximum Likelihood Problem (see \secref{cha:probReasoning}).
% LEMMA TO CHA:PROBREASONING?
In order to characterize the solution of the cross entropy minimization problem on Hybrid Logic Networks, we first characterize the solution of the cross entropy minimization on exponential families.

\begin{lemma}
    \label{lem:minCrossEntropyExponential}
    Let $\gendistributionwith$ be a distribution, $\mlnstat$ a boolean statistic, and choose a subset $\variableset\subset[\seldim]$ and a boolean tuple $\headindexof{\variableset}$.
    We build the mean parameter $\genmeanwith=\contractionof{\gendistributionwith,\sencmlnstatwith}{\selvariable}$ and have the following:
%    For any $\variableset\subset[\seldim]$ and boolean tuple $\headindexof{\variableset}$ we have
    \begin{itemize}
        \item[(1)] If $\genmeanwith \in \sbinteriorof{\meansetof{\mlnstat,\hlnformula}}$ then
            \begin{align*}
                \min_{\canparamwithin} \centropyof{\gendistribution}{\probtensorof{\mlnstat,\canparamwith,\hlnformula}}
                = -\sentropyof{\probtensorof{\mlnstat,\backwardmapwrtof{\mlnstat,\hlnformula}{\genmeanwith},\hlnformula}} \, .
            \end{align*}
        \item[(2)] If $\genmeanwith\in\closureof{\meansetof{\mlnstat,\hlnformula}}$ then there is a sequence $\left(\meanparamofat{n}{\selvariable}\right)_{n\in\nn}\subset\hlnmeanset$ converging coordinatewise to $\genmeanwith$ and
            \begin{align*}
                \min_{\canparamwithin} \centropyof{\gendistribution}{\probtensorof{\mlnstat,\canparamwith,\hlnformula}}
                = \lim_{\meanparamofat{n}{\selvariable}\rightarrow\genmeanwith}-\sentropyof{\probtensorof{\mlnstat,\backwardmapwrtof{\mlnstat,\hlnformula}{\meanparamofat{n}{\selvariable}},\hlnformula}} \, .
            \end{align*}
        \item[(3)] If $\genmeanwith\notin\closureof{\meansetof{\mlnstat,\hlnformula}}$ then
            \begin{align*}
                \min_{\canparamwithin} \centropyof{\gendistribution}{\probtensorof{\mlnstat,\canparamwith,\hlnformula}}
                = \infty \, .
            \end{align*}
    \end{itemize}
%    %$\meanparamwith\in\{0,0.5,1\}^\seldim$ we have
%    \begin{align*}
%        \min_{\canparamwithin} \centropyof{\gendistribution}{\probtensorof{\mlnstat,\canparamwith,\hlnformula}}
%        = \begin{cases}
%              -\sentropyof{\probtensorof{\mlnstat,\backwardmapwrtof{\mlnstat,\hlnformula}{\genmeanwith},\hlnformula}} & \text{if} \quad \genmeanwith \in \sbinteriorof{\meansetof{\mlnstat,\hlnformula}} \\
%              \lim_{\meanparamofat{n}{\selvariable}\rightarrow\genmeanwith}-\sentropyof{\probtensorof{\mlnstat,\backwardmapwrtof{\mlnstat,\hlnformula}{\meanparamofat{n}{\selvariable}},\hlnformula}} & \text{if} \quad \genmeanwith \in \closureof{\meansetof{\mlnstat,\hlnformula}} \\
%              \infty & \text{if} \quad \genmeanwith \notin \closureof{\meansetof{\mlnstat,\hlnformula}}
%        \end{cases} \, ,
%    \end{align*}
%    where in the second case, $\left(\meanparamofat{n}{\selvariable}\right)_{n\in\nn}$ denotes a sequence converging coordinatewise to $\genmeanwith$, for which $\uniquantwrtof{n\in\nn}{\meanparamofat{n}{\selvariable}\in\sbinteriorof{\meansetof{\mlnstat,\hlnformula}}}$ \\
\end{lemma}
\begin{proof}
    See Theorem~3.4 in \cite{wainwright_graphical_2008}.
\end{proof}

Based on this lemma we can characterize the solution of the Maximum Likelihood Problem \probref{prob:minCrossEntropyHLN} with respect to Hybrid Logic Networks.

\begin{theorem}
    Let $\gendistribution$ be any distribution, such that $\genmeanwith$ is reproducable by a Hybrid Logic Network.
    Then the solution of the Maximum Likelihood Problem \probref{prob:minCrossEntropyHLN} is the Hybrid Logic Network $\probtensorof{\mlnstat,\backwardmapwrtof{\mlnstat,\hlnformula}{\genmeanwith},\hlnformula}$.
\end{theorem}
\begin{proof}
    We exploit the parameterization of Hybrid Logic Networks by tuples $\hlnformulaparams$ (parametrizing the corresponding Hard Logic Network) and canonical parameters $\canparamwith$ (parametrizing the corresponding Markov Logic Network).
    The cross entropy minimization is then
    %We exploit the parameterization of Hybrid Logic Networks by hard parameters $\meanparamwith\in\{0,0.5,1\}^\seldim$ and by soft parameters $\canparamwithin$, to express \probref{prob:minCrossEntropyHLN} as
    \begin{align*}
        \min_{\variableset\subset[\seldim]}\min_{\headindexof{\variableset}\in\bigtimes_{\selindex\in\variableset}[2]} \left(\min_{\canparamwithin} \centropyof{\gendistribution}{\probtensorof{\mlnstat,\canparamwith,\hlnformula}}\right) \, .
%        \min_{\meanparamwith\in\{0,0.5,1\}^\seldim}\, .
    \end{align*}
    For any pair $\variableset,\headindexof{\variableset}$ we apply the lemma above and get a characterization of the inner minimum
    \begin{align*}
        \min_{\canparamwithin} \centropyof{\gendistribution}{\probtensorof{\mlnstat,\canparamwith,\hlnformula}}
    \end{align*}
    dependent on the stated tree cases.
    There is exactly one face $\genfaceset$, for which $\genmeanwith\in\sbinteriorof{\genfaceset}$ and by assumption of reproducability there is a parameter tuple $\hlnformulaparams$ such that $\hlnformula$ is the face measure of $\genfaceset$.
    For this parameter tuple we have
    \begin{align*}
        \min_{\canparamwithin} \centropyof{\gendistribution}{\probtensorof{\mlnstat,\canparamwith,\hlnformula}}
        = -\sentropyof{\probtensorof{\mlnstat,\backwardmapwrtof{\mlnstat,\hlnformula}{\genmean},\hlnformula}} \, .
    \end{align*}
    The following two arguments show that this is the minimum among all other faces.
    If for another tuple $\sechlnformulaparams$ we have $\genmeanwith\notin\bmrealprobof{\hlnformulaof{\sechlnformulaparams}}$ (i.e. the third case in \lemref{lem:minCrossEntropyExponential}) then the respective inner minimum is $\infty$ and the outer minimum is not taken.
    If for another tuple $\sechlnformulaparams$ we have $\genmeanwith\in\bmrealprobof{\hlnformulaof{\sechlnformulaparams}}$ but $\genmeanwith\notin\sbinteriorof{\genmeanset\cup\cubeface^{\sechlnformulaparams}}$ (i.e. the second case in \lemref{lem:minCrossEntropyExponential}), then the face $\genmeanset\cap\cubeface^{\hlnformulaparams}$ is contained in $\genmeanset\cap\cubeface^{\sechlnformulaparams}$ and the minimum is taken on that face.
\end{proof}


When $\genmeanwith$ is not reproduceable by a Hybrid Logic Network, we are in the case where the smallest face, such that $\genmeanwith$ is contained is not an intersection of $\genmeanset$ with a cube face.
In this case, there is no solution of the Maximum Likelihood Problem \probref{prob:minCrossEntropyHLN} in the set of Hybrid Logic Networks, since the minimum is not taken.
The reason for this lies in the expressivity problem of Hybrid Logic Networks, which do not reproduce the interior of such faces, but tend in a limit of large canonical parameters to any mean parameter on such faces.
We can instead state a Maximum Likelihood Problem over $\maxrealizabledistsof{\mlnstat}$, which provides enough expressivity to represent all faces.

\begin{theorem}
    Let $\gendistribution$ be any distribution, $\genmeanwith=\contractionof{\gendistribution,\sencmlnstatwith}{\selvariable}$ and $\genfaceset$ be the smallest face of $\genmeanset$, which contains $\genmeanwith$.
    Then the solution of the Maximum Likelihood Problem \probref{prob:minCrossEntropyHLN} over $\realizabledistsof{\mlnstat,\maxgraph}$ is $\probtensorof{\mlnstat,\backwardmapwrtof{\mlnstat,\hlnfacemeasure}{\genmeanwith},\hlnfacemeasure}$, where $\hlnfacemeasure$ is the face measure of $\genfaceset$.
\end{theorem}
\begin{proof}
    Again by application of \lemref{lem:minCrossEntropyExponential} on each face of $\genmeanset$.
    %The outer minimum is taken at the smallest face
\end{proof}


%%% OLD FROM HERE
%
%% Special example: MLE
%The Maximum Likelihood Problem on an exponential family with boolean statistics is the moment projection
%\begin{align*}
%    \argmin_{\canparamat{\selvariable}\in\rr^{\seldim}} \quad
%    \centropyof{\probtensor}{\expdistof{(\sstat,\canparam,\basemeasure)}}
%\end{align*}
%in the case $\probtensor=\empdistribution$ for a sample selector map $\datamap$.
%
%% Backward map
%The moment projection coincides with the backward map
%\begin{align*}
%    \argmax_{\canparamat{\selvariable}\in\rr^{\seldim}} \quad
%    \contraction{\canparamat{\selvariable},\meanparamwith} - \cumfunctionof{\canparamat{\selvariable}}
%\end{align*}
%where
%\begin{align*}
%    \meanparamwith
%    = \contractionof{\sencmlnstat,\probtensor}{\selvariable}
%    \quad \text{and} \quad
%    \cumfunctionof{\canparamat{\selvariable}}
%    = \contraction{\expof{ \contractionof{\sencodingofat{\formulaset}{\shortcatvariables,\selvariable},\canparamat{\selvariable}}{\shortcatvariables} }, \basemeasure} \, .
%\end{align*}
%
%% Extension to HLN
%We now extend the optimization to Hybrid Logic Networks, which are the union of exponential families with same statistics but different base measures.
%\begin{align*}
%    \argmin_{\secprobtensor\in\hlnsetof{\formulaset}} \quad
%    \centropyof{\probtensor}{\secprobtensor}
%\end{align*}
%
%\begin{corollary}
%    Let $\meanparamwith = \contractionof{\probtensor,\sencfset}{\selvariable}$ and
%    \[ \secformulaset = \{\enumformula \, : \, \meanparamat{\indexedselvariable} \in \{0,1\}\} \quad , \quad
%    \basemeasureofat{\secformulaset,\meanparam}{\shortcatvariables}
%    = \bigwedge_{\enumformula\in\secformulaset} \lnot^{(1-\meanparamat{\indexedselvariable})} \enumformulaat{\shortcatvariables}
%    \, . \]
%    If $\meanparamwith$ is reproduceable by a positive distribution with respect to $\basemeasureofat{\secformulaset,\meanparam}{\shortcatvariables} $, then the solution of the M-projection of $\probtensor$ onto the set of hybrid logic networks is representable by $\formulaset$ then coincides with the projection of $\probtensor$ onto $\expfamilyof{\formulaset/\secformulaset,\basemeasureof{\secformulaset,\meanparam}}$.
%\end{corollary}
%%\begin{proof}
%%	Work by weight cutoff, in the limit of hard logics?
%%\end{proof}


\sect{Alternating Algorithms to Approximate the Backward Map}\label{sec:alternatingParEstMLN}

Let us now introduce an implementation of the Alternating Moment Matching Algorithm~\ref{alg:AMM} in case of Markov Logic Networks.
To solve the moment matching condition at a formula $\enumformula$ we refine \lemref{lem:mmContractionEquation} in the following.

\begin{lemma}
    \label{ref:lemMMinMLN}
    Let there be a base measure $\basemeasure$, a formula selecting map $\formulaset=\{\enumformula \, : \, \selindexin\}$ and a canonical parameter $\canparam$, and choose $\selindexin$ such that $\enumformula  \notin \{\onesat{\shortcatvariables},\zerosat{\shortcatvariables}\}$.
    The moment matching condition relative to $\canparam$, $\selindexin$ and $\datameanat{\indexedselvariable}\in(0,1)$ is then satisfied, if
    \begin{align}
        \label{sol:momentMatchingExformula}
        \indexedcanparam = \lnof{
            \frac{\datameanat{\indexedselvariable}}{(1-\datameanat{\indexedselvariable})}
            \cdot \frac{\hypercoreat{\catvariableof{\enumformula }=0}}{\hypercoreat{\catvariableof{\enumformula }=1}}
        }
    \end{align}
    where by $\hypercoreat{\catvariableof{\enumformula }}$ we denote the contraction
    \begin{align*}
        \hypercoreat{\catvariableof{\enumformula}}
        = \contractionof{\{\bencodingof{\enumformula} \, : \, \selindexin\}
        \cup\{\actcoreof{\tilde{\selindex}} : \tilde{\selindex} \in [\seldim], \tilde{\selindex}\neq\selindex\}
        \cup\{\basemeasure\}}{\catvariableof{\enumformula}} \, .
    \end{align*}
\end{lemma}
\begin{proof}
    Since $\imageof{\enumformula}\subset[2]$ we have
    \begin{align*}
        \idrestrictedto{\imageof{\enumformula}} = \onehotmapofat{1}{\catvariableof{\enumformula}}
    \end{align*}
    and the moment matching condition is by \lemref{lem:mmContractionEquation} satisfied if
    \begin{align*}
        \contraction{\actcoreof{\selindex}, \onehotmapof{1}, \hypercore}
        = \contraction{\actcoreof{\selindex},\hypercore} \cdot \datameanat{\indexedselvariable} \, .
    \end{align*}
    This is equal to
    \begin{align*}
        \expof{\canparamat{\indexedselvariable}} \cdot \hypercoreat{\catvariableof{\enumformula}=1}
        = \left( \expof{\canparamat{\indexedselvariable}} \cdot \hypercoreat{\catvariableof{\enumformula}=1} + \hypercoreat{\catvariableof{\enumformula}=0} \right) \cdot \datameanat{\indexedselvariable} \, .
    \end{align*}
    Rearranging the equations this is equal to
    \begin{align*}
        \hypercoreat{\catvariableof{\enumformula}}
        = \contractionof{\{\bencodingof{\enumformula}\}
        \cup\{\actcoreof{\tilde{\selindex}} : \tilde{\selindex} \in [\seldim], \tilde{\selindex}\neq\selindex\}
        \cup\{\basemeasure\}}{\selvariable} \, .
    \end{align*}
    We notice that the right side is well defined, since we have by assumption $\datameanat{\indexedselvariable}, (1- \datameanat{\indexedselvariable}) \neq 0$ and $\hypercoreat{\catvariableof{\enumformula}=0}, \hypercoreat{\catvariableof{\enumformula}=1} \neq 0$ since Markov Logic networks are positive distributions and $\enumformula \notin \{\onesat{\shortcatvariables},\zerosat{\shortcatvariables}\}$.
\end{proof}


%% Hard network reference!
In the case $\datameanat{\indexedselvariable}\in\{0,1\}$ the moment matching conditions are not satisfiable for $\canparamat{\indexedselvariable}\in\rr$.
But, we notice, that in the limit $\canparamat{\indexedselvariable}\rightarrow \infty $ (respectively $-\infty$) we have
\[ \meanparamat{\indexedselvariable} \rightarrow  1 \quad \text{(respectively $0$)}\, ,  \]
and the moment matching can be satisfied up to arbitrary precision.
In \secref{sec:hardNetworks} we will allow infinite weights and interpret the corresponding factors by logical formulas.
As a consequence, we will able to fit graphical models, which we will call hybrid networks on arbitrary satisfiable mean parameters.

%
The cases $\hypercoreat{\catvariableof{\enumformula}=1}=0$, respectively $\hypercoreat{\catvariableof{\enumformula}=1}=0$ only appear for nontrivial formulas when the distribution is not positive.
This is not the case for Markov Logic Networks, but will happen when formulas are added as cores of a Markov Network.
This situation will has been investigated in \secref{sec:hardNetworks}.


% Concave likelihood 
Since the likelihood is concave (see \cite{koller_probabilistic_2009}), there are not local maxima the coordinate descent could run into and coordinate descent will give a monotonic improvement of the likelihood.

We suggest an alternating optimization by Algorithm~\ref{alg:AWO}, solving the moment matching equation iteratively for all formulas $\exformulain$ and repeat the optimization until a convergence criterion is met.
This is an coordinate ascent algorithm, when interpreted the loss $\lossof{\expdist}$ as an objective depending on the vector $\canparam$.

\begin{algorithm}[hbt!]
    \caption{Alternating Weight Optimization (AWO)}\label{alg:AWO} % Call it parameter instead?
    \begin{algorithmic}
%% INPUT: Numerated formula set, mean parameter $\datameanat{\selvariable}$
%\For{$\exformula\in\formulaset$}
        \Require Empirical distribution $\empdistribution$, boolean features $\mlnstat$ %and base measure $\basemeasure$
        \Ensure Canonical parameter $\canparamwith$, such that $\expdist$ is the (approximative) moment projection of $\empdistribution$ onto $\expfamily$
        \hrule
        \State Compute $\datameanat{\selvariable}= \contractionof{\empdistribution,\sencsstat}{\selvariable}$
        \State $\kb = \ones$, $\secnodes=\varnothing$
        \For{$\selindexin$}
            \If{$\meanparamat{\indexedselvariable}=1$}
                \[ \hardformulaset \algdefsymbol \hardformulaset \cup \{\enumformula\}\]
            \ElsIf
                    {$\meanparamat{\indexedselvariable}=0$}
                \[ \hardformulaset \algdefsymbol \hardformulaset \cup \{\lnot\enumformula\}\]
            \Else
                \State $\secnodes\algdefsymbol \secnodes \cup \{\selindex\}$
            \EndIf
        \EndFor
        \For{$\selindex\in\secnodes$}
            \State Compute
            \[ \hypercoreat{\catvariableof{\enumformula}}
            \algdefsymbol \contractionof{\bencodingof{\enumformula}}{\catvariableof{\enumformula}} \]
            \State Set
            \begin{align*}
                \canparamat{\indexedselvariable}
                \algdefsymbol \lnof{
                    \frac{\datameanat{\indexedselvariable}}{(1-\datameanat{\indexedselvariable})}
                    \cdot \frac{\hypercoreat{\catvariableof{\enumformula}=0}}{\hypercoreat{\catvariableof{\enumformula}=1}}
                }
            \end{align*}
        \EndFor
        \If {$\contraction{\kb}=0$}
            \State \textbf{raise} "Inconsistent Knowledge Base"
        \EndIf
        \While{Convergence criterion is not met}
            \For{$\selindex\in\secnodes$}
                \State Compute
                \begin{align*}
                    \hypercoreat{\catvariableof{\enumformula}}
                    = \contractionof{\{\bencodingof{\enumformula} \, : \, \selindexin\}
                    \cup\{\actcoreof{\tilde{\selindex}} : \tilde{\selindex} \in [\seldim], \tilde{\selindex}\neq\selindex\}
                    \cup\{\basemeasure\}}{\catvariableof{\enumformula}}
                \end{align*}
                \State Set
                \begin{align*}
                    \canparamat{\indexedselvariable} = \lnof{
                        \frac{\datameanat{\indexedselvariable}}{(1-\datameanat{\indexedselvariable})}
                        \cdot \frac{\hypercoreat{\catvariableof{\enumformula}=0}}{\hypercoreat{\catvariableof{\enumformula}=1}}
                    }
                \end{align*}
            \EndFor
        \EndWhile
        \State \Return $\canparamwith$
    \end{algorithmic}
\end{algorithm}

%
\red{The canonical parameters in \algoref{alg:AWO} converge, if and only if the mean parameter $\genmeanwith$ is reproducable by a Hybrid Logic Network.}


% Independent formulas
In the initialization phase of Algorithm~\ref{alg:AWO}, each parameters is initialized relative to a uniform distribution.
The algorithm would be finished, if the variables $\catvariableof{\exformula}$ are independent.
This would be the case, if the Markov Logic Network consists of atomic formulas only.
When they fail to be independent, the adjustment of the weights influence the marginal distribution of other formulas and we need an alternating optimization.
% 
This situation corresponds with couplings of the weights by a partition contraction, which does not factorize into terms to each formula.


% Inference
\red{
    Solving Equation~\ref{sol:momentMatchingExformula} requires inference of a current model by answering a query.}
This can be a bottleneck and circumvented by approximative inference, see e.g. CAMEL \cite{ganapathi_constrained_2008}.



\begin{remark}[Grouping of coordinates with trivial sum]
    When having a set of coordinates, such that the coordinate functions are boolean and sum to the trivial tensor, one can find simultaneous updates to the canonical parameters, such that the partition function is staying invariant.
    Given a parameter $\canparam^t$ we compute
    \[ \meanparam^t = \contractionof{\expdistof{(\sstat,\canparam^t)}, \sstat}{\selvariable} \]
    and build the update
    \[ \canparam^{t+1} = \canparam^t + \lnof{\meanparam^{\datamap}}{\meanparam^t} \, . \]
    Then, $\canparam^{t+1}$ satisfies the moment matching equations for all coordinates in the set.


    The assumptions are met when taking all features to any hyperedge in a Markov Network seen as an exponential family.
    In that case, the update algorithm is refered to as Iterative Proportional Fitting \cite{wainwright_graphical_2008}.
    Further, when activating both $\exformula$ and $\lnot\exformula$.

    \red{We will investigate these statistics as partition statistics in \secref{sec:partitionStatistics}.}
\end{remark}


\sect{Forward and backward mappings in closed form}

% Closed form availability
We recall from \charef{cha:probReasoning}, that while forward mappings are always in closed form by contractions, backward mapping in general do not have a closed form representation.
Instead, the backward map is in general implicitly characterized by a maximum entropy problem constrained to matching expected sufficient statistics.
We investigate in this section specific examples, where closed forms are available for both.
In these cases, parameter estimation can thus be solved by application of the inverse on the expected sufficient statistics with respect to the empirical distribution, and iterative algorithms can be avoided.

% Usage
%When the backward map $\backwardmap$ is available in closed form, we directly get optimal parameters by the inversion acting on the satisfaction rate and can avoid iterative algorithms of parameter estimation.

\subsect{Maxterms and Minterms}

Minterms (respectively maxterms) are ways in propositional logics to get a syntactical formula representation based on a formula to each world which is a model (respectively fails to be a model).
We have already studied in \secref{sec:MLNMaxMintermRep} how to represent any distribution as a MLN of maxterms (respectively minterms), see \theref{the:maximalClausesRepresentation}.

We use the tuple enumeration of the maxterms and minterms by $\atomstates$ introduced in \secref{sec:termClauseDecomposition}.
With respect to this enumeration the canonical parameters and mean parameters are tensors in $\bigotimes_{\atomenumeratorin}\rr^2$.
%% Interpretation of the mean parameters
Since the statistic of the minterm family is the identity, the mean parameters for the minterm family are
\[ \meanparamat{\selvariableof{[\atomorder]}=\catindexof{[\atomorder]}}
= \probat{\catindexof{[\atomorder]}}
\]
and therefore after a relabeling of categorical variables to selection variables $\meanparam=\probtensor$.
For maxterms we have analogously
\[ \meanparamat{\selvariableof{[\atomorder]}=\catindexof{[\atomorder]}}
= 1-\probat{\catindexof{[\atomorder]}}
\]
and $\meanparam = \onesat{}-\probtensor$.
We can use these insights to provide a characterization of the forward and backward maps of the minterm and maxterm family.

\begin{theorem}
    Given the Markov Logic Networks to the formula sets
    \[ \mintermformulaset := \{ \mintermof{\atomindices} \, : \, \atomindicesin\} \quad \text{and} \quad
    \maxtermformulaset := \{ \maxtermof{\atomindices} \, : \, \atomindicesin\}  \]
    of all minterms, respectively of all mapterms, the forward mapping are
    %\[ \forwardmapwrt{\mintermformulaset}: \bigotimes_{\atomenumeratorin}\rr^{2} \rightarrow \bigotimes_{\atomenumeratorin}\rr^{2} \]
    \[ \forwardmapwrt{\mlnmintermsymbol}(\canparam) = \normalizationofwrt{\expof{\canparam}}{\shortcatvariables}{\varnothing}
    \quad \text{and} \quad
    \forwardmapwrt{\mlnmaxtermsymbol}(\canparam) = \normalizationofwrt{\expof{-\canparam}}{\shortcatvariables}{\varnothing} \, , \]
    where in a slight abuse of notation we assigned the variables $\shortcatvariables$ to the canonical parameters $\canparam$.

    Possible choices of the backward mappings are
    %\[ \backwardmapwrt{\mlnmintermsymbol}: \bigotimes_{\atomenumeratorin}\rr^{2} \rightarrow \bigotimes_{\atomenumeratorin}\rr^{2} \]
    \[ \backwardmapwrt{\mlnmintermsymbol}(\meanparam) = \lnof{\meanparam}
    \quad \text{and} \quad
    \backwardmapwrt{\maxtermformulaset}(\meanparam) = -\lnof{\meanparam} \, .
    \]
\end{theorem}
\begin{proof}
    For the minterms we use that
    \[ \mintermformulaset[\shortcatvariables,\catvariableof{\mintermformulaset}]  = \identityat{\shortcatvariables,\catvariableof{\maxtermformulaset}}\]
    and get
    \[ \forwardmapwrt{\mlnmintermsymbol}(\canparam)
    = \normalizationof{
        \expof{\contractionof{\{\mintermformulaset, \canparam\}}{\shortcatvariables}}
    }{\shortcatvariables}
    =
    \normalizationof{\expof{\canparam}}{\shortcatvariables} \, .
    \]

    We notice that for any $\meanparam$ in the image of the forward map we have
    \[ \forwardmapwrt{\mlnmintermsymbol}(\backwardmapwrt{\mlnmintermsymbol}(\meanparam)) = \meanparam \]
    Therefore, $\backwardmapwrt{\mintermformulaset}$ is indeed a backward mapping to the exponential family of minterms.

    For the maxterms we use that
    \[ \maxtermformulaset[\shortcatvariables,\catvariableof{\maxtermformulaset}] = \onesat{\shortcatvariables,\catvariableof{\maxtermformulaset}}-\identityat{\shortcatvariables,\catvariableof{\maxtermformulaset}} \]
    and get
    \begin{align*}
        \forwardmapwrt{\mlnmaxtermsymbol}(\canparam)
        & = \normalizationof{
            \expof{\contractionof{\{\mintermformulaset, \canparam\}}{\shortcatvariables}}
        }{\shortcatvariables} \\
        & = \normalizationof{\{
        \expof{\contractionof{\{\ones, \canparam\}}{\shortcatvariables}},
            \expof{-\contractionof{\canparam}{\shortcatvariables}} \}
        }{\shortcatvariables} \\
        & = \normalizationof{
            \expof{-\canparam}
        }{\shortcatvariables}
    \end{align*}
    where we used, that $\expof{\contractionof{\{\ones, \canparam\}}{\shortcatvariables}}$ is a multiple of $\onesat{\shortcatvariables}$ and is thus eliminated in the normalization.
    For any $\meanparam\in\imageof{\forwardmapwrt{\mlnmaxtermsymbol}}$ we have
    \[ \forwardmapwrt{\mlnmaxtermsymbol}(\backwardmapwrt{\mlnmaxtermsymbol}(\meanparam) )
    = \meanparam
        %-\lnof{\expof{-\canparam}} + \contractionof{\expof{-\canparam}}{\varnothing} \cdot \onesat{\shortcatvariables}
        %= \canparam + \contractionof{\expof{-\canparam}}{\varnothing} \cdot \onesat{\shortcatvariables}
    \]
    and $\backwardmapwrt{\mlnmintermsymbol}$ is thus a backward map for the exponential family of maxterms.
\end{proof}

% Fitting arbitrary distributions
Any positive probability distribution can thus be fitted by minterms when we choose $\canparam=\lnof{\probtensor}$, respectively by maxterms when we choose $\canparam=\ones-\lnof{\probtensor}$.
Thus, we have identified a subset of $2^{\atomorder}$ formulas, which is rich enough to fit any distribution.





\subsect{Atomic formulas}

% Repeat atomic formulas
Let us now derive a closed form backward mapping for the statistic
\[ \atomformulaset := \{\atomicformulaof{\atomenumerator}: \atomenumeratorin\} \, . \]

The mean parameters coincide with the queries on the atomic formulas, that is the marginal
\[ \meanparamat{\selvariable=\atomenumerator} = \probat{\catvariableof{\atomenumerator}=1}  \, . \]

\begin{theorem}
    Given a Markov Logic Network with the statistic $\atomformulaset$ of atomic formulas, the forward mapping from canonical parameters to mean parameters is the coordinatewise sigmoid, that is
    \[ \forwardmapwrtof{\mlnatomsymbol}{\canparamat{\selvariable}} = \frac{\expof{\canparamat{\selvariable}}}{\onesat{\selvariable}+\expof{\canparamat{\selvariable}}}   \]
    where the quotient is performed coordinatewise.

    A backward mapping is the coordinatewise logit, that is
    \[ \backwardmapwrt{\mlnatomsymbol}(\meanparamwith)
    = \lnof{\frac{
        \meanparamwith
    }{
        \onesat{\selvariable}-\meanparamwith
    }}  \, . \]
\end{theorem}
\begin{proof}
    We have for any $\canparamat{\selvariable}\in\rr^{\atomorder}$
    \[ \probofat{(\atomformulaset,\canparam)}{\shortcatvariables}
    = \bigotimes_{\atomenumeratorin} \normalizationof{\expof{\canparamat{\selvariable=\atomenumerator}\cdot \atomicformulaof{\atomenumerator}}}{\catvariableof{\atomenumerator}}  \, . \]


    For any $\atomenumeratorin$ it therefore holds, that
    \begin{align*}
        \forwardmapwrtof{\mlnatomsymbol}{\canparamat{\selvariable}}[\selvariable=\atomenumerator]
        &=\contraction{\atomicformulaof{\atomenumerator},  \probofat{(\atomformulaset,\canparam)}{\shortcatvariables}} \\
        &=\contraction{\atomicformulaof{\atomenumerator},  \normalizationof{\expof{\canparamat{\selvariable=\atomenumerator}\cdot \atomicformulaof{\atomenumerator}}}{\catvariableof{\atomenumerator}}} \\
        & = \frac{\expof{\canparamat{\selvariable=\atomenumerator}}}{1+\expof{\canparamat{\selvariable=\atomenumerator}}} \, .
    \end{align*}

    Since the coordinatewise logit is the inverse function of the coordinatewise sigmoid the map
    \begin{align*}
        \backwardmapwrtof{\mlnatomsymbol}{\meanparamwith}[\selvariable=\atomenumerator]
        & = \lnof{\frac{\meanparamat{\selvariable=\atomenumerator}}{1- \meanparamat{\selvariable=\atomenumerator}}}
    \end{align*}
    satisfies for any $\meanparam$ in the image of the forward map
    \begin{align*}
        \forwardmapwrt{\mlnatomsymbol}(\backwardmapwrt{\mlnatomsymbol}(\meanparam)) = \meanparam
    \end{align*}
    and is therefore a backward map.
\end{proof}


% Representation by selection tensor networks
In a selection tensor networks they are represented by a single neuron with identity connective and variable selection to all atoms.
We will investigate such examples in more detail in \charef{cha:sparseRepresentation}, where atomic formulas Markov Logic Networks are specific cases of monomial decomposition of order 1.

% Interpretation of the result as independence approximation
The maximum likelihood estimator of a positive probability distribution by the MLN of atomic formulas is therefore the tensor product of the marginal distributions.
The Kullback-Leibler divergence between the distribution and its projection is the mutual information of the atoms, see for example Chapter~8 in \cite{mackay_information_2003}.

\begin{remark}[Decomposition into systems of atomic networks]
    \red{By Independence Decomposition we reduce to a system of atomic MLN.
    The minterms of such MLNs are the literals.
    By redundancy (literals sum up to $\ones$), it suffices to take only the positive or the negative literal.
    }
%	We set the weights of $\weightof{\lnot\atomicformulaof{\atomenumerator}}=0$ (corresponding with a gauge normalization of the energy offset symmetry). % Not needed!
\end{remark}






\sect{Constrained parameter estimation in the minterm family}

% Naive exponential family
We approach structure learning as constrained parameter estimation in the naive exponential family (see \secref{sec:mintermExpFamily}), which coincides with the minterm family $\formulasetof{\mlnmintermsymbol}$.
The minterm family is defined by the statistic $\sstat = \identityat{\shortcatvariables, \selvariableof{[\catorder]}}$ and has energy tensors coinciding with the canonical parameters.

% Convex polytope characterization
\red{For the minterm family, we have as mean parameter set the convex hull of one-hot encodings.
Each basis vector is an extreme point is an extreme point.
}


By \theref{the:mintermExpressivityMLN} all positive distributions are member of the minterm markov logic network family.
This expressivity result was generalized to arbitrary distributions, when allowing for formulas as basemeasures by \theref{the:mintermExpressivityHLN}.

Finding the distribution maximizing the likelihood of data would then be the empirical distribution.
In this case we would have $\datameanat{\selvariableof{[\catorder]}=\shortcatindices} = \empdistributionat{\shortcatvariables=\shortcatindices}$ and the maximum likelihood distribution is found by the problem
\begin{align*}
    \argmax_{\canparam\in\facspace}  \contraction{\canparam,\empdistribution} - \cumfunctionof{\canparam} \,
\end{align*}
which is solved at $\canparam=\lnof{\empdistribution}$ with $\probtensorof{(\identity,\lnof{\empdistribution})}= \empdistribution$.
This follows from $\lossof{\probtensorof{(\identity,\canparam)}}=\kldivof{\empdistribution}{\probtensorof{(\identity,\canparam)}}$, which is by Gibbs inequality minimized at $\probtensorof{(\identity,\canparam)}=\empdistribution$, which is the case for $\canparam = \lnof{\empdistribution}$.

We here allow for $\lnof{0}=-\infty$, with the convention of $\expof{-\infty}=0$, to handle datasets where specific worlds are not represented.
\red{Better: Use \theref{the:mintermExpressivityHLN} with basemeasure dropping non appearing data.}


% Regularization
To avoid this overfitting situation, we regularize by restricting the parameter to be a set $\energyhypothesis\subset\facspace$ and state
\begin{align}
    \tag{$\mathrm{P}_{\energyhypothesis, \empdistribution}$}\label{prob:restrictedNaiveMLE}
    \argmax_{\canparam\in\energyhypothesis}  \contraction{\canparam,\empdistribution} - \cumfunctionof{\canparam} \, .
\end{align}

Problem~\ref{prob:restrictedNaiveMLE} has two important types of instantiation, which we discuss in the next sections.

\subsect{Parameter Estimation}

% Parameter Estimation
\red{Projecting onto the markov logic family to the statistic $\formulaset$ is the instance of Problem~\ref{prob:restricedNaiveMLE} with the hypothesis choice}
%When the $\formulaset$ is known we take $\energyhypothesis$ as the linear hull 
\[ \energyhypothesisof{\formulaset} = \spanof{\{\formula : \formula\in\formulaset \}} \, . \]
Then, the problem is the parameter estimation problem studied in \secref{sec:parameterEstimation}.
To see this, we reparametrize by the coefficient vectors of the elements in the span, which are then understood as the canonical parameter of the respective distribution in the markov logic family to $\formulaset$.


\begin{remark}[Overparametrization]
    Taking $\formulaset$ to consist of all propositional formulas, we get a massive overparametrization:
    The essential statistics maps to a $2^{\left(2^\atomorder \right)}$ dimensional real vector space.
    All possible distributions of the $\atomorder$ atomic variables are mapped to an $2^\atomorder-1$ dimensional submanifold, where also the essential statistics maps to.

    Thus, to identify probabilistic knowledge bases, we need to drastically restrict the shape of formulas allowed.
    It is in principle impossible to decide which formulas to be activated, based only on statistics and not on prior assumptions.

    %The nodes of a Markov Propositional Network are all formulas in a propositional theory and the hyperedges all possible decompositons.
    When having $\atomorder$ atoms, there are $2^{\atomorder}$ states in the factored system.
    Since each state can either be a model of a formula or not, there are
    \[ \cardof{\formulaset} = 2^{\big(2^\atomorder \big)} \]
    formulas.
    Having, for example, $\atomorder=10$, then $\cardof{\formulaset}>10^{308}$.


    % Regularization by sparsity
    One regularization is by allowing only a small number of formulas to be active.
    This corresponds with regularization with $\sparsityof{\canparam}$.
    The problem is then non-convex.


    % Regularization by formula size
    A further regularization strategy is the restriction of the size of the possible formulas to maintain interpretability.
    Thus, we choose small formula selection networks.
\end{remark}




\subsect{Structure Learning}

% Structure Learning
The problem of structure learning arises, when the set of parameters in Problem~\ref{prob:restricedNaiveMLE} is choosen as
\[ \energyhypothesisof{\formulasuperset}= \bigcup_{\formulaset\in\formulasuperset} \spanof{\formulaset} \, .  \] %\energyhypothesisof{\formulaset}\, .
In this case, the problem in general fails to be convex.

% Subspace instuition
Each formula set $\formulaset$ represents a subspace in the parameters of the minterm family, which is spanned by the propositional formulas $\exformula\in\formulaset$.

%\red{Intuition by subspaces in the minterm parameters, which are selected by a nonlinear objective, to distinguish from compressed sensing.}







\sect{Greedy Structure Learning}


%Motivation 
It can be impracticle to learn all formulas at once, since the set $\formulasuperset$ often grows combinatorically, for example when choosing as a powerset of formulas.
\red{Further, we need to avoid overfitting and carefully choose a hypothesis.}
To avoid intractabilities and overfitting, one can choose a greedy approach and learn in addition formulas $\exformula$ when already having learned a set $\formulaset$ of formulas.
We in this section assume a current model $\currentdistribution$, which is a generic positive distribution not necessarily a Markov Logic Network. % or Hybrid Logic Network.

% 
We will use the effective selection tensor network representation of exponentially many formulas described in \charef{cha:formulaSelection} and select from them a small subset.

%\red{Alternative discussion: Can use current distribution as base measure and apply moment matching as first order condition.}


\subsect{Greedy formula inclusions}

Having a current set of formulas $\formulaset$ we want to choose the best $\formula\in\fselectionmap$ to extend the set of formulas to $\formulaset\cup\{\formula\}$ in a way minimizing the cross entropy.
Given this, add each step we solve the greedy cross entropy minimization
\begin{align}
    \label{prob:perfectGreedy}\tag{$\mathrm{P}_{\datamap,\formulaset,\fselectionmap}$}
    \argmin_{\formula\in\fselectionmap} \argmin_{\canparam\in\rr^{\cardof{\formulaset}+1}}
    \centropyof{\empdistribution}{\expdistof{(\formulaset\cup\{\formula\},\canparam,\basemeasure)}} \, .
\end{align}


A brute force solution would require parameter estimation for each candidate in $\fselectionmap$.
We provide two more efficient approximative heuristics in the following (see Chapter~20 in \cite{koller_probabilistic_2009}).


\subsect{Gain Heuristic}

In the gain heuristic, only the parameters of the new formula are optimized and the others left unchanged.
This amounts to
\begin{align}
    \label{prob:greedyGain}\tag{$\mathrm{P}^{\mathrm{gain}}_{\datamap,\formulaset,\fselectionmap}$}
    \argmin_{\formula\in\fselectionmap} \left ( \min_{\canparamat{\cardof{\formulaset}}\in\rr}
    \centropyof{\empdistribution}{\expdistof{(\formulaset\cup\{\formula\},\canparam,\basemeasure)}} \right) \, .
\end{align}
Here we denote by $\canparam$ the first $\cardof{\formulaset}$ coordinates of the M-projection $\currentdistribution$  of $\empdistribution$ onto $\formulaset$ and the variable new coordinate at position $\canparamat{\cardof{\formulaset}}$.

\begin{lemma}
    The gain heuristic objective is an upper bound on the true greedy objective.
\end{lemma}
\begin{proof}
    Since
    \begin{align*}
        &\argmin_{\formula\in\fselectionmap} \left( \argmin_{\canparam\in\rr^{\cardof{\formulaset}+1}}
        \centropyof{\empdistribution}{\expdistof{(\formulaset\cup\{\formula\},\canparam,\basemeasure)}} \right) \\
        &\quad \leq    \argmin_{\formula\in\fselectionmap} \left ( \argmin_{\canparamat{\cardof{\formulaset}}\in\rr}
        \centropyof{\empdistribution}{\expdistof{(\formulaset\cup\{\formula\},\canparam,\basemeasure)}} \right) \, .
    \end{align*}
\end{proof}


% Minterm family interpretation
Further, this is \probref{prob:restrictedNaiveMLE} in the case
\begin{align*}
    \energyhypothesis = \lnof{\currentdistribution} + \cup_{\formula\in\formulaset} \spanof{\formula} \, .
\end{align*}


% For single formula
Let us choose a formula $\formula\in\formulaset$ and consider Problem~\ref{prob:restrictedNaiveMLE}  in the case
\begin{align*}
    \energyhypothesisof{\formula} = \lnof{\currentdistribution} + \spanof{\formula} \, .
\end{align*}
This is parameter estimation on the exponential family with the single feature $\formula$ and the base measure $\currentdistribution$.
Therefore we can apply the theory of \charef{cha:probReasoning} and characterize the solution by the $\weight$ satisfying the moment matching condition
\begin{align*}
    \contraction{\currentdistribution, \normalizationof{\expof{\weight}}{\shortcatvariables} } = \contraction{\empdistribution, \formula} \, .
\end{align*}
We state the solution of this condition in the next theorem.

\begin{theorem}
    Problem~\eqref{prob:greedyGain} is solved at any
    \begin{align*}
        \hat{\canparam} = \weightof{\hat{\formula}} \cdot \hat{\formula}
    \end{align*}
    where the formula $\hat{\formula}$ is in
    \begin{align*}
        \hat{\formula} \in \argmax_{\formula\in\formulaset} \kldivof{\contraction{\empdistribution,\formula}}{\contraction{\currentdistribution,\formula}}
    \end{align*}
    and $\weightof{\hat{\formula}}$ is the weight of $\hat{\formula}$ in the solution of Problem~\ref{prob:restrictedNaiveMLE} with $\Gamma = \currentdistribution + \mathrm{span}(\exformula)$.
    Here we denote by $\kldivof{p_1}{p_2}$ the Kullback-Leibler divergence between Bernoulli distributions with parameters $p_1,p_2\in[0,1]$, that is
    \[ \kldivof{p_1}{p_2} = p_1 \cdot \lnof{\frac{p_1}{p_2}} + (1-p_1) \cdot \lnof{\frac{(1-p_1)}{(1-p_2)}}  \]
\end{theorem}
\begin{proof}
    % Solution of the problem restricted to
    For any formula $\formula$, the inner minimum of Problem~\eqref{prob:greedyGain} is by \lemref{ref:lemMMinMLN} taken at
    \[ \weightof{\formula} = \lnof{\frac{\datamean}{(1-\datamean)}\cdot \frac{(1-\currentmean)}{\currentmean}}  \]
    where
    \[ \currentmean = \contraction{\currentdistribution,\formula} \]
    and
    \[ \datamean = \contraction{\empdistribution,\formula} \, . \]

    The difference of the likelihood at the current distribution and the optimum is
    \begin{align*}
        \centropyof{\empdistribution}{\currentdistribution}
        - \centropyof{\empdistribution}{\expdistof{(\extendedformulaset,\extendedcanparam,\basemeasure)}}
        = \datamean \cdot \weightof{\formula} - \cumfunctionwrtof{\extendedformulaset,\basemeasure}{\extendedcanparam} \, .
    \end{align*}

    % Loss gain at optimum
    We use the representation scheme of Theorem~\ref{the:hybridNetworkRepresentation} and get % References has been overworked!
    \begin{align*}
        \contraction{\currentdistribution, \expof{\weightof{\formula} \cdot \formula}}
        & = \contraction{\currentdistribution, \bencodingofat{\formula}{\catvariableof{\formula}}, \actcoreofat{\formula}{\catvariableof{\formula}}} \\
        & = (1-\currentmean) + \currentmean\cdot \expof{\weightof{\formula}} \\
        & = (1 - \currentmean) + \frac{\datamean \cdot (1-\currentmean)}{(1-\datamean)} \\
        & = (1-\currentmean) \cdot \frac{1}{(1-\datamean)} \, .
    \end{align*}
    % Refining the cumulant term
    It follows, that
    \begin{align*}
        \cumfunctionwrtof{\extendedformulaset,\basemeasure}{\extendedcanparam}
        & = \lnof{\contraction{\currentdistribution, \expof{\weightof{\formula} \cdot \formula}}} \\
        & = \lnof{1-\currentmean} - \lnof{1-\datamean} \, .
    \end{align*}
    % Refining the mean product term
    We further have
    \begin{align*}
        \datamean \cdot \weightof{\formula}
        = \datamean \cdot \left[ \lnof{\frac{\datamean}{(1-\datamean)}\cdot \frac{(1-\currentmean)}{\currentmean}}  \right]
        = \datamean \lnof{\datamean} - \datamean \lnof{1-\datamean} + \datamean \lnof{1-\currentmean} - \datamean \lnof{\currentmean}
    \end{align*}
    and arrive at
    \begin{align*}
        & \centropyof{\empdistribution}{\currentdistribution}
        - \centropyof{\empdistribution}{\expdistof{(\exformula,\weightof{\formula},\currentdistribution)}} \\
        & \quad =  \datamean \lnof{\datamean} - \datamean \lnof{1-\datamean} + \datamean \lnof{1-\currentmean} - \datamean \lnof{\currentmean}
        -  \lnof{1-\currentmean} - \lnof{1-\datamean} \\
        & \quad = \left( -\datamean \lnof{\currentmean} - (1-\datamean) \lnof{1-\currentmean} \right)  - \left( -\datamean \lnof{\datamean} - (1-\datamean) \lnof{1-\datamean} \right) \, .
    \end{align*}
    By definition, this is the Kullback-Leibler divergence between Bernoulli distributions with parameters $\datamean$ and $\currentmean$.
    %
    Since the gain in the likelihood loss when restricting to $\energyhypothesis = \spanof{\formula}$ is thus given by $\kldivof{\contraction{\empdistribution,\formula}}{\contraction{\currentdistribution,\formula}}$, we have that Problem~\ref{prob:restrictedNaiveCE}  in the case $\energyhypothesis = \bigcup_{\formula\in\formulaset}\spanof{\formula}$ is solved at $\estcanparam = \weightof{\hat{\formula}}\cdot \hat{\formula}$ where
    \[ \hat{\formula} = \kldivof{\contraction{\empdistribution,\formula}}{\contraction{\currentdistribution,\formula}} \, . \]
\end{proof}

\red{Thus, we solve the grain heuristic with a coordinatewise transform of the mean parameter tensors to $\empdistribution$ and $\currentdistribution$, using the Bernoulli Kullback-Leibler divergence as transform function.}


% Interpretation
One therefore takes the formula, which marginal distribution in the current model and the targeted distribution are differing at most, measured in the KL divergence.

% Optimization method
One optimization method would thus be the computation of the mean parameters to both distribution, building the coordinatewise KL divergence and choosing the maximum.
Since we need to evaluate each coordinate, this can be intractable for large sets of formulas.


% Further weight optimization
Further improvement of the model can be achieved by iteratively optimizing the other weights as well, since their corresponding moment matching conditions might be violated after the integration of a new formula.
This would require the computation of backward mappings for each candidate formula, for which we only have an alternating approach in general.



\subsect{Gradient heuristic and the proposal distribution}

\red{Advantage: Might avoid formulawise calculus, when sampling from proposal distribution.
Brute force solution of gain heuristic require formulawise approach.}

We now derive a heuristic of choosing features based on the maximal coordinate of the gradient when differentiating the canonical parameter in the minterm family.
To prepare for this, we build the gradient of the loss
%For the naive exponential family 
\begin{align*}
    \lossof{\expdistof{(\naivestat, \naivecanparam)}}
    %= \frac{1}{\datanum} \sum_{\datindexin}\lnof{\expdistofat{(\naivestat, \naivecanparam)}{\shortcatvariables=\datamapat{\datindex}}}
    = \contraction{\empdistribution, \sencodingof{\naivestat}, \naivecanparam} - \lnof{\contraction{\expof{\contractionof{\sencodingof{\naivestat}, \naivecanparam}{\shortcatvariables}}}}
\end{align*}
as
\begin{align*}
    \gradwrt{\naivecanparamat{\selvariable}} \lossof{\expdistof{(\naivestat, \naivecanparam)}}
    &= \contractionof{\sencodingof{\naivestat},\empdistribution}{\selvariable} - \contractionof{\sencodingof{\naivestat},\expdistof{(\naivestat, \naivecanparam)}}{\selvariable} \\
    &= \empdistribution - \expdistof{(\naivestat, \naivecanparam)} \, .
\end{align*}

%% Single feature
%Given a feature $\exfunction[\shortcatvariables]$ we vary the naive parameters by a function on $\canparam\in\rr$ by
%\begin{align*}
%	 \naivestat(\canparam) %=  \mlntensor + \weight_{\selindices} \bencodingof{\exformula_{\selindices}}
%	= \naivestat(0) + \canparam\cdot\exfunction
%\end{align*}
%and get a likelihood gradient of
%\begin{align*}
%	 \frac{\partial \lossof{\expdistof{(\naivestat(\canparam), \naivecanparam)}}}{\partial\canparam} 
%	 &= \contraction{
%	 	\frac{\partial\lossof{\expdistof{(\naivestat, \naivecanparam)}}}{\partial\naivecanparam}|_{\naivecanparam(0)},
%		\frac{\partial\naivecanparam(\canparam)}{\partial\canparam} 
%	 }  \\
%	 &= \contraction{\empdistribution,\exfunction} -   \contraction{\expdistof{(\naivestat, \naivecanparam)},\exfunction} \, .
%\end{align*}


%% Positive and Negative Search
The gradient shows the typical decomposition into a positive and a negative phase.
While the positive phase comes from the data term and prefers directions of large data support, the negative phase originates in the partition function and draws the gradient away from directions already supported by the current model $\expdistof{(\naivestat, \naivecanparam)}$.
%% Regularization functionality
The negative phase is a regularization, by comparing with what has already been learned.
When nothing has been learned so far, we can take the current model to be the uniform distribution, which is the naive exponential family with vanishing canonical parameters.


%% Collection of features by selection
Given a set $\fselectionmap$ of features we vary $\naivecanparam$ by the function
\begin{align*}
    \exfunction(\canparam) = \naivecanparam + \contractionof{\canparam,\sencodingof{\fselectionmap}}{\shortcatvariables} \, .
\end{align*}
At $\canparam=0$ we have the gradient of the loss of the parametrized formula by
\begin{align*}
    \gradwrtat{\canparam}{0}
    \lossof{\expdistof{(\naivestat,\exfunction(\canparam),\basemeasure)}}
    &= \contraction{
        \gradwrtat{\exfunction(\canparam)}{\naivecanparam}  \lossof{\expdistof{(\naivestat,\exfunction(\canparam),\basemeasure)}},
        \gradwrtat{\canparam}{0}  \exfunction(\canparam)
    }  \\
    &= \contractionof{\empdistribution,\sencodingof{\sstat}}{\selvariable} -   \contractionof{\expdistof{(\naivestat, \naivecanparam, \basemeasure)},\sencodingof{\sstat}}{\selvariable} \, .
\end{align*}


%% Grafting
We want to choose the formula, which is best aligned with the gradient of the log-likelihood, that is using a formula selecting map $\fselectionmap$
\begin{align}
    \label{prob:greedyGrad} \tag{$\mathrm{P}^{\mathrm{grad}}_{\datamap,\formulaset,\fselectionmap}$}
    \argmax_{\selindex\in[\seldim]} \contractionof{\empdistribution,\fselectionmap}{\indexedselvariable}
    - \contractionof{\expdistof{(\naivestat, \naivecanparam, \basemeasure)},\fselectionmap}{\indexedselvariable} \, .
\end{align}
This method is known as the gradient heuristic or grafting.
% Mean parameter interpretation
The objective of Problem~\eqref{prob:greedyGrad} has another interpretation by the difference of the mean parameter $\datamean$ and $\currentmean$ of the projections of the empirical and current distributions on the family to $\fselectionmap$. % ! NOT the proposal family, those have transposed statistic

%% Formula alignment perspective
Problem~\eqref{prob:greedyGrad} is further equivalent to the formula alignment
\begin{align*}
    \argmax_{\formula\in\fselectionmap} \contraction{\formula,\empdistribution-\currentdistribution} \, .
\end{align*}
The objective can be interpreted as the difference of the satisfaction probability of the formula with respect to the empirical distribution and the current distribution.
%We can choose selection architectures to efficiently parametrize the formulas in the hypothesis $\fselectionmap$ and rewrite the problem as
%\begin{align*}
%	\argmax_{\selindexin} \contractionof{ \gradwrtat{\canparam}{\canparam=0} \lossof{\expdist}}{\indexedselvariable}
%\end{align*}
%This is thus equivalent to the problem \ref{prob:greedyGrad}, when taking all formulas selectable by $\formulaset$ as the hypothesis $\Gamma$.












\subsect{Iterations}

Let us now iterate the search for a best formula at a current model with the optimization of weights after each step.
The result is Algorithm~\ref{alg:greedyStructureLearning}, which is a greedy algorithm adding iteratively the currently best feature.

\begin{algorithm}[hbt!]
    \caption{Greedy Structure Learning}\label{alg:greedyStructureLearning}
    \begin{algorithmic}
        \Require Empirical distribution $\empdistribution$, hypothesis $\fselectionmap$ of formulas
        \Ensure Distribution $\expdist$ approximating $\empdistribution$
        \hrule
        \State Initialize
        \[ \currentdistribution \algdefsymbol \frac{1}{\prod_{\catenumeratorin}\catdimof{\atomenumerator}} \cdot \onesat{\shortcatvariables} \quad, \quad \formulaset = \varnothing \]
        \While{Stopping criterion is not met}
        % REFINE! Work in data
            \State
            \begin{itemize}
                \item \textbf{Structure Learning:} Compute a (approximative) solution $\hat{\formula}$ to Problem~\ref{prob:restrictedNaiveMLE} and add the formula to $\formulaset$, i.e.
                \[ \formulaset \algdefsymbol \formulaset \cup\{\hat{\formula}\} \]
                Extend dimension of $\selvariable$ by one, by $\formulaof{\seldim}=\hat{\formula}$ and $\canparamat{\seldim}=0$
                \item \textbf{Weight Estimation:} Estimate the best weights for the added formula and recalibrate the weights of the previous formulas, by calling Algorithm~\ref{alg:AWO}.
                \[ \currentdistribution \algdefsymbol \expdistof{\formulaset, \canparam} \]
            \end{itemize}
        \EndWhile
        \State \Return $\formulaset$, $\canparam$ %, $\kb$
    \end{algorithmic}
\end{algorithm}


%% Energy Storage -> Useful after learning for energy-based inference
When having used the same learning architecture multiple times, the energy of the corresponding formulas are all representable by a formula selecting architecture.
Their energy term is therefore a contraction of the selecting tensor with a parameter tensor $\canparam$ in a basis CP decomposition with rank by the number of learned formulas.
When mutiple selection architectures have been used, the energy is a sum of such contractions.
% 
Let us note, that this representation is useful after learning, when performing energy-based inference algorithms on the result.
During learning, one needs to instantiate the proposal distribution, which requires instantiation of the probability tensor.
\red{However, one could alternate data energy-based and use this as a particle-based proxy for the probability tensor.}


\begin{remark}[Sparsification by Thresholding]
    To maintain a small set of active formulas, one could combine greedy learning approaches with thresholding on the coordinates of $\canparam$.
    This is a standard procedure in Iterative Hard Thresholding algorithms of Compressed Sensing, but note that here we do not have a linear in $\canparam$ objective.
\end{remark}




\sect{Proposal distribution}


% Proposal distribution
Let us now understand the likelihood gradient as the energy tensor of a probability distribution, which we call the proposal distribution.

\begin{definition}[Proposal Distribution]
    Let there be a base distribution $\currentdistribution$, a targeted distribution $\empdistribution$ and a formula selecting map $\fselectionmap[\shortcatvariables, \selvariable]$.
    The proposal distribution at inverse temperature $\invtemp>0$ is the distribution of $\selvariable$ defined by
    \begin{align*}
        \normalizationof{\expof{\contractionof{\invtemp\cdot(\empdistribution-\currentdistribution),\fselectionmap}{\selvariable}} }{\selvariable} \, .
    \end{align*}
    The proposal distribution is the member of the exponential family with statistics $\fselectionmap$ and parameter $\invtemp\cdot(\empdistribution-\currentdistribution)$.
\end{definition}


%. Exponential family
The proposal distribution is in the exponential family with sufficient statistic by the formula selecting map $\fselectionmap$, namely the member with the canonical parameters $\canparam=\empdistribution-\currentdistribution$.
Of further interest are tempered proposal distributions, which are in the same exponential family with canonical parameters $\invtemp\cdot(\empdistribution-\currentdistribution)$ where $\invtemp>0$ is the inverse temperature parameter.

% MLN
As Markov Logic Networks, the proposal distributions are in exponential families with the sufficient statistic defined in terms of formula selecting maps.
While Markov Logic Networks contract the maps on the selection variables $\selvariable$, the proposal distributions contract them along the categorical variables $\catvariable$ to define energy tensors.

% Methods to solve mode search
The grafting Problem~\eqref{prob:greedyGrad} is the search for the mode of the proposal distribution.
To solve grafting, we thus need to answer a mode query, for which we can apply the methods introduced in \charef{cha:probReasoning}, such as Gibbs Sampling or Mean Field Approximations in combination with annealing.


\subsect{Mean parameter polytope}

The mean parameter polytope of the proposal distribution with statistic $\proposalstat$ is the convex hull of the formulas in $\formulaset$, that is
\begin{align*}
    \meansetof{\proposalstat}
    = \convhullof{\sencodingof{\proposalstat}{\indexedselvariable,\shortcatvariables} \, : \, \selindexin}
    = \convhullof{\formulaat{\shortcatvariables} \, : \, \formula\in\fselectionmap}
\end{align*}


% 0/1
As it was the case for Markov Logic Networks, the mean parameter polytopes are instances of a $0/1$-polytopes \cite{ziegler_lectures_2000,gillmann_01-polytopes_2007}.

% Interpretation as formulas
The extreme points are the formulas selectable by the formula selecting map $\fselectionmap$.


\sect{Discussion}

\begin{remark}[Bayesian approach]
    We only treated the estimation of a single resulting distribution by the data, while in a Bayesian approach one typically considers an uncertainty over possible distributions.
    % MAP
    \red{When treating $\canparam$ as a random tensor, which prior distribution is given and posteriori distribution wanted, we have a more involved Bayesian approach.}
    When having a prior $\probat{\mlnparameters}$ over the Markov Logic Networks we alternatively want to find the parameters $\mlnparameters$ solving the maximum a posteriori problem
    \begin{align}
        \argmax_{\mlnparameters} \mlnprobat{\data}\cdot \probat{\mlnparameters}\, .
    \end{align}
\end{remark}

To summarize some insights on the mean polytopes $\hlnmeanset$:
\begin{itemize}
    \item If and only f all coordinates are in $\{0,1\}$ then an extreme points, then $\meanparam$ is reproduced by a hard logic network.
    \item If some mean params in $\{0,1\}$, then not in the interior, and not reproduced by a markov logic network.
    Back direction not correct: There are interior points where no coordinate in $\{0,1\}$.
    \item If not in the interior, we can identify with base measure refinement a base measure, such that reproducable by a distribution representable by the base measure.
\end{itemize}


% Polytopes - MLN 
The polytopes of mean parameters to hybrid logic networks and proposal distributions are an interesting connection between the fields of combinatorical optimization and the study of expressivity of tensor networks.
% Minimal Connectivity: Local consitency - Hierarchical Tucker
This is of special interest, when the computation cores of a hybrid logic network are minimally connected, the mean parameters are captured by local consistencies.
Similar investigations have been made in the field of tensor networks, where minimal connected tensor networks are refered to by Hierarchical Tucker formats (HT).
Minimal connection is exploited in the tensor network community to show numerical properties of the format, such as closedness and existence of best approximators.














