\section{Probability Distributions}\label{cha:probDecomposition}

In this chapter we will establish relations between the formalism of tensor networks and basic concepts of probability theory.
We will first understand distributions as tensors and connect their marginalizations and conditionings to the tensor operations of contractions and normations.
Then we discuss independence assumptions as examples of contraction equations, which lead to tensor network decompositions known as graphical models.
We then treat more generic exponential families and investigate their representation as tensor networks.

\subsection{Tensor Representation of Distributions}

%% Random Variables: Introduction in Bayesian way by uncertainties
After having discussed how to represent states of factored systems by one-hot encodings, let us now take advantage of these representation by associating properties with these states.
Let there be uncertainties of the assignments $\catindexof{\atomenumerator}$ to the categorical variables $\catvariableof{\atomenumerator}$ of a factored system.
We then understand $\catvariableof{\atomenumerator}$ as random variables, which have a joint distribution defined by the uncertainties of the state assignments.
To capture these uncertainties we now make use of the one-hot representation of factored systems in Chapter~\ref{cha:factoredRepresentation}.

\begin{definition}[Probability Tensor] % From the axioms of Kolmogorov!
	Let there be a factored system defined by a categorical variable $\catvariableof{\atomenumerator}$ for each $\atomenumeratorin$ taking values in $[\catdimof{\atomenumerator}]$. 
	A probability distribution over the states of $\facsystem$ is a tensor
		\[ \probat{\catvariableof{0},\ldots,\catvariableof{\atomorder-1}} : \facstates \rightarrow [0, 1] \subset \rr \]
	such that
		\[ \sum_{\catindices\in\facstates} \probat{\indexedcatvariables} = 1 \, . \]
\end{definition}

We notice that there are two conditions for a tensor to be probability tensor.
First, the tensor needs to have non-negative coordinates and second, the coordinates need to sum to $1$.

%% One-hot Decomposition -> Contraction Equivalences
The probability tensor to the distribution is an object
		\[ \probat{\catvariables} \in \bigotimes_{\atomenumeratorin}\rr^{\catdimof{\atomenumerator}} \]
which is the sum over the one-hot encodings (see Lemma~\ref{lem:tensorBasisDecomposition})
		\[ \probat{\catvariables} = \sum_{\catindices\in\facstates} \probat{\indexedcatvariables} \cdot \onehotmapofat{\catindices}{\catvariables} \, . \]
		
%%
The normation condition of probability tensors can be expressed by the contraction equation $1= \sbcontraction{\probtensor}$ since
\begin{align*}
	1 = \sum_{\catindices}\probat{\indexedcatvariables}
	=  \sum_{\catindices}\sbcontraction{\probtensor, \onehotmapof{\catindices}}
	= \sbcontraction{\probtensor} \, . 
\end{align*}

%% NOT NEEDED
%Using the Coordinate Calculus as described in Theorem~\ref{the:coordinateCalculus} we can retrieve the coordinates of $\probtensor$ storing the probabilities of specific states by the contraction
%\begin{align*}
%	\probat{\indexedcatvariables} = \contractionof{\{\probtensor, \onehotmapof{\catindices}\}}{\varnothing} \, . 
%\end{align*}

%% Coordinates
%The probability tensor stores all probabilities on its coordinates, which are by construction
%	\[ \probtensor_{\catindices} = \probat{\catvariableof{\atomenumerator} = \catindexof{\atomenumerator} \, : \, \atomenumeratorin}  \, . \]
%We here draw on the redundancy of the one-hot encoding of each state of a factored system, which enables us to represent the properties of multiple states in single tensors (see Example~\ref{exa:onehotUncertainty}).

Probability tensors are depicted as
\begin{center}
	\input{PartI/tikz_pics/probability_decomposition/probability_tensor.tex}
\end{center}


\subsection{Marginal Distribution}

Contractions of probability distributions are related to marginalizations as we introduce next.

\begin{definition}[Marginal Probability]\label{def:marginalProbability}
	Given a distribution $\probat{\exrandom,\secexrandom}$ of the categorical variables $\exrandom$ and $\secexrandom$ the marginal distribution of the categorical variable $\exrandom$ is defined for each $\exrandind$ as the tensor
	\begin{align*}
		\probat{\exrandom} : [\exranddim] \rightarrow \rr
	\end{align*}
	defined for $\exrandind\in[\exranddim]$ by
	\begin{align*}
		\probat{\indexedexrandom} 
		= \sum_{\secexrandind\in[\secexranddim]} \probat{\indexedexrandom,\indexedsecexrandom} \, .
	\end{align*}
\end{definition}

% Sets of variables
Definition~\ref{def:marginalProbability} generalizes to marginalizations of sets of variables, since we can always group a set of categorical variables and understand them as a single one.

%% Contractions
\begin{theorem}\label{the:marginalContraction}
	%Given a Tensor Network (see Definition~\ref{def:tensorNetwork}) $\{\probtensor\}$ consistent of the variables $\exrandom,\secexrandom$ and hyperedge $\{\exrandom,\secexrandom\}$ decorated with the tensor $\probtensor$.
	For any distribution $\probat{\exrandom,\secexrandom}$ the marginal distribution of the variable $\catvariable$ is the contraction
	\begin{align*}
		\probat{\exrandom} = \sbcontractionof{\probtensor}{\exrandom} \, .
	\end{align*}
	Further, any marginal distribution is a probability distribution.
\end{theorem}
\begin{proof}
	We have $\probat{\exrandom} = \contractionof{\{\probtensor\}}{\exrandom}$ by definition.
	To show that $\probat{\exrandom}$ is a probability distribution, we need to show that $\sbcontraction{\probat{\exrandom}}=1$.
	But this follows from the normation of $\probtensor$ and the commutativity of contractions (see Theorem~\ref{the:splittingContractions} in Chapter~\ref{cha:localContractions}) as
		\[ \sbcontraction{\probat{\exrandom}} = 
		\sbcontraction{
			\sbcontractionof{\probtensor}{\exrandom}
		} =
		 \sbcontraction{\probtensor}
		= 1 \, . 
		\]
\end{proof}

%% Tensor Representation
We depict the sum over the possible values of $\secexrandom$ by contraction of the probability tensor with the trivial tensors $\ones$ as 
\begin{center}
	\input{PartI/tikz_pics/probability_decomposition/marginalized_probability.tex}
\end{center}
Let us notice, that marginal distributions are probability tensors for themself, which we again denote by a directed leg.
%We here omit the denotation of the nodes in the hypergraph of a Tensor Network and represent a Tensor Network just by the appearing Tensor Cores on the hyperedge.


\subsection{Conditional Probabilities}

Normations of probability distributions result in conditional distributions as we define next.

\begin{definition}[Conditional Probability]\label{def:conditionalProbability}
	Let $\probat{\exrandom,\secexrandom}$ be a distribution of the categorical variables $\exrandom$ and $\secexrandom$, such that $\probtensor$ is normable on $\{\secexrandom\}$.
	Then the distribution of $\exrandom$ conditioned on $\secexrandom$ is defined by
		\[ \condprobof{\indexedexrandom}{\indexedsecexrandom}  
		= \frac{\probat{\indexedexrandom,\indexedsecexrandom}}{\probat{\indexedsecexrandom}} \, . \]
\end{definition}

%The conditional probability
%	\[ \condprobof{\exrandom}{\indexedsecexrandom}  
%	= \frac{\probat{\exrandom,\indexedsecexrandom}}{\probat{\indexedsecexrandom}} \]
%is also a tensor with legs to $\exrandom$ and $\secexrandom$.
%For each one-hot encoding $\onehotmapof{\secexrandind}$ of the assignment $\secexrandind$ to the variable $\secexrandom$ we represent the conditional probability by the diagrams
%\begin{center}
%	\input{PartI/tikz_pics/probability_decomposition/conditional_probability.tex}
%\end{center}
%Here we denote by the quotient a coordinatewise normation, as sketched by the dashed unit vector. % is contracted before each normation, but we will omit it in future diagrams.
%We depict conditional variables by directed edges, where legs to conditions are incoming while the others outgoing.

%% Normation and Directed Notation
We show in the next theorem, that conditional distributions are calculated by normations.
%We will discuss operations on tensors like conditioning more detail in Chapter~\ref{cha:directedTC} as normation operation of Definition~\ref{def:normation}.
%In Theorem~\ref{the:conditionalContraction} we will show that the resulting tensor is directed with incoming variables by the conditions.

\begin{theorem}\label{the:conditionalContraction}
	The tensor $\condprobof{\exrandom}{\secexrandom}$ is the normation of $\probat{\exrandom,\secexrandom}$ on $\secexrandom$  (see Definition~\ref{def:normation}), that is
	\begin{align*}
		\condprobof{\exrandom}{\secexrandom}   
		= \sbnormationofwrt{\probtensor}{\exrandom}{\secexrandom} \, . 
	\end{align*}
	Further, for any $\secexrandind\in[\secexranddim]$ the tensor $\condprobof{\exrandom}{\indexedsecexrandom}$ is a probability tensor.
\end{theorem}
\begin{proof}
	The first claim follows from a comparison of Definition~\ref{def:conditionalProbability} and \ref{def:normation}.
	The second claim follows from the first and Theorem~\ref{the:normationDirected}.
	Alternatively, the second claim can be showed using the diagrammatic notation as
	\begin{center}
		\input{PartI/tikz_pics/probability_decomposition/proof_cond_normed.tex}
	\end{center}
\end{proof}



% Contraction Formalism
Theorem~\ref{the:marginalContraction} and \ref{the:conditionalContraction} show that the formalism of contractions and normations is applied in basic operations of probabilistic reasoning.

We can further show, that exactly the directed tensors with non-negative coordinates are conditional probability tensors.

\begin{theorem}\label{the:conditionalDirected}
	Any tensor with non-negative coordinates is a conditional distribution tensor, if and only if it is directed with the condition variables ingoing and the other outgoing.
\end{theorem}
\begin{proof}
	\proofrightsymbol:
	By Theorem~\ref{the:conditionalContraction} a conditional probability tensor $\condprobof{\exrandom}{\secexrandom}$ is the normation of a tensor and by Theorem~\ref{the:normationDirected} a directed tensor.
	Since probability tensors have only non-negative coordinates, their contractions with one-hot encodings also have only non-negative coordinates and also their normations. 
	
	\proofleftsymbol:
	Conversely, let $\hypercoreat{\nodevariables}$ be a directed tensor with $\innodes$ incoming and $\outnodes$ outgoing and non-negative coordinates.
	Then
	\begin{align}
		\probat{\nodevariables} = \frac{1}{\prod_{\node\in\innodes}\catdimof{\node}} \cdot \hypercoreat{\nodevariables}
	\end{align}
	is a probability tensor, since 
	\begin{align*}
		\sum_{\atomlegindexof{\innodes}} \sum_{\atomlegindexof{\outnodes}} \probat{\indexedcatvariableof{\nodes}} =
		\sum_{\atomlegindexof{\innodes}} \sum_{\atomlegindexof{\outnodes}} \frac{1}{\prod_{\node\in\innodes}\catdimof{\node}} \cdot \hypercoreat{\indexedcatvariableof{\nodes}} =
		\sum_{\atomlegindexof{\innodes}} \frac{1}{\prod_{\node\in\innodes}\catdimof{\node}} = 1 \, . 
	\end{align*}
	The conditional probability $\condprobof{\catvariableof{\outnodes}}{\catvariableof{\innodes}}$ coincides with $\hypercore$, since
	\begin{align*}
		\condprobof{\catvariableof{\outnodes}}{\indexedcatvariableof{\innodes}} 
		=& \frac{
		\probat{\catvariableof{\outnodes},\indexedcatvariableof{\innodes}}
		}{
		\sum_{\catindexof{\outnodes}} \probat{\indexedcatvariableof{\outnodes},\indexedcatvariableof{\innodes}}
		} \\
		=& \frac{
		\hypercoreat{\catvariableof{\outnodes},\indexedcatvariableof{\innodes}}
		}{
		\sum_{\catindexof{\outnodes}} \hypercoreat{\indexedcatvariableof{\outnodes},\indexedcatvariableof{\innodes}}
		} 
		= \hypercoreat{\catvariableof{\outnodes},\indexedcatvariableof{\innodes}} \, ,
	\end{align*}
	where in the last equation we used that the denominator is by definition trivial since $\hypercore$ is normed.
\end{proof}


Since conditional probabilities are directed tensors we therefore depict them by
\begin{center}
	\input{PartI/tikz_pics/probability_decomposition/ones_property_cond.tex}
\end{center}


%
Theorem~\ref{the:conditionalDirected} specifies a broad class of tensors to represent conditional probabilities.
In combination with Theorem~\ref{the:rencodingDirected}, which states that relational encodings are directed, we get that any relational encoding of a function is a conditional probability tensor.

\subsection{Bayes Theorem and the Chain Rule}

So far, we have connected concepts of probability theory such as marginal and conditional probabilities with contractions and normations of tensors.
We will now proceed to show that basic theorems of probability theory translate into more general contraction equations.

\begin{theorem}[Bayes Theorem]\label{the:bayes}
	For any probability distribution $\probat{\exrandom, \secexrandom}$ with positive $\probat{\secexrandom}$ we have
	\begin{align*}
		\probat{\exrandom,\secexrandom} 
		= \contractionof{\condprobof{\exrandom}{\secexrandom},\probat{\secexrandom}}{\exrandom,\secexrandom} \, . 
	\end{align*}
\end{theorem}
\begin{proof}
	Directly from the more generic contraction equation Theorem~\ref{the:normationContractionEQ}, since by assumption of positivity of $\probat{\secexrandom}$, the tensor network $\probtensor$ is normable with respect to $\secexrandom$.
\end{proof}


Probability distributions can be decomposed into conditional probabilities, as we demonstrate in the next theorem.

\begin{theorem}[Chain Rule]\label{the:chainRule}
	For any joint probability distribution $\probtensor$ of the variables $\probat{\catvariableof{0},\ldots,\catvariableof{\atomorder-1}}$ we have
	\begin{align*}
		\probtensor = \sbcontractionof{\condprobof{\catvariableof{\atomenumerator},\ldots,\catvariableof{\atomorder-1}}{\catvariableof{0},\ldots,\catvariableof{\atomenumerator-1}}\, : \, \atomenumeratorin\}}{\enumeratedatoms} 
	\end{align*}
	where for $\atomenumerator=0$ we denote by $ \condprobof{\catvariableof{0}}{\catvariableof{0},\ldots,\catvariableof{-1}}$ the marginal distribution $\probat{\catvariableof{0}}$.
\end{theorem}
\begin{proof}
	This follows from Theorem~\ref{the:genericChainRule}.
%	We apply Theorem~\ref{the:bayes} on the distribution
%	\begin{align*}
%	\condprobof{
%	\catvariableof{\atomenumerator},\ldots,\catvariableof{\atomorder}
%	}{
%	\indexedcatvariableof{1},\ldots,\indexedcatvariableof{\atomenumerator-1}
%	} \, ,
%	\end{align*}
%	where $\atomenumeratorin$ and $\catindexof{[\atomorder]}$ are chosen arbitrarly.
%	For any $\atomenumeratorin$ we get
%	\begin{align*}
%		%\contractionof{\{
%			\condprobof{\catvariableof{\atomenumerator},\ldots,\catvariableof{\atomorder-1}}{\catvariableof{1},\ldots,\catvariableof{\atomenumerator-1}}
%		%\}}{} 
%		= \contractionof{\{
%			\condprobof{\catvariableof{\atomenumerator+1},\ldots,\catvariableof{\atomorder-1}}{\catvariableof{1},\ldots,\catvariableof{\atomenumerator-1}},
%			\condprobof{\catvariableof{\atomenumerator}}{\catvariableof{1},\ldots,\catvariableof{\atomenumerator-1}}	
%		\}}{
%			\catvariableof{[\atomorder]} 
%		} \, .
%	\end{align*}
%	Applying this equation iteratively and making use of the commutation of contractions we get for any $\atomenumeratorin$
%	\begin{align*}
%		\condprobof{\catvariableof{\atomenumerator},\ldots,\catvariableof{\atomorder-1}}{\catvariableof{1},\ldots,\catvariableof{\atomenumerator-1}}
%		= \contractionof{\{
%			\condprobof{\catvariableof{\secatomenumerator}}{\catvariableof{1},\ldots,\catvariableof{\atomenumerator-1}} \, : \, \secatomenumerator = \atomenumerator, \atomenumerator +1 , \ldots \atomorder-1
%		\}}{
%			\catvariableof{[\atomorder]} 
%		} \, .
%	\end{align*}
%	For $\atomenumerator=0$, this is the claim.
\end{proof}






\subsection{Independent Variables}

Independence leads to severe simplifications of conditional probabilities and is thus the key assumption to gain sparse decompositions.
We will demonstrate this here applying the chain rule.

\begin{definition}[Independence]\label{def:independence}
	Given a joint distribution of variables $\exrandom$ and $\secexrandom$, we say that $\exrandom$ is independent from $\secexrandom$ if for any values $\exrandind,\secexrandind$ we have
		\[ \probat{\indexedexrandom,\indexedsecexrandom} 
		= \margprobof{\indexedexrandom}{\exrandom}
		 \cdot 
		 \margprobof{\indexedsecexrandom}{\secexrandom} \, . \]
\end{definition}

We give a criterion on independence based on a contraction equation of the probability distribution in the next theorem.

\begin{theorem}\label{the:independenceProductCriterion}
	Given a probability distribution $\probtensor$, $\exrandom$ is independent from $\secexrandom$, if and only if 
	\begin{align*}
		\probat{\exrandom,\secexrandom} 
		= \sbcontractionof{\contractionof{\probtensor}{\exrandom},\contractionof{\probtensor}{\secexrandom}}{\exrandom,\secexrandom} \, . 
	\end{align*}
\end{theorem}
\begin{proof}
	By Theorem~\ref{the:marginalContraction} we know that marginal probabilities are equivalent to contracted probability distributions, i.e. $\probat{\exrandom} = \contractionof{\{\probtensor\}}{\exrandom} $.
	By orthogonality of one-hot encodings we have that
	\begin{align*}
		\forall \exrandind, \secexrandind : \quad  \probat{\indexedexrandom,\indexedsecexrandom} 
		= \margprobof{\indexedexrandom}{\exrandom}
		 \cdot 
		 \margprobof{\indexedsecexrandom}{\secexrandom} 
	\end{align*}
	is equivalent to 
	\begin{align*}
		\sum_{\exrandind}\sum_{\secexrandind} \probat{\indexedexrandom,\indexedsecexrandom} \cdot \onehotmapofat{\exrandind}{\exrandom}\onehotmapofat{\secexrandind}{\secexrandom}
		= \sum_{\exrandind}\sum_{\secexrandind} 
		\margprobof{\indexedexrandom}{\exrandom}
		 \cdot 
		 \margprobof{\indexedsecexrandom}{\secexrandom} \cdot \onehotmapofat{\exrandind}{\exrandom}\onehotmapofat{\secexrandind}{\secexrandom} \, .
	\end{align*}
	We reorder the summations and arrive at
	\begin{align*}
		\sum_{\exrandind,\secexrandind} 
		\probat{\indexedexrandom,\indexedsecexrandom} \cdot \onehotmapofat{\exrandind,\secexrandind}{\exrandom, \secexrandom}
		= \left(\sum_{\exrandind}\margprobof{\indexedexrandom}{\exrandom} \onehotmapofat{\exrandind}{\exrandom} \right)
		\cdot 
		\left( \sum_{\secexrandind}  \margprobof{\indexedsecexrandom}{\secexrandom} \cdot \onehotmapofat{\secexrandind}{\secexrandom}  \right) 
	\end{align*}
	which is by Lemma~\ref{lem:tensorBasisDecomposition} equal to the claim
	\begin{align*}
		\probat{\exrandom,\secexrandom} = \sbcontractionof{\contractionof{\probtensor}{\exrandom},\contractionof{\probtensor}{\secexrandom}}{\exrandom,\secexrandom} \, . 
	\end{align*}
\end{proof}


% Usage for tensor decompositions
Independent variables result in decompositions of $\probtensor$ in a tensor product of marginal probability tensors. 
Having pairwise independent variables reduces the degrees of freedom from exponentially many in the number of atoms to linear.

In the tensor network decomposition we depict this by
	\begin{center}
		\input{PartI/tikz_pics/probability_decomposition/independent_decomposition.tex}
	\end{center}

Independence is a very strong assumption, which is often too restrictive.
Conditional independence instead is a less demanding assumption, when certain conditional distribution variables are independent. 
This leads to tensor network decompositions with a more realistic assumption.

\begin{definition}[Conditional Independence]\label{def:condIndependence}
	Given a joint distribution of variables $\exrandom$, $\secexrandom$ and $\thirdexrandom$, we say $\exrandom$ is independent from $\secexrandom$ conditioned on $\thirdexrandom$ if for any incides $\exrandind,\secexrandind$ and $\thirdexrandind$
		\[ \condprobof{\indexedexrandom,\indexedsecexrandom}{\indexedthirdexrandom} 
		= \condprobof{\indexedexrandom}{\indexedthirdexrandom} 
		\cdot \condprobof{\indexedsecexrandom}{\indexedthirdexrandom}   \, . \]
\end{definition}

Conditional independence is a relation between conditional probabilities and is therefore equivalent to a normation equation stated next.

\begin{theorem}[Conditional Independence as a Contraction Equation]\label{the:condIndependenceProductCriterion}
	Given a distribution $\probtensor$ of variables $\exrandom$, $\secexrandom$ and $\thirdexrandom$, the variable $\exrandom$ is independent from $\secexrandom$ if and only if the contraction equation
	\begin{align*}
		 \condprobof{\exrandom,\secexrandom}{\thirdexrandom} 
		 = \sbcontractionof{
		 \condprobof{\exrandom}{\thirdexrandom} ,\condprobof{\secexrandom}{\thirdexrandom} 
		 }{\exrandom,\secexrandom,\thirdexrandom}
	\end{align*}
	holds.
\end{theorem}
\begin{proof}
	Directly by Theorem~\ref{the:conditionalContraction} used on the conditional probabilities in Definition~\ref{def:condIndependence}.
\end{proof}

We can exploit conditional independence to find tensor network decompositions of probability tensors, as we show in the next theorem.

\begin{corollary}\label{cor:secCriterionCondIndepencence}
	If and only if $\exrandom$ is independent from $\secexrandom$ conditioned on $\thirdexrandom$ the probability distribution $\probtensor$ satisfies
		\[ \probat{\exrandom, \secexrandom, \thirdexrandom} 
		= \contractionof{
			\{ \condprobof{\exrandom}{\thirdexrandom}, \condprobof{\secexrandom}{\thirdexrandom}, \margprobof{\thirdexrandom}{\thirdexrandom} \}
		}{
			\exrandom, \secexrandom, \thirdexrandom
		} \, .
		\]
\end{corollary}
\begin{proof}
	Follows from Theorem~\ref{the:condIndependenceProductCriterion} and Theorem~\ref{the:bayes}.
%	We start with the chain rule decomposition of Theorem~\ref{the:chainRule} and have
%		\[ \probat{\exrandom,\secexrandom,\thirdexrandom} = \probat{\thirdexrandom}  \cdot \condprobof{\exrandom,\secexrandom}{\thirdexrandom} \]
%	Since $\exrandom$ is independent from $\secexrandom$ conditioned on $\thirdexrandom$ we have
%		\[ \condprobof{\exrandom,\secexrandom}{\thirdexrandom}  = \condprobof{\exrandom}{\thirdexrandom}  \cdot \condprobof{\secexrandom}{\thirdexrandom}  \, . \]
%	Converse direction similar.
\end{proof}


\begin{corollary}\label{cor:conditionDropping}
	Whenever $\exrandom$ is independent of $\secexrandom$ given $\thirdexrandom$, we have
	\begin{align*}
		\condprobof{\exrandom}{\secexrandom,\thirdexrandom} = \condprobof{\exrandom}{\thirdexrandom} \, .
	\end{align*}
\end{corollary}


\begin{figure}[h]
\begin{center}
	\input{PartI/tikz_pics/probability_decomposition/cond_independence_decomposition.tex}
\end{center}
\caption{Diagrammatic visualization of the contraction equation in Corollary~\ref{cor:secCriterionCondIndepencence}. Conditional independence of $\exrandom$ and $\secexrandom$ given $\thirdexrandom$ holds if the contraction on the right ride is equal to the probability tensor on the left side.}
\end{figure}



% More of an example?
\begin{theorem}[Markov Chain]\label{the:MarkovChain}
	Let there be a set of variables $\catvariableof{\tenumerator}$ where $\tenumeratorin$.
	When $\catvariableof{\tenumerator}$ is independent of $\catvariableof{0:{\tenumerator-2}}$ conditioned on $\catvariableof{\tenumerator-1}$ (the Markov Property), then
	\begin{align*}
		\probtensor = \contractionof{\{ \condprobof{\catvariableof{\tenumerator}}{\catvariableof{\tenumerator-1}}\, : \, \tenumeratorin \}}{
		\catvariableof{0},\ldots,\catvariableof{\tdim-1}
		} 
	\end{align*}	
%		\[ \probat{\catvariableof{0},\ldots,\catvariableof{\tdim-1}} = %\probat{\catvariableof{1}} 
%		\prod_{\tenumeratorin}Â \condprobof{\catvariableof{\tenumerator}}{\catvariableof{\tenumerator-1}} \, . \] 
	We depict this decomposition in Figure~\ref{fig:MC}.
\end{theorem}
\begin{proof}
	By the chain rule (Theorem~\ref{the:chainRule}) we have
	\begin{align*}
	 	\probat{\catvariableof{0},\ldots,\catvariableof{\tdim-1}}
		= \contractionof{
		\{ \condprobof{\catvariableof{\tenumerator}}{\catvariableof{0:\tenumerator}} : \tenumeratorin \}
		}{\catvariableof{[\tdim]}}
		%= \contractionof{\{\probat{\catvariableof{0}} \prod_{\tenumeratorin, \tenumerator>1} \condprobof{\catvariableof{\tenumerator}}{\catvariableof{0:\tenumerator}}\}{\catvariableof{[\tdim]}} \, . 
	\end{align*}
	Using the conditional independence of $\catvariableof{\tenumerator}$ and $\catvariableof{0:{\tenumerator-2}}$ conditioned on $\catvariableof{\tenumerator-1}$ we further have by Corollary~\ref{cor:conditionDropping}
		\[ \condprobof{\catvariableof{\tenumerator}}{\indexedcatvariableof{0:\tenumerator}}  = \condprobof{\catvariableof{\tenumerator}}{\indexedcatvariableof{\tenumerator-1}} \, .  \]
	Composing both equalities shows the claim.
\end{proof}

Here we denoted by $\catvariableof{0:\tenumerator}$ the tuple $\catvariableof{0},...,\catvariableof{\tenumerator}$.

\begin{remark}
	Let us notice that the dimensionality dropped drastically through applying the independence assumption.
	The tensor space in the naive representation of any probability distribution has
		\[ \prod_{\tenumeratorin} \catdimof{\tenumerator}\]
	coordinates, while the Markov Chain is represented by
		\[ \sum_{\tenumeratorin}  \catdimof{\tenumerator}\cdot \catdimof{\tenumerator-1} \, . \]
	Replacing exponential scaling with the number of variables to linear scaling is the advantage of tensor network decompositions.
\end{remark}

\begin{figure}[h]
\begin{center}
	\input{PartI/tikz_pics/probability_decomposition/markov_chain.tex}
\end{center}
\caption{Depiction of a Markov Chain. 
	a) Dependency Graph (of the corresponding chain Graphical Model).
	b) Dual Tensor Network representing the conditional probability factors.}
\label{fig:MC}
\end{figure}





\subsection{Graphical Models}



We have already depicted conditional dependency assumptions made for Markov Chains in Figure~\ref{fig:MC} and discussed the implied decomposition of the dual tensor networks.
Graphical models provide a more general framework for conditional dependency assumptions and provide a generic approach to exploit independences in finding tensor network decompositions of $\probtensor$.


%Graphical Models are typically depicted by nodes to each variable and edges.
Following the tensor network formalism we in this section introduce graphical models based on hypergraphs.
Whether the hypergraph is directed or not distinguished between Bayesian Networks and Markov Networks.




%\begin{remark}[Further nomenclature]
%	The factors of the graphical models are tensors (since multivariate functions of discrete variables).
%	The edges are associated to each axis of the tensor and carry the variables.
%	Since each edge variable can appear in multiple factors, the Tensor Network is defined on a Hypergraph, where edges are interpreted as Hadamard contractions.
%\end{remark}



\subsubsection{Markov Networks}

While typically Markov Networks are defined on graphs, we define them here on hypergraphs to establish a direct connection to tensor networks defined on the same hypergraph.
Along that line, Markov Networks are tensor networks with non-negative tensors (see Definition~\ref{def:tensorNetwork}), which are interpreted as probability distributions after normation.

\begin{definition}\label{def:markovNetwork}
	Let $\tnetof{\graph}$ be a Tensor Network of non-negative tensors on a hypergraph $\graph$.
	Then the Markov Network to $\tnetof{\graph}$ is the probability distribution of $\catvariableof{\node}$ defined by the tensor
		\[ \probofat{\graph}{\nodevariables} = \frac{
			\contractionof{\{\hypercoreof{\edge} : \edge \in \edges\}}{\nodevariables} 
		}{
			\contraction{\{\hypercoreof{\edge} : \edge \in \edges\}}
		} = \normationof{\tnetof{\graph}}{\nodevariables} \, . \] 
	We call the denominator
		\[\partitionfunctionof{\tnetof{\graph}} = \contraction{\{\hypercoreof{\edge} : \edge \in \edges\}} \]
	the partition function of the Markov Network.
\end{definition}

% Marginalization and Conditioning
Often, we are only interested in the distribution of a subset of variables, which are called the observable variables, and call the other variables hidden variables.
The marginalization of a Markov Network to $\tnetof{\graph}$ on the variables $\catvariableof{\secnodes}$ is
	\[
		\probofat{\graph}{\catvariableof{\secnodes}}
		= \normationof{\tnetof{\graph}}{\catvariableof{\secnodes}} \, . 
	\]
This can be derived from Theorem~\ref{the:splittingContractions}, which established an equivalence of contractions with sequences of consecutive contractions.


Further, the distribution of $\catvariableof{\secnodes}$ conditioned on $\catvariableof{\thirdnodes}$, where $\secnodes,\thirdnodes$ are disjoint subsets of $\nodes$, is
	\[
		\probtensor^{\graph}\left[ \catvariableof{\secnodes} | \catvariableof{\thirdnodes}\right] 
		= \normationofwrt{\tnetof{\graph}}{\catvariableof{\secnodes}}{\catvariableof{\thirdnodes}} \, . 
	\]

\begin{definition}[Separation of Hypergraph]
	A path in a hypergraph is a sequence of nodes $\node_{\atomenumerator}$ for $\atomenumeratorin$, such that for any $\atomenumerator\in[\atomorder-1]$ we find a hyperedge $\edge\in\edges$ such that $(\node_{\atomenumerator}, \node_{\atomenumerator+1})\subset \edge$.
	Given disjoint subsets $\nodesa$, $\nodesb$, $\nodesc$ of nodes in a hypergraph $\graph$ we say that $\nodesc$ separates $\nodesa$ and $\nodesb$ with respect to $\graph$, when any path starting at a node in $\nodesa$ and ending in a node in $\nodesb$ contains a node in $\nodesc$.
	%when removing the hyperedges which are contained in $\nodesc$ leads to a hypergraph with no path of hyperedges between a node in $\nodesa$ to a node in $\nodesb$.
\end{definition}

To characterize Markov Networks in terms of conditional independencies we need to further define the property of clique-capturing.
This property of clique-capturing established a correspondence of hyperedges with maximal cliques in an alternative graph-based definition of Markov Networks \cite{koller_probabilistic_2009}.

\begin{definition}[Clique-Capturing Hypergraph]\label{def:ccHypergraph}
	We call a hypergraph $\graph$ clique-capturing, when each subset $\secnodes\subset\nodes$ is contained in a hyperedge, if for any $a,b\in\secnodes$ there is a hyperedge $\edge\in\edges$ with $a,b\in\secnodes$.
\end{definition}

Let us now show a characterization of Markov Networks in terms of conditional independencies, which is analogous to Theorem~\ref{the:condIndBN}.

% Characterization
\begin{theorem}\label{the:condIndMN}
	Given a clique-capturing hypergraph $\graph$, the set of positive Markov Networks on the hypergraph coincides with the set of positive probability distributions, such that each for each disjoint subsets of variables $\nodesa$, $\nodesb$, $\nodesc$ we have $\catvariableof{\nodesa}$ is independent of $\catvariableof{\nodesb}$ conditioned on $\catvariableof{\nodesc}$, when $\nodesc$ separates $\nodesa$ and $\nodesb$ in the hypergraph. % called d-separation
\end{theorem}
\begin{proof}
	%=>
	%Given any Markov Network, contracting with $\onehotmapof{\atomlegindexof{\nodesc}}$ turns all hyperedges contained in $\nodesc$ to scalar factors (copying possible).
	Let there be a hypergraph $\graph$, a Markov Network $\extnet$ on $\graph$ and nodes $\nodesa,\nodesb,\nodesc \subset \nodes$, such that $\nodesc$ separates $\nodesa$ from $\nodesb$.
	Let us denote by $\nodes_0$ the nodes with paths to $\nodesa$, which do not contain a node in $\nodesc$, and by $\nodes_1$ the nodes with paths to $\nodesb$, which do not contain a node in $\nodesc$.
	Further, we denote by $\edges_0$ the hyperedges which contain a node in $\nodes_0$ and by $\edges_1$ the hyperedges which contain a node in $\nodes_1$.
	By assumption of separability, both sets $\edges_0$ and $\edges_1$ are disjoint and no node in $\nodesa$ is in a hyperedge in $\edges_1$, respectively no node in $\nodesb$ is in a hyperedge in $\edges_0$, .
	We then have
	\begin{align*}
		\normationofwrt{\extnetasset}{\catvariableof{\nodesa},\catvariableof{\nodesb}}{\indexedcatvariableof{\nodesc}} 
		= & \normationof{\extnetasset\cup\{\onehotmapof{\catindexof{\nodesc}}\}}{\catvariableof{\nodesa},\catvariableof{\nodesb}} \\
		= &  \normationof{\{\hypercoreof{\edge}\, : \, \edge\in\edges_0\}\cup\{\onehotmapof{\catindexof{\nodesc}}\}}{\catvariableof{\nodesa}}
		\otimes \normationof{\{\hypercoreof{\edge}\, : \, \edge\in\edges_1\}\cup\{\onehotmapof{\catindexof{\nodesc}}\}}{\catvariableof{\nodesb}} \, .
	\end{align*}
	By Theorem~\ref{the:condIndependenceProductCriterion}, it now follows that $\catvariableof{\nodesa}$ is independent of $\catvariableof{\nodesb}$ conditioned on $\catvariableof{\nodesc}$.
	%<= HARDER! Hammersley Clifford needed
	The converse direction, i.e. that positive distributions respecting the conditional indpendence assumptions are representable as Markov Networks, is known as the Hammersley Clifford Theorem, 
	which we will proof later in Section~\ref{sec:proofHCTheorem}.
	%for which proof we refer to Theorem~4.8 in KOLLER.
\end{proof}

% Positivity
From the proof of Theorem~\ref{the:condIndMN} Markov Networks with zero coordinates still satisfy the conditional independence assumption.
However, the reverse is not true, that is there are distributions with vanishing coordinates, which satisfy the conditional independence assumptions, but cannot be represented as a Markov Network (see Example~4.4 in \cite{koller_probabilistic_2009}).




\subsubsection{Bayesian Networks}

Bayesian networks are described by directed acyclic graphs (DAG).
The probability distribution is a Hadamard product of conditional probabilities, where each variable has a conditional probability factor conditioned on the parents variables in the graph.

We introduce Bayesian Networks based on directed hypergraphs (see Definition~\ref{def:hypergraphs}) and define further properties.

\begin{definition}
%% Already in notation chapter 
%	A directed hypergraph is a tuple $\graph=(\nodes,\edges)$ of nodes $\nodes$ and hyperedges $\edges$, where each hyperedge $\edge\in\edges$ is a tuple
%		\[ \edge = (\incomingnodes,\outgoingnodes) \]
%	of disjoint sets of incoming nodes $\incomingnodes\subset\nodes$ and outgoing nodes $\outgoingnodes\subset\nodes$.
	A directed path is a sequence $\node_{0},\ldots\node_{\secatomorder}$ such that for any $\secatomenumeratorin$ there is an hyperedge $\edge=(\incomingnodes,\outgoingnodes)\in\edges$ such that $\node_{\secatomenumerator}\in\incomingnodes$ and $\node_{\secatomenumerator+1}\in\outgoingnodes$.
	We call the hypergraph $\graph$ acyclic, if there is no path with $\secatomorder>0$ such that $\node_{0}=\node_{\secatomorder}$.
	Given a directed hypergraph $\graph=(\nodes,\edges)$ we define for any node $\nodein$ its parents by
		\[ \parentsof{\node} = \{\secnode \, : \, \exists\edge=(\incomingnodes,\outgoingnodes)\in\edges: \secnode\in\incomingnodes,\node\in\outgoingnodes \} \]
	and its non-descendants $\nondescendantsof{\node}$ as the set of nodes $\secnode$, such that there is no directed path from $\node$ to $\secnode$.
\end{definition}

\begin{definition}
	%Let $\nodes$ be a set of nodes decorated by dimensions and 
	Let $\graph=(\nodes,\edges)$ be a directed acyclic hypergraph with edges of the form 
		\[ \edges = \{(\parentsof{\node},\{\node\}) \, : \, \nodein\} \, . \]
%	and for each node $\node\in\nodes$ a random variable $\catvariableof{\node}$.
	A \emph{Bayesian Network} is a decoration of each edge $(\parentsof{\node},\{\node\})$ by a conditional probability distribution
	%Further let there be for each node $\node\in\nodes$ with parents $\parentsof{\node}$ a conditional probability distribution
		\[ \condprobof{\catvariableof{\node}}{\catvariableof{\parentsof{\node}}} \]
	which represents the probability distribution
%	Then the \emph{Bayesian Network} with respect to $\graph$ and the conditional probability terms is the distribution
	\begin{align*}
		\probat{\nodevariables} = \contractionof{\{\condprobof{\catvariableof{\node}}{\catvariableof{\parentsof{\node}}} \, : \, \nodein\}}{\nodevariables} \, .
	\end{align*}
%		\[ \probat{\catvariableof{\node} \, : \, \node\in\nodes } = \prod_{\node\in\nodes} \condprobof{\catvariableof{\node}}{\catvariableof{\parentsof{\node}}} \, . \]
\end{definition}

%
By definition each tensor decorating a hyperedge is directed with $\catvariableof{\parentsof{\node}}$ incoming and $\catvariableof{\node}$ outgoing.
Thus, the directionality of the hypergraph is reflected in each tensor decorating a directed hyperedge.
This allows us to verify with Theorem~\ref{the:conditionalContractionPreservation} that their contraction defines a probability distribution.

% Contraction -> Now in definition!
%By definition we can represent a Bayesian network by the contraction
%\begin{align*}
%	\probtensorof{\graph} = \sbcontractionof{\{ \condprobof{\catvariableof{\node}}{\catvariableof{\parentsof{\node}}} \, : \, \node\in\nodes\}}{\nodes} \, . 
%\end{align*}

% Dual
%The dual tensor network consists of conditional probability distributions to each node $\node\in\nodes$ (see Figure~\ref{fig:BayesianFactor}b).

\begin{figure}[h]
\begin{center}
	\input{PartI/tikz_pics/probability_decomposition/bayesian_factor.tex}
\end{center}
\caption{Example of a Factor of a Bayesian Network to the node $\catvariableof{\node}$ with parents $\catvariableof{0},\ldots,\catvariableof{\catorder-1}$, as subgraph $a)$ and dual tensor core $b)$.}
\label{fig:BayesianFactor}
\end{figure}


%% Marginalization and Contraction
Marginalization of a Bayesian Network are still Bayesian Networks on a graph where the edges directing to variables, which are not marginalized over, are replaced by directed edges to the children.
Conditioned Bayesian Network do not have a simple Bayesian Network representation, which is why we will treat them as Markov Networks to be introduced next.


\begin{theorem}[Independence Characterization of Bayesian Networks]\label{the:condIndBN}
	A probability distribution $\probat{\nodevariables}$ has a representation by a Bayesian Network on a directed acyclic graph $\graph=(\nodes,\edges)$, if and only if for any $\nodein$ the variables $\catvariableof{\node}$ are independent on $\nondescendantsof{\node}$ conditioned on $\parentsof{\node}$.
\end{theorem}
\begin{proof}
	We choose a topological order $\prec$ on the nodes of $\graph$, which exists since $\graph$ is acyclic.
	% =>
	Let us assume, that the conditional independencies are satisfied and apply the chain rule with respect to that ordering to get
	\begin{align*}
		\probat{\nodevariables} =
		\contractionof{
			\condprobof{\catvariableof{\node}}{\catvariableof{\secnode} : \secnode \prec \node}
		}
		{\nodevariables} \, .
	\end{align*}
	Since $\prec$ is a topological ordering we have
		\[ \parentsof{\node} \subset \{\secnode : \secnode \prec \node\} \]
	We apply the assumed conditional independence with Corollary~\ref{cor:conditionDropping} and get
	\begin{align*}
		\probat{\nodevariables} =
		\contractionof{
			\condprobof{\catvariableof{\node}}{\catvariableof{\parentsof{\node}}}
		}
		{\nodevariables} \, .
	\end{align*}
	% <=
	To show the converse direction, let there be a Bayesian Network $\probat{\nodevariables}$ on $\graph$.
	To show for any node $\node$, that $\catvariableof{\node}$ is independent of $\nondescendantsof{\node}$ conditioned on $\parentsof{\node}$, we reorder the tensors in the contraction
	%with respect to a set $\node_0$ 
	\begin{align*}
		& \condprobof{\catvariableof{\node},\catvariableof{\nondescendantsof{\node}}}{\indexedcatvariableof{\parentsof{\node}}} \\
		& \quad\quad = \normationofwrt{
			\{\condprobof{\catvariableof{\secnode}}{\catvariableof{\parentsof{\secnode}}} \, : \, \secnode\in\nodes\}
		}
		{\catvariableof{\node},\catvariableof{\nondescendantsof{\node}}}
		{\indexedcatvariableof{\parentsof{\node}}} \\
		& \quad\quad  = \normationof{
			\{\condprobof{\catvariableof{\secnode}}{\catvariableof{\parentsof{\secnode}}} \, : \, \secnode\in\nodes\} \cup \{\onehotmapof{\catindexof{\parentsof{\node}}}\}
		}
		{\catvariableof{\node},\catvariableof{\nondescendantsof{\node}}}\\
		&  \quad\quad = \normationof{
			\{\condprobof{\catvariableof{\secnode}}{\catvariableof{\parentsof{\secnode}}} \, : \, \secnode\in\nondescendantsof{\node}\} \cup \{\onehotmapof{\catindexof{\parentsof{\node}}}, \condprobof{\catvariableof{\node}}{\catvariableof{\parentsof{\node}}} \}
		}
		{\catvariableof{\node},\catvariableof{\nondescendantsof{\node}}} \\
		&  \quad\quad =  %\contractionof{
		 \normationof{
			\{\condprobof{\catvariableof{\secnode}}{\catvariableof{\parentsof{\secnode}}} \, : \, \secnode\in\nondescendantsof{\node}\} \cup \{\onehotmapof{\catindexof{\parentsof{\node}}}\}
		}
		{\catvariableof{\nondescendantsof{\node}}} \\
		& \quad\quad  \quad  \cdot \normationof{
			\{\condprobof{\catvariableof{\node}}{\catvariableof{\parentsof{\node}}},\onehotmapof{\catindexof{\parentsof{\node}}}\}
		}
		{\catvariableof{\node}} \\
		& \quad\quad  = \contractionof{\{
		\condprobof{\catvariableof{\nondescendantsof{\node}}}{\indexedcatvariableof{\parentsof{\node}}},
		\condprobof{\catvariableof{\node}}{\indexedcatvariableof{\parentsof{\node}}}
		\}}{\catvariableof{\node},\catvariableof{\nondescendantsof{\node}}}
		%}{\catvariableof{\node},\catvariableof{\nondescendantsof{\node}}}
	\end{align*}
	Here we have dropped in the third equation all tensors to the descendants, since their marginalization is trivial (which can be shown by a leaf-stripping argument).
	In the fourth equation we made use of the fact, that any directed path between the non-descendants and the node is through the parents of the node.
	By Theorem~\ref{the:condIndependenceProductCriterion}, it now follows that $\catvariableof{\node}$ is independent of $\nondescendantsof{\node}$ conditioned on $\parentsof{\node}$.
\end{proof}



\subsubsection{Example of a Bayesian Network: Hidden Markov Models}

We here extend the example of Markov Chains from Theorem \ref{the:MarkovChain} to a limited observation of the variables by observations.
Let there be the variables $\catvariableof{\tenumerator}$ (states) and $\randomeof{\tenumerator}$ (observations) with a discrete and finite time $\tenumeratorin$.

The conditional assumptions are 
\begin{itemize}
	\item $\catvariableof{\tenumerator+1}$ is independent of $\catvariableof{0:\tenumerator-1}$ and $\randomeof{0:\tenumerator}$ conditioned on $\catvariableof{\tenumerator}$
	\item $\randomeof{\tenumerator}$ is independent of all other variables conditioned on $\catvariableof{\tenumerator}$
\end{itemize}

Then the probability tensor has the decomposition 
\begin{align}
	\probat{\catvariableof{0:\tdim},\randomeof{0:\tdim}} 
	& = \prod_{\tenumeratorin}
	 \left( \condprobof{\catvariableof{\tenumerator}}{\catvariableof{0:\tenumerator-1},\randomeof{0:\tenumerator-1}} \cdot \condprobof{\randomeof{\tenumerator}}{\catvariableof{0:\tenumerator},\randomeof{0:\tenumerator-1}} \right) \\
	& = \probat{\catvariableof{0}} \cdot \condprobof{\randomeof{0}}{\catvariableof{0}} \cdot \prod_{\tenumeratorin, \tenumerator>0} 
	\left( \condprobof{\catvariableof{\tenumerator}}{\catvariableof{\tenumerator-1}} \cdot \condprobof{\randomeof{\tenumerator}}{\catvariableof{\tenumerator}} \right)
\end{align}
Here we used the Chain Rule decomposition of Theorem~\ref{the:chainRule} in the first equation and the conditional independence assumptions in the second.

We notice, that this is a Bayesian Netowork on a directed acyclic hypergraph $\graph$ consistent in nodes to each state and each observation and directed hyperedges
\begin{itemize}
	\item $(\{\catvariableof{\tenumerator}\}, \{\catvariableof{\tenumerator+1}\})$ for $\tenumerator\in[\tdim-1]$
	\item $(\{\catvariableof{\tenumerator}\}, \{\randomeof{\tenumerator}\})$ for $\tenumeratorin$
\end{itemize}


\begin{figure}[h]
\begin{center}
	\input{PartI/tikz_pics/probability_decomposition/hidden_markov_model.tex}
\end{center}
\caption{Depiction of a Hidden Markov Model. 
	a) Dependency Graph (of the corresponding chain Graphical Model).
	b) Dual Tensor Network representing the conditional probability factors.}
\label{fig:HMM}
\end{figure}



\subsubsection{Bayesian Networks as Markov Networks}

Markov Networks are more flexible compared with Bayesian Networks, since any Bayesian Network is a Markov Network by ignoring the directionality of the hypergraph and understanding the conditional distributions as generic tensor cores.
In the next theorem we provide the conditions for the interpretation of a Markov Network as a Bayesian Network.

\begin{theorem}\label{the:MarkovToBayesian}
	Let $\tnetof{\graph}$ be a tensor network on a directed acyclic hypergraph, such that the edges are of the structure
		\[ \edges = \{ (\parentsof{\node}, \{\node\}) \, : \, \node\in\nodes \} \]
	and each tensor $\hypercoreof{\edge}$ respects the directionality of the graph, that is each $\hypercoreof{(\parentsof{\node}, \{\node\})}$ is directed with the variables to $\parentsof{\node}$ incoming and $\node$ outgoing.
	Then $\partitionfunctionof{\tnetof{\graph}}=1$ and for each $\node\in\nodes$ we have
		\[ \bnnodecore = \normationofwrt{\tnetof{\graph}}{\catvariableof{\node}}{\catvariableof{\parentsof{\node}}} \, . \]
	In particular, $\tnetof{\graph}$ is a Bayesian Network.
\end{theorem}
\begin{proof}
	We show the claim by induction over the cardinality of $\nodes$.
	
	$\cardof{\nodes}=1$: In this case we find a unique node $\node\in\nodes$ and have $\edges=\{(\varnothing,\{\node\})\}$.
		The tensor $\hypercoreof{(\varnothing,\{\node\})}$ is then normed with no incoming variables and we thus have
			\[ \partitionfunctionof{\tnetof{\graph}} = \contraction{\tnetof{\graph}} = \contraction{\hypercoreof{(\varnothing,\{\node\})}} = 1 \]
		and
			\[ \normationof{\tnetof{\graph}}{\catvariableof{\node}} = \hypercoreof{(\varnothing,\{\node\})} \, .  \]
			
	$\cardof{\nodes}-1 \rightarrow \cardof{\nodes}$: Let there now be a directed hypergraph $\graph=(\nodes,\edges)$ and let us now assume, that the theorem holds for any tensor networks with node cardinality $\cardof{\nodes}-1$.
		Since the hypergraph is acyclic, we find a root $\node\in\nodes$ such that $\node\notin\parentsof{\secnode}$ for $\secnode\in\nodes$.
		We denote $\tnetof{\secgraph}$ the tensor network on the hypergraph $\secgraph=\{\nodes/\{\node\},\edges/\{(\parentsof{\node},\{\node\})\}\}$ with decorations inherited from $\tnetof{\graph}$.
		With Theorem~\ref{the:splittingContractions}, the directionality of $\bnnodecore$ and the induction assumption on $\tnetof{\secgraph}$ we have
		\begin{align*}
			\contraction{\tnetof{\secgraph}\cup\left\{\bnnodecore\right\}}
			 = \contraction{\tnetof{\secgraph}\cup\left\{\contractionof{\bnnodecore}{\catvariableof{\parentsof{\node}}}\right\}}
			 = \contraction{\tnetof{\secgraph}\cup\left\{\onesat{\catvariableof{\parentsof{\node}}}\right\}}
			 = 1
		\end{align*}
		and thus a trivial partition function.
		Since $\node$ does not appear in $\secgraph$, we have for any index $\catindexof{\parentsof{\nodes}}$
		\begin{align*}
			\contractionof{\tnetof{\graph}}{\catvariableof{\node},\indexedcatvariableof{\parentsof{\node}}}
			= \contractionof{\bnnodecore}{\catvariableof{\node},\indexedcatvariableof{\parentsof{\node}}}
			\cdot \contractionof{\tnetof{\secgraph}}{\indexedcatvariableof{\parentsof{\node}}}
		\end{align*}
		and thus, since $\bnnodecore$ is directed, that
		\begin{align*}
			\normationofwrt{\tnetof{\graph}}{\catvariableof{\node}}{\catvariableof{\parentsof{\node}}}
			= \bnnodecore \, .
		\end{align*}
\end{proof}


%\begin{theorem}\label{the:BayesianToMarkov}
%	Any Bayesian Network on a directed graph $\graph=(\nodes,\edges)$ is a Markov Network on a hypergraph $\secgraph=(\nodes,\secedges)$ with identical nodes and hyperedges consistent of  a hyeredge to each node with $\node$ being the only outgoing node and
%		\[  \{\tilde{\node} \, : \, (\tilde{\node},\node) \in \edges\} \,  \]
%	being the incoming nodes.
%	Each hyperedge of the Markov Network is decorated with the conditional probability distribution and the partition function is vanishing.
%\end{theorem}
%\begin{proof}
%	Each conditional probability distribution is associated with the hyperedge constructed to the representative node.
%	The contraction of all conditional probability distributions is the Bayesian Network, which corresponds with the constructed Markov Network due to the trivial partition function.
%\end{proof}

%% Bayesian Network richer
Theorem~\ref{the:MarkovToBayesian} states that Bayesian Networks are a subset of Markov Networks.
While Markov Network allow generic tensor cores, Bayesian Networks impose a local directionality condition on each tensor core by demanding it to be a conditional probability tensor.
In our diagrammatic notation, the local normation of Bayesian Networks is highlighted by the directionality of the hypergraph.
Generic Markov Networks are on undirected hypergraphs, where in general no local directionality condition is assumed.
As a consequence, tasks such as the determination of the partition functions or calculation of conditional distributions involve global contractions.


%% Conditioning
%The representation of Bayesian Networks by Markov Networks is of special interest when representing conditional distributions.
%Bayesian Networks conditioned on evidence are no longer Bayesian Networks on the same graph, but Markov Networks on a hypergraph enriched by the evidence conditioned about.








\subsection{Exponential Families}\label{sec:exponentialFamilies}

% Usage of the selection encoding -> Can also make a theorem out of this
Exponential families are collections of probability distributions, where each coordinate is determined by a base measure and a set $\sstat$ of features as
	\[ \probat{\indexedshortcatvariables}  \propto \basemeasure(\catindex) \cdot \expof{\sum_{\statenumeratorin} \sstatcoordinateofat{\selindex}{\indexedshortcatvariables} \cdot \canparamat{\indexedselvariable}} \, . \]
We use the selection encoding to represent the weighted summation over the statistics, that is the tensor
	\[ \sencsstatat{\shortcatvariables,\selvariable}: \facstates \times [\statorder] \rightarrow \rr \]
with
	\[ \sencsstatat{\indexedshortcatvariables,\indexedselvariable} = \sstatcoordinateofat{\selindex}{\indexedshortcatvariables} \, . \]
We then understand $\canparam$ as a vector to the categorical variable $\selvariable$ and use Theorem~\ref{the:linCompSelEncoding} to get
	\[ \sum_{\statenumeratorin}\canparamat{\indexedselvariable}\cdot \sstatcoordinateofat{\selindex}{\shortcatvariables}
		 = \sbcontractionof{\sencsstatat{\shortcatvariables,\selvariable},\canparamat{\selvariable}}{\shortcatvariables} \, . \]

\begin{definition}
	Given a sufficient statistics 
		\[ \sstat : \facstates \rightarrow \parameterspace\]
%		\[ \sstat : \atomstates \times [\statorder] \rightarrow \rr \]
	and a non-negative base measure
		\[ \basemeasure : \facstates \rightarrow \rr \]
	the set $\expfamily=\{\expdist \, : \, \canparam[\selvariable] \in \simpleparspace\}$ of probability distributions 
		\[ \expdist = \normationof{\expof{\sbcontractionof{\sencodingof{\sstat},\canparam}{\shortcatvariables}}}{\shortcatvariables} \]
	is called the exponential family to $\sstat$.
	If the base measure is positive, we define for each member with parameters $\canparam$
		\[ \expenergy = \sbcontractionof{\sencsstat,\canparam,\lnof{\basemeasure}}{\shortcatvariables} \]
	the associated energy tensor.
	We further introduce the cumulant function
		\[ \cumfunctionof{\canparam} = \lnof{\sbcontraction{\basemeasure,\expof{\sbcontractionof{\sencsstat,\canparam}{\shortcatvariables} }} } \, .\]
\end{definition}


%We have
%	\[ \expenergyat{\indexedcatvariables} = \sum_{\statenumeratorin}\sstatcoordinateof{\statenumerator}(\catindices) \cdot \canparam(\statenumerator) \, . \]

% Diverging partition functions avoided here
Since we here restrict the discussion to finite state spaces, the distribution $\expdist$ is well-defined for any $\canparam\in\rr^{\statorder}$.
For infinite state space there are sufficient statistics and parameters, such that the partition function $\sbcontraction{\basemeasure,\expof{\sbcontractionof{\sencsstat,\canparam}{\shortcatvariables}}}$ diverges and the normation $\expdist$ is not defined.
In that cases, the canonical parameters need to be chosen from a subset where the partition function is finite. 

% Cumulant representation
\begin{lemma}\label{lem:energyCumulantRepresentation}
	For any member of an exponential family $\expfamily$ with positive base measure we have
		\[ \expdist = \expof{ \expenergy - \cumfunctionof{\canparam}\cdot \onesat{\shortcatvariables}} \, . \]
\end{lemma}
\begin{proof}
	By definition we have
	\begin{align*}
		\expdist 
		&= \normationof{
		\expof{\sbcontractionof{\sencsstat,\canparam}{\shortcatvariables}}
		}{\shortcatvariables} \\
		&= \frac{\contractionof{\expof{\sbcontractionof{\sencsstat,\canparam}{\shortcatvariables}}}{\shortcatvariables}
			}{\contraction{\expof{\sbcontractionof{\sencodingof{\sstat},\canparam	}{\shortcatvariables}}}} \\
		&=  \frac{
		\contractionof{\expof{\expenergyat{\shortcatvariables}}}{\shortcatvariables}
		}{
		\expof{\cumfunctionof{\canparam}}
		} \\
		& = \expof{ \expenergyat{\shortcatvariables} - \cumfunctionof{\canparam}\cdot \onesat{\shortcatvariables}} \, . 
	\end{align*}
\end{proof}


\subsubsection{Tensor Network Representation} 

We can use the relational encoding formalism to represent members of exponential families by a single contraction, as we show next.
The central insight here is a relational encoding of the sufficient statistics, which enables representation by tensor network decomposition, when the sufficient statistic is decomposable.

\begin{theorem}[Generic Representation of Exponential Families]\label{def:expFamilyTensorRep}
	Given any base measure $\basemeasure$ sufficient statistic $\sstat$ we enumerate for each coordindate $\selindexin$ the image $\imageof{\sstatcoordinateof{\selindex}}$ by a variable $\sstatcatof{\selindex}$ taking values in $[\cardof{\imageof{\sstatcoordinateof{\statenumerator}}}]$, given an interpretation map
		\[ \indexinterpretationof{\selindex} : 
		[\cardof{\imageof{\sstatcoordinateof{\statenumerator}}}] \rightarrow \imageof{\sstatcoordinateof{\statenumerator}} \, . \]
	
	For any parameter vector $\canparamat{\selvariable}:[\seldim]\rightarrow\rr$ we build the activation cores
		\[ \headcoreofat{\statenumerator}{\sstatcatof{\selindex}=\sstatindof{\selindex}} 
		= \expof{\canparamat{\indexedselvariable} \cdot \indexinterpretationofat{\selindex}{\sstatcatof{\selindex}} } \,   \]
	and have
		\[ \expdist = 
		\normationof{\{\basemeasure,\rencodingof{\sstat}\}\cup\{\headcoreof{\statenumerator} \, : \, \statenumeratorin\}}{\shortcatvariables} \, . 
		\]
%	where we use the vectors $\headcoreof{\statenumerator} : \imageof{\sstatcoordinateof{\statenumerator}} \rightarrow \rr $ defined for $y \in \imageof{\sstatcoordinateof{\statenumerator}}$ by
\end{theorem}
\begin{proof}
	We use an extended image of $\sstat$ by  %	which does not modify the statement of Theorem~\ref{the:tensorFunctionComposition} (since extension to cases, which are never met).
		\[ \imageof{\sstat} = \bigtimes_{\statenumeratorin} \imageof{\sstatcoordinateof{\selindex}} \, . \]
	Theorem~\ref{the:tensorFunctionComposition} implies
		\[ \expof{\contractionof{\{\sstat, \canparam\}}{X}}
		= \contractionof{\{\rencodingof{\sstat}, \restrictionofto{\expof{\braket{\cdot, \weight}}}{\imageof{\sstat}} \}}{X} \, . \]
	The claim follows from the equation
		\[ \restrictionofto{\expof{\braket{\cdot, \canparam}}}{\imageof{\sstat}} 
		= \bigotimes_{\selindexin} \restrictionofto{\expof{\cdot \canparamat{\indexedselvariable}}}{\imageof{\sstatcoordinateof{\selindex}}}  
		= \bigotimes_{\selindexin} \headcoreof{\selindex} \, . \]
\end{proof}


We notice, that the relational encoding is the contraction of the relational encoding of its coordinate maps as 
	\[ \rencodingofat{\sstat}{\shortcatvariables,\sstatcatof{[\seldim]}} = \contractionof{\rencodingof{\sstatcoordinateof{0}},\ldots,\rencodingof{\sstatcoordinateof{\seldim-1}}}{\shortcatvariables,\sstatcatof{[\seldim]}} \, .  \]
We will show this property in Theorem~\ref{the:functionDecompositionBasisCP}.
One strategy to create $\rencodingof{\sstat}$ is thus the creation of the encoding of all its coordinate maps.
When the coordinate maps are sharing common components, a sparser representation can be derived through encodings of the components shared among the coordinate map encodings.


% Core types
A tensor network representation of an exponential family is thus a Markov Network consistent of two types of cores.
Computation cores are relational encodings of statistics $\rencodingof{\sstatcoordinateof{\selindex}}$.
Our intuition is that they compute the hidden variable $\catvariableof{\sstatcoordinateof{\selindex}}$, based on Basis Calculus (see Chapter~\ref{cha:basisCalculus}).
Activation cores $\headcoreof{\selindex}$ exploit the computed variable and provide, when contracted with the relational encoding, a factor 
	\[ \sbcontractionof{\rencodingof{\sstatcoordinateof{\selindex}}, \headcoreofat{\statenumerator}{\catvariableof{\statenumerator}}}{\shortcatvariables}  \]
to the Markov Network reduced to the visible coordinates $\shortcatvariables$.
The activation cores are trivial, i.e. $\headcoreofat{\selindex}{\sstatcatof{\selindex}}=\onesat{\sstatcatof{\selindex}}$, when $\canparamat{\selvariable=\selindex}=0$.
In that case 
	\[  \sbcontractionof{\rencodingof{\sstatcoordinateof{\selindex}}, \headcoreofat{\statenumerator}{\catvariableof{\statenumerator}}}{\shortcatvariables} 
	= \onesat{\shortcatvariables} \]
and both the activation core and the corresponding computation core can be dropped from the network without changing its distribution.

%% FALSE STATEMENT? 
%We can sum multiples of the trivial tensor on the head cores without changing the distribution as we show next.
%
%\begin{theorem}
%	For any $\statenumeratorin$, the distribution is invariant under replacing $\headcoreofat{\statenumerator}{\selvariableof{\statenumerator}}$ by $\headcoreofat{\statenumerator}{\catvariableof{\statenumerator}}+\lambda\cdot \onesat{\catvariableof{\statenumerator}}$ where $\lambda\in\rr$
%\end{theorem}
%\begin{proof}
%	Follows from linearity in each head core, trivialization by trivial heads and normation.
%	
%	By linearity we have
%	\begin{align*}
%		\sbcontractionof{\rencodingof{\sstatcoordinateof{\selindex}}, (\headcoreofat{\statenumerator}{\catvariableof{\statenumerator}}+\lambda\cdot \onesat{\catvariableof{\statenumerator}})}{\shortcatvariables}
%		= 
%		\sbcontractionof{\rencodingof{\sstatcoordinateof{\selindex}}, \headcoreofat{\statenumerator}{\catvariableof{\statenumerator}}}{\shortcatvariables}
%		+\lambda\cdot  \sbcontractionof{\rencodingof{\sstatcoordinateof{\selindex}}, \onesat{\catvariableof{\statenumerator}}}{\shortcatvariables}
%		=  \sbcontractionof{\rencodingof{\sstatcoordinateof{\selindex}}, \headcoreofat{\statenumerator}{\catvariableof{\statenumerator}}}{\shortcatvariables}
%		+ \lambda \cdot \onesat{\shortcatvariables} \, .
%	\end{align*}
%\end{proof}


\begin{remark}[Comparison of relation and selection encodings]
	% Relation vs Selection encoding
	Relation encodings are in general of higher dimensions than selection encodings.
	In can thus be intractible to instantiate the probability distribution as a tensor networks, while the energy tensor can still be efficiently represented based on selection encodings.
	\red{In this case, energy-based reasoning algorithms are tractible while more direct methods are intractible.}
\end{remark}





\subsubsection{Mean Parameters}

Mean parameters are an alternative way to represent members of exponential families.

\begin{definition}\label{def:meanForwardBackward}
	Let there be an exponential family defined by $\sstat$.
	We call the tensor
		\[ \meanparam = \sbcontractionof{\expdist,\sencodingof{\sstat}}{\selvariable} \]
	the mean parameter tensor to a member $\expdist$ of an exponential family.
	The set 
		\[ \meansetof{\sstat} = \{\contractionof{\probtensor,\sencodingof{\sstat}}{\selvariable} \, : \, \probtensor\in\probtensorset \} \, , \]
	where $\probtensorset$ denotes the set of all probability distributions,
	is called the convex polytope of realizable mean parameters.
	The map
		\[ \forwardmap :  \simpleparspace\rightarrow\simpleparspace\]
	with $\forwardmapof{\canparam} = \sbcontractionof{\expdist,\sencodingof{\sstat}}{\selvariable}$ is called the forward map of the exponential family and any map
		\[ \backwardmap : \imageof{\forwardmap} \rightarrow \simpleparspace\]
	with $\expdistof{(\sstat,\backwardmapof{\forwardmapof{\canparam}},\basemeasure)} = \expdist$ for any $\canparam\in\rr^{\statorder}$ a backward map.
\end{definition}


% Polytope
The image $\imageof{\forwardmap}$ of the forward map is the interior of the convex polytope $\meansetof{\sstat}$.
It contains any mean parameters $\sbcontractionof{\probtensor,\sstat}{\selvariable}$ realizable by any probability distribution $\probtensor$ \cite{wainwright_graphical_2008}.

\red{Add convex hull interpretation!}

\subsubsection{Examples}

% Naive Exponential Family
\begin{example}[The naive exponential family]\label{exa:naiveExpFamily}
	When taking as sufficient statistic the identity $\identityat{\shortcatvariables,\selvariable}$, we can represent any positive distribution $\probtensor$ as a member of the exponential family, namely when choosing the canonical parameter
		\[ \canparam = \lnof{\probtensor} \, . \]
	The associated mean parameter is then
		\[ \meanparam = \probtensor \, . \]
\end{example}


% Markov Networks
Given a hypergraph with fixed node decoration, the different decorations of the hyperedges by tensors can be represented by an exponential family, as we show next.

\begin{theorem}[Exponential Representation of Markov Networks]
	For any hypergraph $\graph=(\nodes,\edges)$ we define a sufficient statistics 
		\[ \sstat = \bigtimes_{\edge\in\edges}  \sstatcoordinateof{\edge} \]
	where 
		\[ \sstatcoordinateof{\edge}(\catindexof{\nodes}) = \catindexof{\edge} \, . \]
	Given any Markov Network $\{\hypercoreof{\edge}\}$ on $\graph$ with positive tensors $\hypercoreof{\edge}$ we define
		\[ \canparam = \bigtimes_{\edge\in\edges} \canparam_{\edge} \]
	where
		\[ \canparam_{\edge} =  \ln\left[ \hypercoreof{\edge} \right] \]
	and $\ln$ acts coordinatewise.
	Then, the Markov Network is in the member of the exponential family with trivial base measure, sufficient statistic $\sstat$ and parameters $\canparam$.
\end{theorem}
\begin{proof}
	We have for any $\catindexof{\nodes}$
	\begin{align}
	\prod_{\edge\in\edges} \hypercoreofat{\edge}{\indexedcatvariableof{\edge}}
		= \expof{\sum_{\edge\in\edges} \canparamwrtat{\edge}{\indexedcatvariableof{\edge}}}
		= \expof{\sum_{\edge\in\edges} \sbcontraction{\canparamwrtat{\edge}{\catvariableof{\edge}},\sstatcoordinateof{\edge}(\catindexof{\nodes})}}  \, .
	\end{align}
	Using that
		\[ \contractionof{\sstat,\canparam}{\nodevariables} = \sum_{\edge\in\edges} \contractionof{\sstatcoordinateof{\edge},\canparam_{\edge}}{\nodevariables} \]
	we get
	\begin{align}
		\contractionof{\{\hypercoreof{\edge}: \edge\in\edges\}}{\nodevariables} = \expof{\contractionof{\canparam,\sstat}{\nodevariables}} \, .
	\end{align}
	This implies 
	\begin{align}
		\normationof{\{\hypercoreof{\edge}: \edge\in\edges\}}{\nodevariables} = \normationof{\expof{\contractionof{\canparam,\sstat}{\nodevariables}}}{\nodevariables} \, .
	\end{align}
\end{proof}


% Mean parameters
The mean parameter of the Markov Network exponential family is the cartesian product of the marginals $\meanparam_\edge[\catvariableof{\edge}]$ are often refered to as beliefs in the literature.



\subsection{Empirical Distributions}\label{sec:empDistribution}


%The statistic of observed worlds is stored in the data tensor $\datacore$, carrying again indices to each atom.
%It is the probability tensor of the empirical distribution $\probtensorof{\datacore}$. 
%Each coordinate is thus the ratio of the observation of the world with the by the indices specified world.
%
%
%\subsubsection{Representing a single sample}
%
%Single samples are states of the factored systems, which are indexed by $(\catindices)$ and represented by one-hot encodings $\onehotmapof{\catindices}$.
%
%%% Inductive vs Deductive perspective
%Each evidence is a probability distribution
%\begin{itemize}
%	\item Inductive Reasoning: When we interpret evidence as a datapoint, they are typically a basis tensor specifying precisely a world.
%	\item Deductive Reasoning: Evidence is a partial observation of the world, typically basis vectors at each variable, but leaving some unspecified ($\ones$).
%	We then interpret the evidence as being a uniform distribution over the worlds not contradicting with the evidence.
%\end{itemize}
%
%
%\subsubsection{Construction from a list of samples}

\begin{definition}\label{def:dataMap}
	Given a dataset $\{(\catindicesof{\dataindex}) \, : \, \dataindexin \}$ of samples of the factored system we define the sample selector map
		\[ \datamap : [\datanum] \rightarrow \facstates \]
	elementwise by 
		\[ \datamap(\dataindex) = (\catindicesof{\dataindex}) \, . \]
	Its relational encoding (see Definition~\ref{def:functionRepresentation}) is the tensor
		\[ \rencodingofat{\datamap}{\datvariable,\shortcatvariables} = \sum_{\dataindexin} \onehotmapofat{\dataindex}{\datvariable} \otimes \onehotmapofat{\catindicesof{\dataindex}}{\shortcatvariables} \, , \]
	which we call a data tensor.
\end{definition}

%% Basic CP Decomposition of the Data Tensor
The Data Tensor is a conditional probability tensor and has a network decomposition depicted in Figure~\ref{fig:DataDecomposition}.
The cores $\datacoreof{\atomenumerator}$ are matrices storing the value of the categorical variable $\catvariableof{\atomenumerator}$ in the sample world indexed by $\dataindex$.
Whereas the one-hot encoding of single samples is a basis tensor (and therefore a basis elementary decomposition), the data tensor has a basis CP decomposition, see Section~\ref{sec:basisCP}).
This follows from Theorem~\ref{the:functionDecompositionBasisCP}, using the coordinate maps of $\datamap$ by
	\[ \datamap_{\atomenumerator} : [\datanum] \rightarrow [\catdimof{\atomenumerator}] \]
defined by
	\[  \datamap_{\atomenumerator}(\dataindex) = \catindexof{\atomenumerator}^\dataindex \, .  \]

\begin{figure}[h]
\begin{center}
	\input{PartI/tikz_pics/probability_decomposition/data_decomposition.tex}
\end{center}
\caption{
	Representation of a dataset.
	a) As a Bayesian network.
	b) Decomposition of the data tensor into a tensor network in the $\cpformat$ Format.
	Without the contraction with the dashed $\frac{1}{\datanum}\ones$ core, the datacore encodes the distribution conditioned on a datapoint. }
\label{fig:DataDecomposition}
\end{figure}


%% Conditional Probability interpretation
The Data Tensor a conditional probability tensor, which retrieves the respective sample distribution when selecting a sample.
We can represent this probability distribution by a random variable $\catvariableof{\dataindex}$ selecting a specific datapoint on which the atoms depend.

%% Empirical Distribution
We define the empirical distribution by the normation of the relational encoding of the datamap as
\begin{align*}
	\empdistribution 
	\coloneqq \sbnormationof{\datacore}{\shortcatvariables} \, . 
\end{align*}
Each coordinate of the empirical distribution is the frequency of the by the index specified word in the data.

\begin{theorem}\label{the:empCPRep}
	Given a data map $\datamap$ we have
	\begin{align*}
		\rencodingofat{\datamap}{\datvariable,\shortcatvariables}  
		= \contractionof{
		\{\rencodingofat{\datamap^{\atomenumerator}}{\datvariable,\catvariableof{\atomenumerator}} : \atomenumeratorin \} 
		}{\datvariable,\shortcatvariables} 
	\end{align*}
	and
	\begin{align*}
	\empdistribution = \sbcontractionof{\datacore, \frac{1}{\datanum}\ones}{\shortcatvariables} 
	= \sbcontractionof{\datacoreof{0},\ldots,\datacoreof{\atomorder-1}, \frac{1}{\datanum}\onesat{\datvariable}}{\shortcatvariables} \, . 
	\end{align*}
\end{theorem}
\begin{proof}
	The first claim is a special case of Theorem~\ref{the:functionDecompositionBasisCP}, to be shown in Chapter~\ref{cha:tensorEncodings}.
	To show the second claim we notice
		\[ \sbcontraction{\datacore} = \sum_{\datindexin} \sbcontraction{\rencodingofat{\datamap}{\datvariable=\datindex,\shortcatvariables}} = \datanum \,  . \]
	With the first claim it follows that
	\begin{align*}
		\empdistribution 
		 = \sbnormationof{\datacore}{\shortcatvariables}
		 = \frac{\sbcontractionof{\datacore}{\shortcatvariables}}{\sbcontraction{\datacore}} 
		 =  \contractionof{
		\{\rencodingofat{\datamap^{\atomenumerator}}{\datvariable,\catvariableof{\atomenumerator}} : \atomenumeratorin \} \cup \{Â \frac{1}{\datanum} \onesat{\datvariable} \}
		}{\datvariable,\shortcatvariables}  \, . 
	\end{align*}
\end{proof}

%The normation can be represented by averaging the data index $\dataindex$ and we have
%\begin{align*}
%	\empdistribution = \contractionof{\{\datacore, \frac{1}{\datanum}\ones \}}{\shortcatvariables} 
%	= \contractionof{\{\datacoreof{0},\ldots,\datacoreof{\atomorder-1}, \frac{1}{\datanum}\ones \}}{\shortcatvariables} \, . 
%\end{align*}
In a contraction diagram we represent the empirical distribution by
\begin{center}
	\input{PartI/tikz_pics/probability_decomposition/empirical_distribution.tex}
\end{center}

%% Perspective of forwarding the uniform distribution of the samples
In another perspective, we can understand $\frac{1}{\datanum}\ones$ as the uniform probability distribution over the samples, which is by the map $\datamap$ forwarded to a distribution over $\facstates$.
%By Theorem~\ref{the:conditionalAverage} also the empirical distribution tensor $\empdistribution$ is a probability tensor.






\section{Discussion and Outlook}

\begin{remark}[Alternative definitions of graphical models]
	In the literature, tensor networks are often called dual to the hypergraphs defining graphical models (see e.g. \cite{robeva_duality_2019}).
	The duality becomes clear, when one interpretes the tensors as cores and their common variables as edges.
	We in this work avoid this ambiguity by directly defining tensor networks as decoration of hyperedges by tensors.
	
	Often, the tensors decorating hyperedges are called factors and their logarithm features \cite{koller_probabilistic_2009}.
	
	Further, we directly use hypergraphs instead of the more canonical association of factors with cliques of a graph.
	This avoids the discussion of non-maximal cliques as decorated with trivial tensors.
	Such hypergraphs follow the same line of though compared with factor graphs, which are bipartite graphs with nodes either corresponding with single variables or with a collection of them affected by a factor.
\end{remark}







